#! /bin/sh -e
#! /bin/sh
#! /bin/sh --
#! /proc/parent/exe --
#! /bin/sh -eEauf

# [ "$(cat /etc/hostname 2> /dev/null)" != "kiss" ] &&
[ ! -z "${IS_KISS+x}" ] && set -Eau || set -au

check_pipefail="$(set -o | grep pipefail | awk "{print \$1}")"
[ "$check_pipefail" != "pipefail" ] || set -o pipefail

# Outdated option: shellcheck source=/dev/null
#
# Simple package manager written in POSIX shell for https://kisslinux.org
#
# The MIT License (MIT)
#
# Copyright (c) 2019-2021 Dylan Araps
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Coding specifications and conventions (recommended by Tuo Jung)
# Environment variables value convention
# To simplify the conventions of the system, undefined and "" (empty) mean
# different behaviors
# Since "set -u" is a good habit, "" (empty) should be used for satisficing it
# "${KISS_STRIP-}" will be used where citations are required, which means
# the default behavior
# Note the different meanings of the following definitions
# [ -n "${KISS_STRIP:+x}" ] means no stripping (non-null value)
# [ -z "${KISS_STRIP:+x}" ] means stripping (non-null value)
# While
# [ -n "${KISS_DEBUG:+x}" ] means debugging (non-null value)
# [ -z "${KISS_DEBUG:+x}" ] means no debugging (non-null value)
# And readonly makes their values maintaining consistency
# For history compatibility, we check the value of other customary conventions
# after this

# Naming convention/semantics
# XXX_DIR     : parent address for a package   (like dirname, subject depends)
# XXX_FOLDER  : parent dir name for a package  (has no path)
# XXX_ROOT    : search root for target         (further finding needed)
# XXX_PATH    : full address of a package      (like realpath)

# xxx_dir     : parent address for a package (locally / does not export)

# Search "File Hierarchy" / "init_dirs()" (without quotes) for naming applications

# Levels of structure
#                       |---------------pkg_cache-----------|
#   local_route    |--build--|      |--pkg_cache--|
# src_url -> des -> make -> pkg -> archive -> extract -> install

# Tips
# Line number calculatiions by alias might be interrupted due to it's quotation broken lines
# We know what code does, and codes know what they do. Never break the chain of integration

# https://stackoverflow.com/questions/52659038/how-to-suppress-irrelevant-shellcheck-messages
# shellcheck --exclude=SC1127,SC2016,SC2015,SC3043,SC2155,SC3001,SC3003,SC3014,SC2287,SC2031

[ -t 0 ] || {
	printf '%s %s\n' 'fd 0' "does not work at $LINENO"
	# exec </dev/stdin
	exec </dev/tty
}

# printf '%s %s\n' '$LINENO' "$LINENO"

# Put arguments to the array arg[]
# index=0
# for arg do eval "arg_$index=\$arg"; : "$((index += 1))"; done
# unset index

[ -n "${HEADER+x}" ] ||
printf '%s %s\n' '$HEADER' "not defined"

# [ -z "${USE_SAY_PIPE+x}" ] || unset USE_SAY_PIPE
# KISS_INNER_PIPE defined means using pipe_reader in kiss-share
# : "${KISS_INNER_PIPE:=""}"
# : "${USE_ENV:=""}" && export USE_ENV
[ -z "${KISS_INNER_PIPE+x}" ] || unset KISS_INNER_PIPE
[ -z "${mute_err+x}" ] || unset mute_err
[ -z "${KEEP_DEPRECATED+x}" ] || unset KEEP_DEPRECATED
: "${SESSION_PID:="$$"}" && export SESSION_PID
: "${SESSION_PPID:="${PPID}"}" && export SESSION_PPID
: "${KISS_PID:=$$}" && export KISS_PID
: "${KISS_TMPDIR:="/tmp/$LOGNAME/kiss"}" && export KISS_TMPDIR
# Neither the log folder nor the pipes are created at this moment.
# So don't use the log functions before user_output and pipes/listeners are ready
[ -d "$KISS_TMPDIR" ] || mkdir -p "$KISS_TMPDIR"
log_dir="$KISS_TMPDIR/logs"
[ -d "$log_dir" ] || mkdir -p "$log_dir"
: "${USER_OUTPUT:="$KISS_TMPDIR/logs/build.log"}" && export USER_OUTPUT

interrupt_type="$(type "interrupt" > /dev/null && type "interrupt")" || :
{
	[ ! -z "${interrupt_type:+x}" ] &&
	[ -z "${interrupt_type##*"alias"*}" ]
	# set | grep -q _level > /dev/null &&
	# [ -n "${-##*x*}" ]
	# [ -n "${HEADER+x}" ]
} || {

	# Outdated option: shellcheck source=/dev/null
	# shellcheck source=/usr/include/kiss-share
	. /usr/include/kiss-share
	# . /usr/include/kiss-share > /dev/null 2>&1

	[ -t 0 ] || // die 'fd 0' "does not work"
	# export $(cut -d= -f1 /usr/include/kiss-share)

	# -ash: //: Permission denied -- // is not defined
	# // war '$HEADER' "$HEADER"

	# export HEADER=
}

# Test line number calcuation -- searching different typographics have the same line number
# printf '%s %s\n' 'Current line' "New line"
// log 'inside' "kiss"

SCRIPT_NAME="kiss" && export SCRIPT_NAME

# : "${lineno="$((LINENO + 2))"}"
# : "${lineno_scope="$lineno"}"
# // war '$HEADER' "$HEADER"

# Without kiss-share file version
# / "$function_debug_filter"

// && [ "$lineno" -eq "$LINENO" ] || // war '$lineno : $LINENO' "$lineno : $LINENO"

run() {
	_level_2
	# Print the command, then run it.
	// log "$scope" "$*"
	"$@"
}

// && [ "$lineno" -eq "$LINENO" ] || // war '$lineno : $LINENO' "$lineno : $LINENO"

# Aquire an empty file in temporary directory for writing into
# it step by step in the future
# $1 repo_urn    : repo name
# $2 src_address : source file full path or file name
slot_aquire() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local src_address="$(standardize "$2")"
	local src_name="${src_address##*/}"
	src_name="${src_name%\?*}"

	[ "${src_address:0:1}" != '/' ] || src_address="${src_address#/}"

	# Create a uniquely named temporary file and store its absolute path
	# in a variable and return it to the caller (stack_topend).

	# The following comments was deprecated
	# To prevent subshell usage and to handle cases where multiple files
	# are needed, this saves the last two temporary files to variables
	# for access by the caller (allowing 3 files at once).

	# local stack_topend="$TEMP_ROOT/$pkg_name/$src_address.$(mktemp -u XXXXXX)"
	local stack_topend="$TEMP_ROOT/$pkg_name/$src_address"
	[ ! -f "$stack_topend" ] ||
	[ ! -s "$stack_topend" ] || {
		// war '$stack_topend' \
			"'$stack_topend'\
			${newline}already exists and is not empty \
			${newline}[make sure it's designed that way]"
		# local index=0
		# while read -r line; do
		#     : $((index += 1))
		#     // log '$stack_topend' "$(delegate -- format "$index") $line"
		# done < "$stack_topend"
	}

	local dir_topend="${stack_topend%/*}"
	[ -d "$dir_topend" ] || // as_own "$TEMP_ROOT" mkdir -p "$dir_topend"

	// as_own "$TEMP_ROOT" touch "$stack_topend" ||
		// die "$src_address" \
			"failed to create the temporary file under $TEMP_ROOT/$pkg_name"
	printf '\n%s' "$stack_topend"
}

// && [ "$lineno" -eq "$LINENO" ] || // war '$lineno : $LINENO' "$lineno : $LINENO"

# Copy an extarnal file to temporary directory in one time
# Won't create empty file
# $1 repo_urn    : repo name
# $2 src_address : source file full path
slot_push() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local src_address="$2"
	local src_name="${src_address##*/}"
	src_name="${src_name%\?*}"

	# Create a uniquely named temporary file and make a duplicate of
	# the file in '$src_address' if it exists.
	local stack_top="$(// delegate -- slot_aquire "$pkg_name" "$src_address")"
	// log '$stack_top' "'$stack_top' touched"

	[ ! -f "$src_address" ] ||
	null "$stack_top" || {
		// as_own "$stack_top" rsync -aqzL "$src_address" "$stack_top" ||
			// die '$src_address' "\"$src_address\" failed to copy"
		sync
		// log '$src_address' "$src_address"
		// log '$stack_top' "$stack_top"
	}

	printf '\n%s' "$stack_top"
}

mkcd() {
	_level_2

	ok "$1" || // die "Trying to create an empty directory"

	local target="$1"
	local item
	for item do
		item="$(standardize "$item")"
		// debug '$item' "$item"
		local parent_dir="${item%/*}"
		// debug '$parent_dir' "$parent_dir"
		local index=0
		[ -z "${parent_dir:+x}" ] ||
		# Have not been created yet
		while [ ! -d "$parent_dir" ] && [ "$index" -lt "10" ]; do
			[ -z "${parent_dir:+x}" ] || parent_dir="${parent_dir%/*}"
			: $((index += 1))
		done
		[ -n "${parent_dir:+x}" ] ||
			// die 'mkdir -p $item' 'Trying to modify system root /'
		[ "$parent_dir" != "$KISS_ROOT" ] ||
			// die 'mkdir -p $item' 'Trying to modify $KISS_ROOT/'
		// debug '$parent_dir' "$parent_dir"
		// debug '$item' "$item"
		// as_own "$parent_dir" \mkdir -p "$item" || // die 'mkdir' "$item"
	done
	cd "$target"
	// log '$PWD' "$PWD"
}

# encode right to left in a pair and left to right in $@ (pairs)
# encode "$source_string" "REPO_MAIN" "$REPO_MAIN" "REPO_ROOT" "$REPO_ROOT"
#               ^             ^            |             ^           |
#               |             |____________|             |___________|
#               |___________________|_________________________|
[ -z "${KEEP_DEPRECATED+x}" ] ||
# Deprecated
encode() {
	local level=-1
	[ "$level" -eq "-1" ] ||
	_level_2
	// debug '$@' "$(esceval "$@")"
	[ "$#" -ge "3" ] || // die '$#' "$# parameters are not enough"
	local str="$1"
	shift 1

	local arguments=

	# local ifs="$IFS"
	# local IFS="$IFS_ORIGIN"
	for index in $(seq 1 2 $#); do
		local target="$(/ "printf '%s' \"\${$index}\"")"
		[ -n "$target" ] || target=\"\"
		local source="$(/ "printf '%s' \"\${$((index + 1))}\"")"
		[ -n "$source" ] || source=\"\"
		case "$target" in
			*"$source"*)
				// die '$target contains $source' "'$target' contains '$source'"
		esac

		# If you have an array, and step in 2 elements at a time
		# set -f -- "$@" "\ " "$target" "$target" "$source" "\\$target" "\ "
		arguments="${arguments:+"${arguments} "}$FS $target $target $source \\$target $FS"

	done
	// debug '$arguments' "$arguments"
	local ifs="$IFS"
	local IFS=$' '
	set +f
	set -f -- $arguments
	set -- "$str" "$@"
	IFS="$ifs"
	// debug '$#' "$#"
	[ "$#" -ge "3" ] || // die '$#' "$# parameters are not enough"

	# Don't quote $arguments in the following line if referenced
	printf '\n%s' "$(// delegate -- replace "$@")"
}

# decode right to left in a pair and left to right in $@ (pairs)
# decode "$source_string" "$REPO_MAIN" "REPO_MAIN" "$REPO_ROOT" "REPO_ROOT"
#               ^             ^            |             ^           |
#               |             |____________|             |___________|
#               |___________________|_________________________|
[ -z "${KEEP_DEPRECATED+x}" ] ||
# Deprecated
decode() {
	local level=-1
	[ "$level" -eq "-1" ] ||
	_level_2
	// debug '$@' "$(esceval "$@")"
	[ "$#" -ge "3" ] || // die '$#' "$# parameters are not enough"
	local str="$1"
	shift 1

	local arguments=

	# local ifs="$IFS"
	# local IFS="$IFS_ORIGIN"
	# $10 will be treated as $1+0
	# // debug '$10' "$10"
	# // debug '${10}' "${10}"
	for index in $(seq 1 2 $#); do
		// debug '$index' "$index"
		# // debug "\$${index}" "$(/ "echo \"\${$index}\"")"
		# // printf '%s %s\n' "\$${index}" "$(/ "echo \"\${$index}\"")" >> "$USER_OUTPUT"
		local target="$(/ "printf '%s' \"\${$index}\"")"
		[ -n "$target" ] || target=\"\"
		// debug '$target' "$target"
		# // debug "\$$((index+1))" "$(/ "echo \"\${$((index+1))}\"")"
		# // printf '%s %s\n' "\$$((index+1))" "$(/ "echo \"\${$((index+1))}\"")" >> "$USER_OUTPUT"
		local source="$(/ "printf '%s' \"\${$((index + 1))}\"")"
		[ -n "$source" ] || source=\"\"
		// debug '$source' "$source"
		case "$target" in
			*"$source"*)
				// die '$target contains $source' "'$target' contains '$source'"
		esac

		# If you have an array, and step in 2 elements at a time
		# set -f -- "$@" "\ " "\\$source" "$target" "$source" "$source" "\ "
		arguments="${arguments:+"${arguments} "}$FS \\$source $target $source $source $FS"

	done
	// debug '$arguments' "$arguments"
	local ifs="$IFS"
	local IFS=$' '
	set +f
	set -f -- $arguments
	set -- "$str" "$@"
	IFS="$ifs"
	// debug '$#' "$#"
	[ "$#" -ge "3" ] || // die '$#' "$# parameters are not enough"

	# Don't quote $arguments in the following line if referenced
	printf '\n%s' "$(// delegate -- replace "$@")"
}

# $1 parameter
# $2 library
# $3 manifest list
pkg_owner() {
	_level_2

	ok "$2" || { set +f; set -f -- "$1" "$sys_db"/*/manifest; }

	_owns="$(grep -lxF "$@")"
	_owns="${_owns%/*}"
	_owns="${_owns##*/}"

	ok "$_owns"
}

resolve_path() {
	_level_2
	_rpath=$KISS_ROOT/${1#/}
	local _parent
	# Attempt to resolve symlinks by using 'cd'.
	# If this fails, fallback to the file's parent
	# directory.
	if cd -P "${_rpath%/*}" 2>/dev/null; then
		_parent=$PWD
		cd "$OLDPWD"
	else
		_parent=${_rpath%/*}
	fi

	_rpath=${_parent#"$KISS_ROOT"}/${_rpath##*/}
}

run_hook() {
	_level_2
	local command="$1"
	shift 1

	# Run all hooks in KISS_HOOK (a colon separated
	# list of absolute file paths).
	local ifs="$IFS"
	local IFS=$':'

	for hook in ${KISS_HOOK:-}; do
		[ ! -f "$hook" ] ||
		case $hook in
			*?*)
				// as_own "$KISS_ROOT/" "$hook" "$command" "$@" ||
					// die "$command" "hook failed: '$hook'"
		esac
	done

	IFS="$ifs"

	# [ "$command" == "SIGINT" ] ||
	# [ "$command" == "SIGEXIT" ] || return 0
}

# $1 command
# $2 pkg_name
# For compatibility, do not change the "$pkg_name" parameter
run_hook_pkg() {
	_level_2
	local command="$1"
	shift 1
	local pkg_name="$1"
	pkg_name="${pkg_name%%@*}"
	local repo_ver="$2"
	local repo_rel="$3"
	local repo_dir="$4"
	local repo_urn="$1repo_dir/$pkg_name"
	local real_command="$repo_urn/$command"
	[ -f "$real_command" ] || {
		# Run a hook from the package's database files.
		# real_command="$sys_db/$pkg_name/$command"
		# [ -f "$real_command" ] || {
			// log "$command" "skipping hook: no executable command"
			return 0
		# }
	}
	! command -v "$real_command" > /dev/null 2>&1 || {
		// log "$pkg_name" "running $command hook"
		// as_own "$KISS_ROOT/" "$real_command" "$@" ||
		// die '$real_command' "'$real_command' execution failed"
	}
}

# $1 tar_file : tar file
decompress() {
	_level_2
	local tar_file="$1"

	set --
	local tar_dir_user="$(// delegate owner "$TAR_ROOT")"
	[ "$LOGNAME" = "$tar_dir_user" ] ||
		set -- $(// delegate as_user "$tar_dir_user")

	[ -f "$tar_file" ] &&
		// log '$tar_file' "$tar_file [local]" ||
		// die '$tar_file' "${tar_file:+"${tar_file} "}has not yet built [local]"

	case "$tar_file" in
		*.zip)
			local tar_path="${tar_file%/*}"
			"$@" unzip -oq "$tar_file"
			tar_file="${tar_file##*/}"
			tar_file="$tar_path/${tar_file%%.*}.tar"
			"$@" tar -cf "$tar_file" ./
	esac

	case "$tar_file" in
		*.tbz|*.bz2) "$@" bzip2 -d ;;
		*.lzma)      "$@" lzma -dc ;;
		*.lz)        "$@" lzip -dc ;;
		*.tar)       "$@" cat      ;;
		*.tgz|*.gz)  "$@" gzip -d  ;;
		*.xz|*.txz)  "$@" xz -dcT0 ;;
		*.zst)       "$@" zstd -dc ;;
	esac < "$tar_file"

}

sh256() {
	_level_2
	# Higher level sh256 function which filters out non-existent
	# files (and also directories).
	for f do shift
		[ -d "$f" ] || [ ! -e "$f" ] || set -- "$@" "$f"
	done

	local hash="$(// _sh256 "$@")" || // die '_sh256' "$hash"
	printf '\n%s' "$hash"
}

_sh256() {
	_level_2

	# There's no standard utility to generate sha256 checksums.
	# This is a simple wrapper around sha256sum, sha256, shasum,
	# openssl, digest, ... which will use whatever is available.
	#
	# All utilities must match 'sha256sum' output.
	#
	# Example: '<checksum>  <file>'
	local hash=

	# Skip generation if no arguments.
	! equ "$#" 0 || return 0

	# Set the arguments based on found sha256 utility.
	case ${cmd_sha##*/} in
		openssl) set -- dgst -sha256 -r "$@" ;;
		 sha256) set -- -r "$@" ;;
		 shasum) set -- -a 256 "$@" ;;
		 digest) set -- -a sha256 "$@" ;;
	esac

	local ifs="$IFS"
	local IFS="$newline"

	# Generate checksums for all input files. This is a single
	# call to the utility rather than one per file.
	local sha_list="$("$cmd_sha" "$@")" || // die "Failed to generate checksums"

	# Strip the filename from each element.
	# '<checksum> ?<file>' -> '<checksum>'
	for sum in $sha_list; do
		hash=$hash${hash:+"${IFS}"}${sum%% *}
	done

	printf '\n%s' "$hash"
	IFS="$ifs"
}

is_version() {
	ok "$1" || return 1
	local ver="$1"
	ver="$(// delegate -- replace "$ver" "" ".")"
	is_integer "$ver"
}

pkg_base() {
	_level_2
	local pkg_name="$1"
	# local repo_urn="$1"
	# repo_urn="$(standardize "$repo_urn")"
	# local pkg_name="${repo_urn##*/}"
	# # [ -d "$repo_urn" ] || // die '$repo_urn' "'$repo_urn' directory does not exist"
	# local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local target_source=

	# # Keys design begin
	# [ -z "${USE_KEYS:+x}" ] || {
	#   # Recover repo from "keys" file
	#   # Keys design was deprecated. "repo_dir" merged into version file
	#   [ ! -f "$repo_urn/keys" ] || {
	#       local last_sentence="$(// delegate -- valid_tail "$repo_urn/keys")"
	#       [ -n "${last_sentence:+x}" ] ||
	#       // die '$repo_urn/keys' "file \"$repo_urn/keys\" is invalid"
	#       IFS=$' ' read -r _ _ target_source \
	#           < <(printf '%s\n' "$last_sentence") > /dev/null || {
	#           cat "$repo_urn/keys"
	#           // die '$repo_urn/keys' "query failed on '$repo_urn/keys'"
	#       }
	#       [ -z "${target_source:+x}" ] || {
	#           target_source="$( \
	#               // delegate -- bicode "code" "$target_source" "REPO_MAIN" "$REPO_MAIN")"
	#           [ -d "$target_source" ] ||
	#           // die '$target_source' "no such package \"$target_source\""
	#       }
	#   }
	# }
	# # Keys design end

	# [ -n "${target_source:+x}" ] ||
	! is_repos "$REPO_BASE/$pkg_name" || target_source="$REPO_BASE/$pkg_name"
	[ -n "${target_source:+x}" ] || {
		# ! is_repos "$REPO_UNDERCONSTRUCTION/$pkg_name" ||
		# target_source="$REPO_UNDERCONSTRUCTION/$pkg_name"

		// log '$target_source' \
			"${target_source:+"${target_source} "}does not exist [$repo_urn] [version issue]"
		printf '\n%s' ""
		# Normal result
		return 1
	}
	// log '$target_source' "$target_source"

	# repo_urn is just a pkg_name
	# set --
	# local repo_user="$(// delegate -- owner "$repo_urn")"
	# [ "$LOGNAME" == "$repo_user" ] ||
	# set -- $(// delegate -- as_user "$repo_user")
	# "$@" rsync -aqzL "$target_source/." --exclude="keys" --exclude="manifest" "$repo_urn/"
	# "$@" sync
	# is_repos "$repo_urn" && [ -f "$repo_urn/version" ] ||
	#   // die '$repo_urn' "'$repo_urn' recover failed"

	printf '\n%s' "$target_source"
}

# We don't dig into repo_dir_decoded for further details
# But we do decode it
# Package version of selected $KISS_PATH
# $1 repo_urn
# $2
# $3 -d / -x
# $4 $KISS_PATH / $sys_db / $PATH
pkg_version() {
	_level_2
	# local repo_urn="${1:?"\"repo_urn\" has to be provided"}"
	local repo_urn="$(realpath "$1" 2>/dev/null || echo -n "$1")"
	local list_type="${2-}"
	local target_type="${3-}"
	local search_dir="${4-}"
	local pkg_name=

	[ -n "${repo_urn:+x}" ] ||
	// die '$repo_urn' "valid value has not been provided"

	{
		[ -n "${repo_urn##*"REPO_MAIN"*}" ] &&
		[ -n "${repo_urn##*"REPO_ROOT"*}" ]
	} ||
		# Decode the url
	repo_urn="$(// delegate -- bicode "code" "$repo_urn" \
		"REPO_MAIN" "$REPO_MAIN" "REPO_ROOT" "$REPO_ROOT")"

	repo_urn="$(standardize "$repo_urn")"
	[ -z "${repo_urn##*"/"*}" ] && pkg_name="${repo_urn##*/}" ||
		pkg_name="$repo_urn"

	pkg_name="${pkg_name%%@*}"

	is_repos "$repo_urn" || {
		# // debug '$pkg_name' "$pkg_name"
		# // debug '$repo_urn' "$repo_urn [input]"
		: "${search_dir:="$KISS_PATH"}"
		// debug '$search_dir' "$search_dir"
		local repo_retrieved="$(// delegate -- repo_trace "$pkg_name" \
				"$list_type" "$target_type" "$search_dir")"

		[ "$repo_retrieved" = "$repo_urn" ] || [ -z "$repo_retrieved" ] || {
			# // debug '$repo_retrieved != $repo_urn' \
			#     "\$repo_urn == '$repo_urn' is mapped to $newline\$repo_retrieved == '$repo_retrieved'"
			repo_urn="$repo_retrieved"
		}
	}

	// log '$repo_urn' "$repo_urn"

	local repo_dir="${repo_urn%/*}"

	local repo_ver=
	local repo_rel=
	local repo_alias=
	local repo_url=
	local reference_type=

	[ -d "$repo_urn" ] || {
		// die '$repo_urn' "'$repo_urn' no such package installed"
		printf "\n%s$FS%s$FS%s$FS%s$FS%s$FS%s" \
			"$repo_dir" "$repo_ver" "$repo_rel" \
			"$repo_alias" "$repo_url" "$reference_type"
		interrupt
	}

	is_repos "$repo_urn" && [ -f "$repo_urn/version" ] || {
		// die '$repo_urn' "\"$repo_urn\" is not a valid package"
		printf "\n%s$FS%s$FS%s$FS%s$FS%s$FS%s" \
			"$repo_dir" "$repo_ver" "$repo_rel" \
			"$repo_alias" "$repo_url" "$reference_type"
		interrupt
	}

	# Look, we just read the repo_ver repo_rel of the current "$repo_urn/version" file
	# Normally we do't dig into some repo_dir_decoded for further details since we have a working repo
	# Otherwise, the performance will be terrible
	IFS=$' ' read -r repo_ver repo_rel \
		repo_alias repo_url reference_type 2>/dev/null \
		< "$repo_urn/version" ||
	// die "$pkg_name" "failed to read $repo_urn/version"

	[ -z "${repo_alias:+x}" ] ||
	[ ! -z "${repo_url:+x}" ] || repo_alias=

	// debug '$repo_dir' "$repo_dir"
	// debug '$repo_ver' "$repo_ver"
	// debug '$repo_rel' "$repo_rel"
	// debug '$repo_alias' "$repo_alias"
	// debug '$repo_url' "$repo_url"
	// debug '$reference_type' "$reference_type"

	# equ "git" "$(// delegate -- pkg_format "$repo_urn")" || {
	printf "\n%s$FS%s$FS%s$FS%s$FS%s$FS%s" \
		"$repo_dir" "$repo_ver" "$repo_rel" \
		"$repo_alias" "$repo_url" "$reference_type"
	return 0
	# }

	# Deprecated
	local repo_dir_decoded=
	local version_is_valid=0

	# [ -n "${repo_alias:+x}" ] ||
	# is_in_main "$repo_urn" ||
	# [ -n "${repo_urn##*"${sys_db}"*}" ] ||
	#     // war '$repo_alias' \
	#         "${repo_alias:+"'${repo_alias}' "}is only in $sys_db"

	local repo_dir=
	[ -z "${repo_alias:+x}" ] || {
		repo_dir_decoded="$( \
			// delegate -- bicode "code" "$repo_alias" "REPO_MAIN" "$REPO_MAIN")"
		// debug '$repo_dir_decoded' "$repo_dir_decoded"
		[ -n "${repo_dir_decoded:+x}" ] ||
		// war '$repo_dir_decoded' "is undefined"
		[ -d "$repo_dir_decoded/$pkg_name" ] ||
		// war '$repo_dir_decoded/$pkg_name' \
			"'$repo_dir_decoded/$pkg_name' directory does not exist"
		is_repos "$repo_dir_decoded/$pkg_name" &&
		repo_dir="$repo_dir_decoded" || {
			version_is_valid=1
			for item in $repo_dir_decoded; do
				is_repos "$item/$pkg_name" || continue
				repo_dir="$item"
				break
			done
			[ -n "${repo_dir:+x}" ] || {
				// war '$repo_dir_decoded' \
					"'$repo_dir_decoded' is not a valid repo and reseted"
			}
			# printf "\n%s$FS%s$FS%s" "$repo_ver" "$repo_rel" "$repo_dir"
			# return 0
			# interrupt
		}
	}

	is_version "$repo_rel" || {
		// war '$repo_rel' "$repo_rel"
		// war "$pkg_name" "release field not found in version file"
		#
		# Keep pkg_version function read-only
		# repo_rel=0
		#
		version_is_valid=1
	}

	is_version "$repo_ver" ||
	# equ "$repo_ver" "git" ||
	{
		// war '$repo_ver' "$repo_ver"
		# equ "git" "$(// delegate -- pkg_format "$repo_urn")" && {
		#     # Highlight will be ruined by wrong line continuation
		#     # Might recursive calling pkg_version itself in remote_sync (could be avoid)
		#     # Remote fetching tags will be extremely slow even no recursive calling (it means an update)
		#     [ -z "${repo_urn:+x}" ] ||
		#     # null "${repo_urn##*"${sys_db}"*}" ||
		#     ! is_writable "$repo_urn" ||
		#     [ ! -d "$SRC_ROOT/$pkg_name" ] ||
		#     # [ -z "${repo_ver:+x}" ] ||
		#     # ok "${repo_ver##*"v"*}" &&
		#     # ok "${repo_ver##*"-"*}" &&
		#     # Just enter for history reason, so don't need to consider real git repos
		#     # [ "git" != "$format" ] ||
		#     # [ "git" != "$repo_ver" ] ||
		#     {
		#         # is_in_main "$repo_urn" || // die 'is_in_main' "did wrong thing"
		#         / "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		#         << $(// here_doc -- remote_sync "$repo_urn")"
		#              2>/dev/null || // die 'remote_sync' "failed"

		#         # is_version "$repo_ver" && is_version "$repo_rel" ||
		#         # / "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		#         # << $(// here_doc -- remote_sync "$repo_urn")"
		#         #     2>/dev/null || // die 'remote_sync' "failed"

		#         # // ver_update "$repo_urn" "$repo_ver" "$repo_rel"

		#         # // density_out "$repo_urn" "${target_source-}"
		#         # // density_out "$repo_urn" "$repo_urn"
		#     }

		#     # repo_ver="git"
		# } ||
		#
		# Keep pkg_version function read-only
		# repo_ver=0
		#
		version_is_valid=1
	}


	! is_writable "$repo_urn" ||
	[ "$version_is_valid" -eq "0" ] ||
	// ver_update "$repo_urn" "$repo_ver" "$repo_rel"

	// debug '$repo_dir' "$repo_dir"
	// debug '$repo_dir_decoded' "$repo_dir_decoded"
	// debug '$repo_ver' "$repo_ver"
	// debug '$repo_rel' "$repo_rel"
	// debug '$repo_alias' "$repo_alias"
	// debug '$repo_url' "$repo_url"
	// debug '$reference_type' "$reference_type"

	printf "\n%s$FS%s$FS%s$FS%s$FS%s$FS%s" \
		"$repo_dir_decoded" "$repo_ver" "$repo_rel" \
		"$repo_alias" "$repo_url" "$reference_type"

}

# Package version of $sys_db
version_installed() {
	_level_2
	local repo_urn
	if ok "$1"; then repo_urn="$1"; else repo_urn="kiss"; fi
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local repo_dir ver rel alias repo_url reference_type
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir ver rel alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn" "" "" "$sys_db")"
		> /dev/null || // die 'pkg_version' "failed"

	// log '$repo_dir' "$repo_dir"
	// log '$ver-$rel' "$ver-$rel"
	// log '$alias' "$alias"
	// log '$repo_url' "$repo_url"
	// log '$branch' "$branch"
}

# Package version details of selected $KISS_PATH
# Output could be "" -- not an integer
# Input $1 repo_ver : package version string
ver_split() {
	_level_2

	# local repo_urn="$1"
	# local list_type="${2-}"
	# local target_type="${3-}"
	# local search_dir="${4-}"

	# local pkg_name="${repo_urn##*/}"
	# pkg_name="${pkg_name%%@*}"
	# is_repos "$repo_urn" || {
	#     ok "$search_dir" || search_dir="$KISS_PATH"
	#     repo_urn="$(// delegate -- repo_trace "$pkg_name" "" "" "$search_dir")"
	# }
	# // debug '$pkg_name' "$pkg_name"

	# # https://stackoverflow.com/questions/2488715/idioms-for-returning-multiple-values-in-shell-scripting
	# / "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel repo_dir \
	#     << $(// here_doc -- pkg_version "$repo_urn" "$list_type" \
	# "$target_type" "$search_dir")"
	# 2> /dev/null || // die 'pkg_version' "failed"
	# ok "$repo_ver" || // die '$repo_ver' "$repo_ver"
	# ok "$repo_rel" || // die '$repo_rel' "$repo_rel"
	# // debug '$repo_ver' "$repo_ver"

	local repo_ver="$1"
	local repo_major= repo_minor= repo_patch= repo_ident= repo_suffix=
	# Split the version on '.+-_' to obtain individual components.
	IFS=/.+-_ read -r repo_major repo_minor repo_patch repo_ident repo_suffix \
		< <(printf '%s\n' "$repo_ver") > /dev/null ||
	// die "printf '%s\\n' \"$repo_ver\"" "failed"
	// debug '$repo_urn' "$repo_urn"
	// debug '$repo_major' "$repo_major"
	// debug '$repo_minor' "$repo_minor"
	// debug '$repo_patch' "$repo_patch"
	// debug '$repo_ident' "$repo_ident"
	// debug '$repo_suffix' "$repo_suffix"

	# [ -z "${repo_major:+x}" ] && repo_major=0 ||
	[ -z "${repo_major:+x}" ] ||
	is_integer "$repo_major" ||
	repo_major="$(// delegate -- extract "is_integer" "$repo_major")"
	# repo_major="$(// delegate -- extract "is_integer" "$repo_major")" ||
	# repo_major=9999

	# [ -z "${repo_minor:+x}" ] && repo_minor=0 ||
	[ -z "${repo_minor:+x}" ] ||
	is_integer "$repo_minor" ||
	repo_minor="$(// delegate -- extract "is_integer" "$repo_minor")"
	# repo_minor="$(// delegate -- extract "is_integer" "$repo_minor")" ||
	# repo_minor=9999

	# [ -z "${repo_patch:+x}" ] && repo_patch=0 ||
	[ -z "${repo_patch:+x}" ] ||
	is_integer "$repo_patch" ||
	repo_patch="$(// delegate -- extract "is_integer" "$repo_patch")"
	# repo_patch="$(// delegate -- extract "is_integer" "$repo_patch")" ||
	# repo_patch=9999

	# [ -z "${repo_ident:+x}" ] && repo_ident=0 ||
	[ -z "${repo_ident:+x}" ] ||
	is_integer "$repo_ident" ||
	repo_ident="$(// delegate -- extract "is_integer" "$repo_ident")"
	# repo_ident="$(// delegate -- extract "is_integer" "$repo_ident")" ||
	# repo_ident=9999

	printf "\n%s$FS%s$FS%s$FS%s$FS%s" \
		"$repo_major" "$repo_minor" "$repo_patch" "$repo_ident" "$repo_suffix"

}

density_out() (
	_level_2
	[ "$#" -ge "3" ] || // die '$#' "not enough parameters gave $# but needs 3"
	local repo_urn="$1"
	local target_source="$2"
	[ -n "${target_source:+x}" ] ||
	target_source="$(// delegate -- repo_trace "$repo_urn" "pure")"

	[ ! -L "$repo_urn" ] ||
	repo_urn="$(readlink -f "$repo_urn")"
	[ ! -L "$target_source" ] ||
	target_source="$(readlink -f "$target_source")"

	local index="${3-}"

	local repo_dir=
	local repo_ver=
	local repo_rel=
	local repo_alias=
	local repo_url=
	local reference_type=

	# shellcheck disable=SC1035
	!!
	# local format="$(// delegate -- pkg_format "$repo_urn")"
	local format= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		format reference_type \
		<< $(// here_doc -- pkg_format "$repo_urn")"
	> /dev/null || { // die 'pkg_format' "failed"; exit 1; }
	^^

	local index_repo_urn=0
	for item in $repo_urn; do
		// debug '$item' "$item"
		: $((index_repo_urn += 1))
	done
	[ "$index_repo_urn" -eq "1" ] || // die '$repo_urn' "\"$repo_urn\" is an array?"
	!!
	# IFS=$' ' read -r repo_ver repo_rel _ 2>/dev/null < "$repo_urn/version" ||
	#     // die "$repo_urn" "failed to read $repo_urn/version"
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir repo_ver repo_rel \
		repo_alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn")"
	> /dev/null || { // die 'pkg_version' "failed"; exit 1; }
	^^
	local scope_origin="$scope"
	local func_name_origin="$func_name"
	length_trim "repo_ver" "$((2 * TABSTOP))"
	length_trim "repo_rel" "$TABSTOP"
	local route=
	local color_parent_origin="$color_parent"
	# local color_child_origin="$color_child"
	# color_child="$color_parent"

	[ -z "${repo_urn:+x}" ] ||
	# [ -n "${repo_urn##*"$sys_db"*}" ] ||
	# { route="<x>"; local color_parent='\033[1;45m'; local color_child='\033[1;07m'; }
	[ -n "${repo_urn##*"$sys_db"*}" ] || { route="<x>"; local color_parent='\033[1;45m'; }
	# [ "$target_source" != "$repo_urn" ] ||
	# { route=">o<"; local color_parent='\033[1;45m'; local color_child='\033[1;07m'; }
	[ "$target_source" != "$repo_urn" ] ||
		[ -z "${repo_urn##*"$sys_db"*}" ] ||
		{ route=">o<"; local color_parent='\033[1;45m'; }


	! equ "$index" "0" || {
		local title='No.'
		local length_index="$((${#title} + 1))"
		local margin_index="$((TABSTOP - length_index))"
		[ "$margin_index" -ge "0" ] || margin_index="$(tabstop_remainder $length_index)"
		// debug '$margin_index' "$margin_index"
		scope='$pkg_name'
		func_name="$( \
			printf "%-${TABSTOP}s %-${margin_index}s%s" 'Format' "" "$title")"
			# A title line (no evaluations)
		// cue "$(printf "%-$((2 * TABSTOP))s %-${MARGIN_ROUTE}s%-${TABSTOP}s" \
			'$ver' "" '$rel')" '$route $repo_urn'
	}

	local length_index="$((${#index} + 1))"
	local margin_index="$((TABSTOP - length_index))"
	[ "$margin_index" -ge "0" ] || margin_index="$(tabstop_remainder $length_index)"
	// debug '$margin_index' "$margin_index"
	scope="${repo_urn##*/}"

	# func_name="$(printf "%-${LENGTH_VER}s %-${TABSTOP}d" "${repo_urn##*/}" "$index")"
	func_name="$(printf "%-${TABSTOP}s %-${margin_index}s%s" "$format" "" "$index")"
	// log "$(printf "%-$((2 * TABSTOP))s %-${MARGIN_ROUTE}s%-${TABSTOP}s" \
		"$repo_ver" "" "$repo_rel")" "${route:+"${route} "}$repo_urn"
	# color_child="$color_child_origin"
	local color_parent="$color_parent_origin"
	func_name="$func_name_origin"
	scope="$scope_origin"
)

valid_tail() (
	_level_2
	local target_file="$1"
	local tail_deep=1
	[ -s "$target_file" ] || // die '$target_file' "'$target_file' is empty"
	local found=
	local lines="$(wc -l "$target_file" | cut -f 1 -d ' ')"
	while [ -z "${found:+x}" ] && [ "$tail_deep" -le "$lines" ]; do
		found="$(tail -n "$tail_deep" "$target_file")"
		: $((tail_deep += 1))
	done
	[ -n "${found:+x}" ] || // die '$target_file' "\"$target_file\" is invalid"
	# Hung up?
	# // log '$found' "'$found'"
	printf '\n%s' "$found"
)

is_repos() (
	_level_2
	local result=0
	local repo_urn
	for repo_urn do
		local not_repo=1

		[ -d "$repo_urn" ] || return "$not_repo"
		# local repo_urn="$1"
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"

		// debug '$repo_urn' "$repo_urn"

		case "$repo_urn" in
			*.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z|*.zip)
				// debug '$repo_urn' "return from tar cases"
				# return 0
				empty "$EXTRACT_ROOT/$pkg_name" ||
				# find "$EXTRACT_ROOT/$pkg_name" -mindepth 1 -delete
				for item in $(// as_own "$EXTRACT_ROOT" \
					find "$EXTRACT_ROOT/$pkg_name" -mindepth 1 -maxdepth 1); do
					# choices folder items won't accept removing by normal users even it's is owned by the normal user
					[ ! -e "$item" ] || [ ! -h "$item" ] ||
					// as "root" \rm -rf "$item";
				done
				// mkcd "$EXTRACT_ROOT/$pkg_name"
				// decompress "$repo_urn" | tar xf -
				repo_urn="$EXTRACT_ROOT/$pkg_name/$db/$pkg_name"

				# continue
		esac

		# [ ! -x "$repo_urn/build" ] ||
		! command -v "$repo_urn/build" > /dev/null 2>&1 ||
		# [ ! -f "$repo_urn/sources" ] ||
		# Recursively calling between is_repos and pkg_format
		# { [ ! -f "$repo_urn/version" ] &&
		# [ "git" != "$(// delegate -- pkg_format "$repo_urn")" ]; } || {
		[ ! -f "$repo_urn/version" ] ||
		{
			// debug '$repo_urn' "return from files check"
			# return 0
			continue
		}
		// debug '$pkg_name' "$pkg_name"
		// debug '$not_repo' "$not_repo"
		return "$not_repo"
	done
	return "$result"
)

# Query package from $REPO_ROOT without being limited by $KISS_PATH
# and install it from the query index (optional)
# $1 repo_urn : package repo url/uri or package  name
# $2 index    : the selected index
pick_up() {
	_level_2
	CROSS_ACTION="pick"
	local index=0
	[ -z "${IS_KISS+x}" ] || {
		trap_print "trap_status" "INT|TERM|QUIT|PIPE|EXIT"
		[ -n "$trap_status" ] || {
			# printf '%s %s\n' 'trap' "definitions at $LINENO"
			// war 'trap' "definitions"
			trap
		}
	}
	# // trap_off

	[ -t 0 ] || { // war 'fd 0' "recovered"; exec </dev/tty; }

	# Final sources
	local install_list=
	# Candidates
	local source_list=
	local indexes_picked=

	# Single target only
	local repo_urn
	local pkg_name
	# $sys_db/$pkg_name
	local repo_target
	# is_mirror "$target_source" "$repo_target" == true
	local target_source
	local mirror_list=

	local deps= makedeps= explicit=

	# trap '' INT TERM QUIT

	key_filter() {
		[ "${1##*/}" = "${2##*/}" ]
	}

	# Just reference by density_out
	# Output  : target_source
	# Input   : pkg_name
	# Input   : source_list
	_mirror_list() {
		_level_2

		local target_source_name="$1"
		local mirror_list_name="$1"
		shift 1
		local pkg_name="$1"
		pkg_name="${pkg_name##*/}"
		local repo_target="$sys_db/$pkg_name"
		local source_list="${2-}"
		local target_source=

		for item in $source_list; do
			is_mirror "$item" "$repo_target" || continue
			target_source="$item"
			// log '$target_source' "$target_source"
			(IFS="$newline" && filter_contains "key_filter" "$target_source" $mirror_list) ||
				mirror_list="${mirror_list:+"${mirror_list}${newline}"}$target_source"
			break
		done

		[ -n "${target_source:+x}" ] &&
		(IFS="$newline" && filter_contains "key_filter" "$target_source" $mirror_list) ||
		[ ! -f "$repo_target/version" ] || {
			local _dir= _ver= _rel= _alias= _url= _reference_type= condidates=
			/ "IFS=$(printf '%b' "$FS") read -r \
			_dir _ver _rel \
			_alias _url _reference_type \
				<< $(// here_doc -- pkg_version "$repo_target" "" "-d" "$sys_db")"
			> /dev/null || // die 'pkg_version' "failed"
			[ -z "$_url" ] || {
				{ [ -n "${_url##*"REPO_MAIN"*}" ] &&
				[ -n "${repo_urn##*"REPO_ROOT"*}" ]; } ||
					_url="$(// delegate -- bicode "code" "$_url" "REPO_MAIN" "$REPO_MAIN")"
				git_sync \
					condidates "$_alias" "$_url" "$_reference_type"
				local item
				for item in $condidates; do
					is_mirror "$item" "$repo_target" || continue
					target_source="$item"
					// log '$target_source' "$target_source"
					(IFS="$newline" && filter_contains "key_filter" "$target_source" $mirror_list) ||
						mirror_list="${mirror_list:+"${mirror_list}${newline}"}$target_source"
					break
				done
			}
		}

		# Keys design begin
		# [ -z "${USE_KEYS:+x}" ] || {
		#     [ -n "${target_source-}" ] ||
		#     [ ! -f "$repo_target/keys" ] || {
		#         local last_sentence="$(// delegate -- valid_tail "$repo_target/keys")"
		#         [ -z "${last_sentence:+x}" ] || {
		#             IFS=$' ' read -r _ _ repo_record < <(printf '%s\n' "$last_sentence") \
		#                 > /dev/null || // die "printf '%s\\n' $last_sentence" "failed"
		#             repo_record="$(// delegate -- bicode "code" "$repo_record" "REPO_MAIN" "$REPO_MAIN")"
		#             [ ! -d "$repo_record" ] || {
		#                 target_source="$repo_record"
		#                 // log '$target_source' "$target_source"
		#             }
		#         }
		#     }
		# }
		# Keys design end
		[ ! -z "${target_source:+x}" ] || // war '$target_source' "'$target_source' not found"
		# ! is_repos "${target_source-}" ||
		# (IFS="$newline" && list_contains "$target_source" $source_list) ||
		# source_list="${source_list:+"${source_list}${newline}"}$target_source"
		# printf '\n%s' "$target_source" > /dev/stdout

		/ "$target_source_name=\"\$target_source\""
		/ "$mirror_list_name=\"\$mirror_list\""
	}

	# For interactive
	# Output: install_list
	_install_list() {
		_level_2
		local indexes_picked="$1"
		local candidate_list="$2"

		local selected_from_index=

		// debug '$indexes_picked' "$indexes_picked"
		// debug '$candidate_list' "$candidate_list"
		local install_source
		local index_iter=-1
		for install_source in $candidate_list; do
			: $((index_iter += 1))
			local pkg_name="${install_source##*/}"
			is_repos "$install_source" || continue

			// debug '$install_source' "$install_source"
			local ifs="$IFS"
			local IFS=$' ,|'
			# [ -z "${indexes_picked##*"a"*}" ] && {
			#   (IFS="$newline" && filter_contains "key_filter" "$install_source" $install_list) || {
			#       install_list="${install_list:+"${install_list}${newline}"}$install_source"
			#       selected_from_index=1

			#       local target_source
			#       // _mirror_list "target_source" "mirror_list" "$pkg_name" "$candidate_list"
			#       // density_out "$install_source" "$target_source" "$index"
			#   }
			# } ||
			# null "$indexes_picked" || [ "$index_iter" != "$indexes_picked" ] || {
			for index in $indexes_picked; do
				equ "$index" "$index_iter" || continue
				# Won't work
				# IFS="$ifs"
				// debug '$indexes_picked' "$indexes_picked"
				// debug '$install_source' "$install_source"
				(IFS="$newline" && filter_contains "key_filter" "$install_source" $install_list) || {
					install_list="${install_list:+"${install_list}${newline}"}$install_source"
					selected_from_index=1

					// _mirror_list "target_source" "mirror_list" "$pkg_name" "$candidate_list"
					// density_out "$install_source" "${target_source-}" "$index"
					break
				}
			done
			# }
			IFS="$ifs"
		done
		# // cue '$install_list' "$install_list"
		# // density_out "$install_list" "$install_list" "$indexes_picked"
		# Could not return a list with $newline as delimiter elegantly
		# printf '\n%s' "$install_list" > /dev/stdout
	}

	check_list() {
		_level_1
		# local
		local install_list=
		local candidate_list="$1"
		local target_source=
		# local indexes_picked=
		local index_valid=0
		local repo_only
		local selected_from_index=

		// log '$SHLVL' "$SHLVL"
		# [ -t 0 ] || { printf '%s %s\n' 'fd 0' "recovered" >> "$INIT_OUTPUT"; exec </dev/tty; }
		# [ -t 1 ] || { printf '%s %s\n' 'fd 1' "recovered" >> "$INIT_OUTPUT"; exec &>/dev/tty; }
		# [ -t 2 ] || { printf '%s %s\n' 'fd 2' "recovered" >> "$INIT_OUTPUT"; exec &>/dev/tty; }
		[ -t 0 ] || { // war 'fd 0' "recovered"; exec </dev/tty; }
		# Will break return values mechanism
		# [ -t 1 ] || { // war 'fd 1' "recovered"; exec &>/dev/tty; }
		# [ -t 2 ] || { // war 'fd 2' "recovered"; exec &>/dev/tty; }

		# // war 'trap' "definitions"
		# trap
		# trap - INT TERM QUIT
		# trap 'exit' INT TERM
		# -- real code moved to documents because it will ruin the data recovery
		# trap 'stty intr <c-\>; exit' INT TERM

		# -- real code moved to documents because it will ruin the data recovery
		# trap 'stty intr <c-\>; exit' INT TERM QUIT

		# trap 'kill -s INT $$' INT TERM
		# trap 'pkill --pgroup 0' INT TERM
		# trap 'printf '%s\n' ""; return 0' EXIT

		# trap ' \
		# ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"; \
		# // kill_name "$CROSS_ACTION" "{kiss}" "${0##*/}"; \
		# ' EXIT

		# trap ' \
		# printf "%s\n" " USR1 triggered "; \
		# // kill_all "{kiss}" "${0##*/}"; \
		# ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"; \
		# ' INT TERM QUIT PIPE

		# exit; \

		# trap " \
		# printf '%s\n' \"USR1 triggered\"; \
		# // debug_filter -- printf '%s %s\n' '\$PID_SAY' \"\${PID_SAY-}\"; \
		# // debug_filter -- printf '%s %s\n' '\$PID_LOG' \"\${PID_LOG-}\"; \
		# // pipe_cancel \"\PID_SAY\"; \
		# // pipe_cancel \"\PID_LOG\"; \
		# " USR1
		# trap "kill_all $@" EXIT
		#         trap " \
		# // pipe_cancel \"\PID_SAY\"; \
		# // pipe_cancel \"\PID_LOG\"; \
		# kill_all kiss; \
		# " EXIT

		# listen
		# trap_print "trap_status" "INT|TERM|QUIT|PIPE|EXIT"
		# [ -n "$trap_status" ] || {
		#     # printf '%s %s\n' 'trap' "definitions at $LINENO"
		#     // war 'trap' "definitions"
		#     trap
		# }

		# trap

		# -- real code moved to documents because it will ruin the data recovery
		# stty intr <c-c>; \
		# stty intr <c-\>; \
		#
		# Only process single target
		local single_target=0

		[ -n "${target_source:+x}" ] || {
			local pkg_name_global=

			local index_iter=-1
			for repo_url in $candidate_list; do
				: $((index_iter += 1))
				local pkg_name="${repo_url##*/}"
				[ "$index_iter" -ne "0" ] || pkg_name_global="$pkg_name"
				[ "$pkg_name" = "$pkg_name_global" ] || { single_target=1; break; }
				# [ "$pkg_name" != "$pkg_name_global" ] &&
				# { single_target=1; break; } || continue
			done

			[ "$single_target" -eq "1" ] || {
				repo_target="$sys_db/$pkg_name_global"

				is_mirror "$target_source" "$repo_target" ||
				// _mirror_list "target_source" "mirror_list" "$pkg_name_global" "$candidate_list"

				! is_repos "$target_source" ||
				(IFS="$newline" && list_contains "$target_source" $candidate_list) ||
				candidate_list="${candidate_list:+"${candidate_list}${newline}"}$target_source"
			}
		}

		# readonly single_target
		[ "$single_target" -ne "1" ] || // die '$single_target' "'$single_target' equals 1 is not the design"

		printf '%s\n' ""
		local repo_url
		local index_iter=-1
		for repo_url in $candidate_list; do
			: $((index_iter += 1))
			local pkg_name="${repo_url##*/}"
			is_repos "$repo_url" || continue
			# Moved to find command
			# {
			#     # Because the package name in depends files is not mutable
			#     # While the folder name assumes the function of the package name
			#     # We don't maintain a pkgname variable in configure files
			#     is_repos "$repo_url/${pkg_name}" && repo_url="$repo_url/${pkg_name}" ||
			#     continue
			# }

			# // war '$indexes_picked' "$indexes_picked"
			# // war '$index_iter' "$index_iter"
			# case "$index_iter" in
			#     $indexes_picked)
			local ifs="$IFS"
			local IFS=$' ,|'
			for index in $indexes_picked; do
				equ "$index" "$index_iter" || continue
				# Won't work
				# IFS="$ifs"
				// debug '$indexes_picked' "$indexes_picked"
				// debug '$repo_url' "$repo_url"
				# null "$indexes_picked" || [ "$index_iter" != "$indexes_picked" ] || {
				(IFS="$newline" && filter_contains "key_filter" "$repo_url" $install_list) ||
				install_list="${install_list:+"${install_list}${newline}"}$repo_url"

				[ "$single_target" -eq "0" ] && is_repos "$target_source" || {
					// _mirror_list "target_source" "mirror_list" "$pkg_name" "$candidate_list"

					! is_repos "$target_source" ||
					(IFS="$newline" && filter_contains "key_filter" "$target_source" $candidate_list) ||
					candidate_list="${candidate_list:+"${candidate_list}${newline}"}$target_source"
				}
				selected_from_index=1
				# }
				break
			done
			# esac
			IFS="$ifs"

			// density_out "$repo_url" "$target_source" "$index_iter"
			# // density_out "$(realpath "$repo_url" 2>/dev/null ||
			# echo -n "$repo_url")" "$target_source" "$indexes_picked"

			repo_only="$repo_url"
			: $((index_valid += 1))

			local repo_dir="${repo_url%/*}"
			local pkg_selected="${repo_url##*/}"

			// debug '$repo_dir' "$repo_dir"
			// debug '$pkg_selected' "$pkg_selected"
		done

		[ -z "${install_list:+x}" ] ||
		[ -z "${selected_from_index:+x}" ] ||
		// cue '$install_list' \
			"listed above came from \$indexes_picked == '$indexes_picked'"

		[ -n "${repo_only:+x}" ] || {
			// war '${repo_only##*/}' "NONE"
			printf '\n%s' "" > /dev/stdout
			return 0
		}

		[ "$index_valid" -ne "1" ] || {
			install_list="$repo_only"
			// cue '$install_list' "came from the only valid element: '$repo_only'"
			# printf '\n%s' "$install_list" > /dev/stdout
			for repo in $install_list; do
				// log 'install_list : repo' "$repo"
			done
			return 0
		}

		# // war 'input' "pause"
		# local answer="$(// delegate -- read_line)"
		# // war 'inputed' "$answer"

		[ -z "${install_list:+x}" ] || {
			# // war '$install_list' "$install_list"
			for repo in $install_list; do
				// log 'install_list : repo' "$repo"
			done
		}

		# local indexes_picked=
		[ -n "${KISS_PROMPT+x}" ] && equ "$KISS_PROMPT" 0 ||
		[ -z "${install_list:+x}" ] ||
		{
			# printf '\n%s' "$install_list" > /dev/stdout;
			for repo in $install_list; do
				// log 'install_list : repo' "$repo"
			done
			return 0;
		}

		# // prompt "indexes_picked" "1. Choose index numbers(devided by space/comma/bar) \
		# // prompt "indexes_picked" "1. Choose index numbers(1 2/1,2/1|2) \
		# ${newline}Or Enter/Ctrl+\\/Ctrl+C for cancel"
		indexes_picked="$( \
		// delegate -- prompt "Choose index numbers(1 2/1,2/1|2) ${newline}\
			Or Enter/Ctrl+C/Ctrl+\\/Ctrl+D+Enter for cancel")"

		local indexes_number="$(// delegate -- extract "is_integer" "$indexes_picked")"
		local indexes_length="${#indexes_number}"
		// log '$indexes_length' "$indexes_length"
		[ "${indexes_length}" -lt "$list_count" ] || {
			// war '$indexes_picked' \
				"${indexes_picked:+"${indexes_picked} "}selected"
			// _install_list "$indexes_picked" "$candidate_list"
			// debug '$install_list' "$install_list"
		}

		# ${newline}2. * for all, \

		# // war '' "1. Choose index numbers(devided by space/comma/bar) \
		# ${newline}2. * for all, \
		# ${newline}Or Enter/Ctrl+\\/Ctrl+C for cancel"
		# Won't work
		# indexes_picked="$(// delegate -- read_line)"

		# read -r indexes_picked </dev/tty
		# readline indexes_picked
		# trap 'kill_all kiss' INT TERM QUIT

		[ -t 0 ] || {
			// war 'fd 0' "does not work"
			# exec </dev/stdin
			exec </dev/tty
		}

		# local control
		# readc control < /dev/tty continue 2> /dev/null

		# [ -t 0 ] || // war 'fd 0' "does not work"
		# [ ! -t 0 ] || {
		#     # stty -g
		#     stty_settings=$(stty -g)
		#     stty -icanon min 1 time 0 || ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		# }
		# -- real code moved to documents because it will ruin the data recovery
		# control='<c-c>'
		# while
		#     # content=$(dd if=/dev/stdin ibs=1 count=1 </dev/stdin continue 2> /dev/null; echo .)
		#     content=$(dd bs=1 count=1 2> /dev/null; echo .)
		#     # content=$(read -r line </dev/stdin continue 2> /dev/null; echo ${line}.)
		#     content=${content%.}
		#     [ -n "$content" ] &&
		#     eval "control=\${control}"'$content
		#     [ "$(($(printf %s "$control" | wc -m )))" -eq 0 ]'; do
		#     continue
		# done
		# [ ! -t 0 ] ||
		# stty $stty_settings || ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		#
		# // war '$control' "$control"
		# -- real code moved to documents because it will ruin the data recovery
		# { equ "$control" '<c-c>' || equ "$control" '<c-\>' || equ "$control" '<enter>' ||
		#     equ "$control" "<c-c><enter>" || equ "$control" "<c-\><enter>"; } && {
		#     # ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		#     # / 'printf %s\n "stty intr \<c-\>"'
		#     // war '$control' "$control"
		#     printf '\n%s' ""
		#     return 0
		#     :
		# } || {
		#     [ ! -t 0 ] || {
		#         stty_settings=$(stty -g)
		#         stty -icanon min 1 time 0 || ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		#         # stty -icanon min 0 time 0
		#     }
		#     # trap 'tput setf 1; tput hold; read; tput init' DEBUG
		#     # local fd=19
		#     while
		#         # set -x
		#         # indexes_picked="$( \
		#         #     # exec 3<&0
		#         #     read -r <&3 line "$fd" continue 3<&0 {fd}< /dev/tty 2> /dev/null ; echo ${line}.
		#         # )"
		#         indexes_picked="$(read -r line </dev/stdin continue 2> /dev/null ; echo "$control${line}.")"
		#         # exec 3<&-
		#         # set +x
		#         # indexes_picked="$(sed 1q)."
		#         [ "${#indexes_picked}" -eq 0 ]; do
		#         continue
		#     done
		#     [ ! -t 0 ] || stty "$stty_settings" || ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		#     indexes_picked="${indexes_picked%.}"
		# } # control charater

		# [ -z "$indexes_picked" ] && {
		#     // check_list "$candidate_list" || :
		#     # printf '\n%s' ""
		#     # return 0
		# } || {
		[ -z "$indexes_picked" ] || {
			local repo_url
			index_iter=-1
			for repo_url in $candidate_list; do
				local pkg_name="${repo_url##*/}"
				: $((index_iter += 1))
				# null "$indexes_picked" && {
				#     install_list="${install_list:+"${install_list}${newline}"}$repo_url"
				#     break
				# }
				local ifs="$IFS"
				local IFS=$' ,|'
				for index in $indexes_picked; do
					equ "$index" "$index_iter" || continue
					(IFS="$newline" && list_contains "$repo_url" $install_list) || {
						install_list="${install_list:+"${install_list}${newline}"}$repo_url"

						[ "$single_target" -eq "0" ] && is_repos "$target_source" ||
						// _mirror_list "target_source" "mirror_list" "$pkg_name" "$candidate_list"

						// density_out "$repo_url" "${target_source-}" "$index_iter"
						break
					}
				done
				IFS="$ifs"
			done
		}

		local indexes_number="$(// delegate -- extract "is_integer" "$indexes_picked")"
		local indexes_length="${#indexes_number}"
		// log '$indexes_length' "$indexes_length"
		# [ ! -z "$install_list" ] ||
		[ "${indexes_length}" -ge "$list_count" ] ||
			// check_list "$candidate_list" || :

		# // prompt "indexes_picked" "Enter if there are no other changes" || :
		# null "$indexes_picked" && break || :
		# // prompt "indexes_picked" "Enter if there are no other changes"
		# // war ''  "Enter if there are no other changes"
		# IFS= read -r indexes_picked </dev/tty

		# } # [ -n "$install_list" ] ||

		# local repo_url
		# local index_iter=-1
		# for repo_url in $install_list; do
		#     : $((index_iter += 1))
		#     // density_out "$repo_url" "${target_source-}" "$index_iter"
		# done

		# [ -n "${KISS_PROMPT+x}" ] && equ "$KISS_PROMPT" 0 ||
		# // prompt "indexes_picked" "Enter if there are no other changes" || :
		# null "$indexes_picked" || // die '$indexes_picked' "cancelled"
		#
		# Could not return a list with $newline as delimiter elegantly
		# printf '\n%s' "$install_list" > /dev/stdout
	}

	pick_up_perfrom() {
		# // trap_on "p" $1
		local repo_url
		for repo_url do
			// cue 'checksum' "$repo_url"
			action="checksum"
			type_include "pkg_checksum" "function" ||
				// die 'function' "'pkg_checksum' is not defined"
			// pkg_checksum  "$repo_url" 2>&1 ||
			// die '$repo_url' "pkg_checksum failed"
		done
		// cue 'build_all' "$deps $makedeps $@"
		action="build"
		# ! // build_all "$deps" "$makedeps" "$repo_url" 2>&1
		// build_all "$deps" "$makedeps" "$@" 2>&1 ||
		// die '$repo_url' "build_all failed"
		# || {
		#     // cue 'pkg_install' "$repo_url"
		#     // log '$repo_url' "$repo_url"
		#     # export KISS_FORCE=; // args "install" "$repo_url" 2>&1 || :
		#     # (export KISS_FORCE=; // args "install" "$repo_url")
		#     if ! equ "$LOGNAME" "root"; then
		#         // subshell_all "install" "$repo_url" 2>&1 || :
		#         // log 'test' "test_04"
		#     else
		#         // pkg_install "$repo_url" 2>&1 || :
		#     fi
		# }
		# done
		# // subshell_all "install" "$@" 2>&1 ||
		// alter "install" "$@" 2>&1 ||
		// die '$@' "'$@'install failed"
	}

	# Initial parameters route
	# Input : package name select index
	# Output : pkg_name, repo_urn, source_list, indexes_picked, part of install_list
	if ok "$1"; then
		# This "$1" is always a package name
		# If you want to pick up init system "66" under index syntax, you could use
		# things like "/var/db/kiss/lm/system/66" as parameter
		# if ok "$1" && ! is_integer "$1"; then
		# pkg_name="${1##*/}"
		repo_urn="$(realpath "$1" 2>/dev/null || echo -n "$1")"
		pkg_name="${repo_urn##*/}"

		if is_repos "$repo_urn"; then
			// log '$pkg_name' "$pkg_name came from \$1 = '$1'"
			install_list="$repo_urn"
			// cue '$install_list' ">o< '$install_list' came from \$1 == '$1' [route 0-0]"
			source_list="$repo_urn"
			# Means the only option
			indexes_picked="$index"

		else

			// log '$pkg_name' "$pkg_name manual inputed"
			repo_target="$sys_db/$pkg_name"
			# "$repo_urn" is not a repo here
			# [ -z "${repo_urn:+x}" ] ||
			# [ -z "${repo_urn##*"${sys_db}"*}" ] ||
			# ! is_mirror "$sys_db/$pkg_name" "$repo_urn" ||
			# target_source="$repo_urn"
			local real_repo_main="$(readlink -fn "${REPO_MAIN}")"
			// log '$real_repo_main' "$real_repo_main"
			source_list="$(// as_own "$REPO_ROOT_DEV/" find -L "$REPO_ROOT_DEV/" \
				\( -type d -o -type l \) -not \( -path "$real_repo_main" -type d -prune \) -name "${pkg_name}")"
			# No interaction, you know the answer
			null "$2" || {
				indexes_picked="${2}"
				// cue 'repo_urn : index' "'$repo_urn' : '$indexes_picked' explicitly given [route 0-0]"
			}
		fi
	elif is_repos "${PWD}"; then
		# If is_repos "${PWD}" == false, giving an integer index doesn't make sense
		# So, "$1" is always a package name or not have any "$1"
		repo_urn="${PWD}"
		pkg_name="${repo_urn##*/}"
		// log '$pkg_name' "$pkg_name came from \$PWD = $PWD"
		install_list="$repo_urn"
		// cue '$install_list' ">o< '$install_list' came from \$PWD == '$PWD' [route 1-0]"
		source_list="$repo_urn"
		# Means the only option
		indexes_picked="$index"
	else
		// war '$PWD' "does not have repo_urn files"
		local item
		for item in $(\ls -1); do
			! is_repos "$item" || pick_up "$item"
		done
		return 0
	fi

	# $explicit_count != $#
	local order= redro=
	# Order the argument list based on dependence.
	/ "IFS=$(printf '%b' "$FS") read -r order redro deps makedeps \
		<< $(// here_doc -- pkg_order "$deps" "$makedeps" "$repo_urn")"
			2> /dev/null || // die 'pkg_order' "failed"

	local index=0
	# Construct integrity
	for item in $order; do
		local dep_name="${item##*/}"
		/ "${pkg_name}_${index}=\"\$dep_name\""
		: $((index += 1))
	done
	local list_count="$index"
	readonly list_count
	// log '$list_count' "$list_count"

	has_integrity() {
		local resut=0
		for index in $(seq 0 1 $((list_count - 1))); do
			(IFS="$newline" && ! / "filter_contains key_filter \${${pkg_name}_${index}} $install_list") || continue
			resut=1
			break
		done
		return $resut
	}

	local color_child_origin="$color_child"
	// debug '$LENGTH_VER' "$LENGTH_VER"
	// debug '$MARGIN_ROUTE' "$MARGIN_ROUTE"

	is_repos "${target_source:+x}" || {
		// _mirror_list "target_source" "mirror_list" "$pkg_name" "$source_list"

		! is_repos "${target_source-}" ||
		(IFS="$newline" && list_contains "$target_source" $source_list) ||
		source_list="${source_list:+"${source_list}${newline}"}$target_source"
	}

	[ -n "${source_list:+x}" ] || {
		// war "$pkg_name" "NONE"
		return 0
	}

	has_integrity ||
		// check_list "$source_list" || :

	local indexes_number="$(// delegate -- extract "is_integer" "$indexes_picked")"
	local indexes_length="${#indexes_number}"
	// log '$indexes_length' "$indexes_length"
	[ "${indexes_length}" -lt "$list_count" ] ||
		// _install_list "$indexes_picked" "$source_list"

	set --
	local repo
	for repo in $install_list; do
		// log '$repo' "$repo"
		REPO_DIR="${REPO_DIR:+"${REPO_DIR}:"}${repo%/*}"
		set -- $@ "$repo"
	done
	// log '$#' "$#"
	[ "$#" -gt "0" ] && is_repos "$@" || return 0

	# // prompt "content" "Pick up the repo_urn shows above?" ||
	# // die '$repo_urn' "'$repo_urn' was cancelled"
	local repo_tips="repo_urn"
	[ "$#" -le "1" ] || repo_tips="repo_urns"
	local content=
	content="$( \
		// delegate -- prompt \
			"Pick up the selected $repo_tips shows above?${newline}\
		Enter for Yes/Ctrl+C|n|N for cancel")" ||
		// die 'prompt' "failed"

	// log '$content' "$content"
	! expr "$content" : '[n|N]\+' > /dev/null || return 0
	export REPO_DIR
	// pick_up_perfrom "$@"
	// log 'test' "test_05"
}

// && [ "$lineno" -eq "$LINENO" ] || // war '$lineno : $LINENO' "$lineno : $LINENO"

# Figure out which repository a package belongs to (repo_urn)
# or print applications in $PATH (executable applications path)
# $1 pkg_name/repo_urn  : might has asterisk mark (*), and works with set +f
# $2 list option        : list_type
#                       : "" for the first one encountered (default)
#                       : "pure" for neither $sys_db nor global $REPO_DIR -- just main repo,
#                       : "all" for repositories,
# $3 shell (test) flag  : target_type
#                       : -d for repo (default)
#                       : -x for executable
# $4 search_dir         :
#                       : $sys_db for installed repo
#                       : $KISS_PATH for package manager recommended repo
#                       : $PATH for executable
# Paths don't have pkg_name
# repo_trace is the semantic. -x is an extension
repo_trace() {
	_level_2
	local repo_urn="$1"
	local list_type="${2-}"
	// debug '$list_type' "$list_type"
	local target_type=
	[ ! -z "${3:+x}" ] &&
	target_type="$3" || {

		[ "pure" = "$list_type" ] && target_type="-d" ||
		[ -z "${4:+x}" ] ||
		case "$4" in
			*"${REPO_ROOT_DEV#*/}"*|*"${REPO_ROOT#*/}"*)
				target_type="-d" ;;
			*"bin"*)
				target_type="-x"
		esac

		[ ! -z "${target_type:+x}" ] ||
			// war '$target_type' "'$target_type' better given explicitly"

		# [ ! -z "${target_type:+x}" ] || target_type="-d"
	}
	// debug '$target_type' "$target_type"
	ok "$list_type" ||
	equ "$target_type" "-x" ||
	repo_urn="$(standardize "$repo_urn")" # pkg_name=${pkg_name%%\*}
	local repo_dir="${repo_urn%/*}"
	# $pkg_name might like kiss-b*/kiss-r*/kiss-i* ...
	local pkg_name="${repo_urn##*/}"
	// debug '$repo_dir' "$repo_dir"
	// debug '$pkg_name' "$pkg_name"
	local search_dir="${4:-"$KISS_PATH"}"

	local repo_result=

	equ "$target_type" "-x" || {
		[ -n "${list_type:+x}" ] ||
		{ ok "$search_dir" &&
			! equ "$search_dir" "$KISS_ROOT/$sys_db"; } ||
		# ! (IFS="$(printf ":")" && list_contains "$KISS_ROOT/$sys_db" $search_dir) ||
		{ ok "$repo_dir" &&
			! equ "$repo_dir" "$KISS_ROOT/$sys_db"; } ||
		# ! (IFS="$(printf ":")" && list_contains "$KISS_ROOT/$sys_db" $repo_dir) ||
		! is_repos "$KISS_ROOT/$sys_db/$pkg_name" || {
			# Suppose that you said: repo_trace $pkg_name "" "" "$sys_db"
			repo_result="$KISS_ROOT/$sys_db/$pkg_name"
			printf '\n%s' "$repo_result"
			return 0
		}
		# local real_path="$(realpath "$4" 2>/dev/null || echo -n "$4")"
		# [ -n "${real_path##*"/"*}" ] || search_dir="$4"
		[ "pure" = "$list_type" ] ||
		# Respect given search_dir
		# [ -n "${search_dir:+x}" ] &&
		[ -n "${search_dir##*":"*}" ] ||
		[ -z "${REPO_DIR:+x}" ] || {
			# [ -z "${search_dir##*"${sys_db}"*}" ] ||
			# search_dir="${search_dir:+"${search_dir}:"}$sys_db"
			local ifs="$IFS"
			local IFS=$':'
			local _dir
			for _dir in $REPO_DIR; do
				[ -z "${search_dir##*"${_dir}"*}" ] ||
				search_dir="${_dir}:${search_dir}"
			done
			IFS="$ifs"
		}
		is_repos "$repo_urn" || repo_dir=
	}

	# Figure out which repository a package belongs to by searching for
	# directories matching the package name in $KISS_PATH/*.
	# set -- "$1" "${2:=""}" "$3" "${4:-"$KISS_PATH"}"
	set -- "$pkg_name" "$list_type" "$target_type" "$search_dir"

	// debug '$@' "$(esceval "$@")"

	local ifs="$IFS"
	local IFS=$':'
	# Iterate over KISS_PATH, grabbing all directories which match the query.
	local dir repo name search_path=
	for dir in $search_dir; do
		[ -d "$dir" ] || continue
		// debug '$dir' "$dir"
		dir="$(readlink -f "$dir")" || // war '$dir' "$dir"
		(IFS=$':' && list_contains "$dir" $search_path) ||
		search_path="${search_path:+"$search_path:"}$dir"
	done
	# Intentional.
	# shellcheck disable=2086
	// debug '$search_dir' "$search_dir"
	// debug '$search_path' "$search_path"
	for dir in $search_path; do
		null "$dir" || {
			dir="$(standardize "$dir")"
			// debug '$dir' "$dir"
		}
		# Expansion will mistake folder name for an implied package name
		set +f
		# if null "$list_type"; then
		# // log '$list_type' "$list_type"
		# $pkg_name might like kiss-b*/kiss-r*/kiss-i* ...
		local repo_list=$dir/$pkg_name
		# Might be a list like "/usr/bin/kiss-bup${newline}/usr/bin/kiss-chroot"
		// debug '$repo_list' "$repo_list"
		IFS=$newline
		for repo in $repo_list; do
			// debug '$repo' "$repo"
			repo="$(standardize "$repo")"
			// debug '$repo' "$repo"
			[ ! -z "${target_type:+x}" ] || {
				[ -d "$repo" ] && target_type="-d" || target_type="-x"
			}
			(IFS="$newline" && list_contains "$repo" "$@") ||
			! test "${target_type:--d}" "$repo" || {
				equ "$target_type" "-x" ||
				null "$repo_dir" || is_mirror "$repo_urn" "$repo" || continue
				# Let's say repo_urn == $PKG_ROOT/var/db/kiss/installed/$pkg_name
				# And repo == $REPO_BASE/$pkg_name
				# or $REPO_MAIN/system/$pkg_name
				set -f -- "$@" "$repo"
				ok "$list_type" || break
			}
		done
		IFS=$':'
		// debug '$#' "$#"
		# else    # ok "$list_type"
		#     // log '$list_type' "$list_type"
		#     IFS=$newline
		#     for name in $(\ls -1 "$dir" 2>/dev/null | \
		#                 grep "$(standardize "$pkg_name")"); do
		#         // debug '$name' "$name"
		#         repo=$dir/$name
		#         repo="$(standardize "$repo")"
		#         // debug '$repo' "$repo"
		#         (IFS="$newline" && list_contains "$repo" "$@") ||
		#         ! test "${target_type:--x}" "$repo" ||
		#             set -f -- "$@" "$repo"
		#     done
		#     IFS=$':'
		#     // debug '$#' "$#"
		# fi
	done
	IFS="$ifs"

	// debug 'search done'
	// debug '$#' "$#"
	// debug '$list_type-$#' "$list_type-$#"

	# Figure out which repository a package belongs to by searching for
	# Show all search results if called from 'kiss search', else store the
	# values in variables. If there are 4 arguments, no package has been found.
	case $list_type-$# in
		*-4)
			equ "$target_type" "-x" || {
				repo_result="$(// delegate -- pkg_base "$pkg_name")"
				[ "$?" -eq "0" ] && is_repos "$repo_result" || {
					repo_result=
					printf '\n%s' "$repo_result"
					return 1    # // die '$pkg_name' "not found"
				}
			}
			;;
		-*) # null "$list_type"
			repo_result="$(standardize "$5")"
			// log '$repo_result' "$repo_result"
			;;
		*)  # ok "$list_type"
			shift 4;
			for item in "$@"; do
				(IFS="$newline" && list_contains "$(readlink -f "$item")" $repo_result) ||
				repo_result="${repo_result:+"${repo_result}$newline"}$item"
			done
			// debug '$applications' "$repo_result"
			# For pkg_help_ext() -- without empty line at the first line
			printf '%s' "$repo_result"
			return 0
	esac

	// debug '$repo_result' "$repo_result"

	printf '\n%s' "$repo_result"
}

list_version() {
	_level_2
	// debug '$#' "$#"
	local repo_urn="${1:-"${PWD##*/}"}"
	// log '$repo_urn' "$repo_urn [input]"

	# List installed packages. As the format is files and directories, this
	# just involves a simple for loop and file read.

	// log '$sys_db' "$sys_db"

	# Optional arguments can be passed to check for specific packages. If no
	# arguments are passed, list all.
	if null "$repo_urn"; then
		set +f; set -f -- "$sys_db"/*
	else
		set -- "$repo_urn"
	fi
	# Loop over each package and print its name and version.
	local index=0
	for repo_urn do
		// log '$repo_urn' "$repo_urn [output]"
		local pkg_name="${repo_urn##*/}"
		local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
		/ "IFS=$(printf '%b' "$FS") read -r \
			repo_dir repo_ver repo_rel \
			repo_alias repo_url reference_type \
			<< $(// here_doc -- pkg_version "$repo_urn" "" "" "$sys_db")"
			> /dev/null || // die 'pkg_version' "failed"
		# // log "${repo_urn}" "$repo_ver-$repo_rel"
		// density_out "$repo_urn" "$repo_dir/$pkg_name" "$index"
		# // density_out "$repo_urn" "${target_source:-"$repo_urn"}" "$index"
		: $((index += 1))
	done
}

# Should be subshell function
# How to use:
# local tar_file="$(// delegate -- pkg_cache "$repo_urn")"
# $1 repo_urn : package repo url/uri
pkg_cache() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	// log '$TAR_ROOT' "$TAR_ROOT"

	# Find the tarball of a package using a glob. Use the user's set compression
	# method if found or first match of the below glob.

	local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir repo_ver repo_rel \
		repo_alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn")"
		> /dev/null || // die 'pkg_version' "failed"

	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"

	set +f -- "${TAR_ROOT}/${pkg_name}/${pkg_name}@${repo_ver}-${repo_rel}.tar."
	set -f -- "${1}$KISS_COMPRESS" "${1}"*

	local tar_file=""

	// log '$1' "$1"
	// log '$2' "$2"

	# If the first match does not exist, use the second. If neither exist,
	# this function returns 1 and the caller handles the error.
	if [ -f "$1" ]; then
		tar_file="$1"
	elif [ -f "$2" ]; then
		tar_file="$2"
	else
		// log '$tar_file' "for \"$repo_urn\" is going to be built"
	fi

	// debug '$1' "$1"
	// debug '$2' "$2"
	// debug '$tar_file' "$tar_file"

	printf '\n%s' "$tar_file"
}

is_archive() {
	# local archive_local="$ARCHIVE_ROOT/$pkg_name/${dest:+"$dest/"}$src_name"
	local archive_local="$1"
	# local archive_local_res_type="file"
	local target_is_archive=1
	case "$archive_local" in
		*.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z|*.zip)
			# archive_local_res_type="archive"
			target_is_archive=0
	esac
	return $target_is_archive
}

# Given a route of the input from a sources file single line with parameters (src_url)
# to a designated target folder name (dest), translate parameters and return
# an absolute directory (_local_dir) and a target name (_target_name) pointed
# to the local resource as if they're already there -- "you'd better do it that way"
# -- errors come out if not.
# Input
# $1 repo_urn  : package repo url/uri
# $2 src_url   : source link (in sources file)
# $3 dest      : destination / source folder name (in sources file)
# $4 action
# How to use
# IFS=$(printf '%b' "$FS") read -r _local_dir _res_type _res _target_name \
#     < <(// delegate -- local_route "$repo_urn" "$src_url" "$dest" \
#         "$action") > /dev/null || // die 'local_route' "failed"
# / "IFS=$(printf '%b' "$FS") read -r _local_dir _res_type _res _target_name \
#     << $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest" "$action")"
# > /dev/null || // die 'local_route' "failed"
# Output
# _local_dir    : target file/folder parent directory
# _res_type     : resource type
# _res          : local source or remote url
# _target_name  : target file/folder name
local_route() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	ok "$repo_urn" || // die '$repo_urn' "$repo_urn"
	local src_url="$2"
	local dest="$3"
	local action="${4-}"
	# real_url     : reemote source url / local relative location
	# _res is the final url ("l" stands for location)
	local _res_type= _res= _target_name= _local_dir= real_url=

	ok "${2%%\#*}" || {
		printf "\n%s$FS%s$FS%s$FS%s" "" "" "" ""
		return 0
	}

	local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir repo_ver repo_rel \
		repo_alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn")"
	> /dev/null || // die 'pkg_version' "failed"

	local repo_major= repo_minor= repo_patch= repo_ident= repo_suffix=
	/ "IFS=$(printf '%b' "$FS") read -r repo_major repo_minor \
	repo_patch repo_ident repo_suffix \
		<< $(// here_doc -- ver_split "$repo_ver")"
	> /dev/null || // die 'ver_split' "failed"

	// debug '$repo_major' "$repo_major"
	// debug '$repo_minor' "$repo_minor"
	// debug '$repo_patch' "$repo_patch"
	// debug '$repo_ident' "$repo_ident"
	// debug '$pkg_name' "$pkg_name"

	: "${ARCH:="${KISS_XHOST_ARCH}"}"
	# [ -n "${ARCH:+x}" ] || // die '$ARCH' "${ARCH:+"${ARCH} "}must be defined"
	// log '$ARCH' "$ARCH"
	local real_url="$src_url"
	case "$src_url" in
		*"REPO_MAIN"*|*"ARCH"*|*"VERSION"*|*"RELEASE"*|*"MAJOR"*|*"MINOR"*|*"PATCH"*|*"IDENT"*|*"PACKAGE"*)
			real_url="$(// delegate -- bicode "code"  \
					"${src_url%"${src_url##*[!/]}"}"  \
					"REPO_MAIN" "$REPO_MAIN"          \
					"ARCH"      "$ARCH"               \
					"VERSION"   "$repo_ver"           \
					"RELEASE"   "$repo_rel"           \
					"MAJOR"     "$repo_major"         \
					"MINOR"     "$repo_minor"         \
					"PATCH"     "$repo_patch"         \
					"IDENT"     "$repo_ident"         \
					"PACKAGE"   "$pkg_name")"
	esac
	// log '$real_url/uri' "$real_url"

	set -- "$pkg_name" "$real_url" "${3%"${3##*[!/]}"}" "${4-}"

	pkg_name="$1"
	src_url="$2"
	dest="$3"
	action="$4"

	local src_name="${src_url##*/}"
	src_name="${src_name%\?*}"

	# local src_current="${src_name%%-"$repo_ver"*}"
	# src_current="${src_current%%"$repo_ver"*}"
	# src_current="${src_current%%[@\#]*}"
	# [ -n "$src_current" ] || {
	#     src_current="$pkg_name"
	# }
	# local _des_name=$src_current
	# case $src_url in
	#     git+*)
	#         ;;

	#     *.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z)
	#         // log '$dest' "$dest"
	#         # // mkcd "$MAKE_ROOT/$pkg_name/${_local_dir##*/}"
	#         local head=${src_name%.t??*}
	#         local tail=${src_name##$head}
	#         src_current=$src_current-$repo_ver$tail
	#         ;;

	#     *?*)
	#         ;;
	# esac
	# // log '$src_current' "$src_current"

	local src_dir="$SRC_ROOT/$pkg_name"
	local make_dir="$MAKE_ROOT/$pkg_name"

	local archive_local="$ARCHIVE_ROOT/$pkg_name/${dest:+"$dest/"}$src_name"

	# Remote source files which have been cached to local archives.
	# AKA local archive files
	# They don't must is an archive, they just normally has $dest and
	# it means that they don't want to polute the main repo if possible
	# Find reference in llvm/sources (config.guess)
	if [ -f "$archive_local" ] && is_archive "$archive_local"; then
		_res_type="archive"
		_res="$archive_local"
		_target_name="."
		_local_dir="$src_dir${dest:+"/$dest"}"

	# Git repository. Branch/tag name might in _res
	elif null "${src_url##git+*}"; then
		_res_type="git"
		_res="${src_url##"$_res_type+"}"
		_target_name="."
		# _local_dir=$SRC_ROOT/$pkg_name/${dest:-"$src_name"}
		# _local_dir=${_local_dir%[@#]*}/.
		_local_dir="$src_dir${dest:+"/$dest"}"

	# How to judge the content under src's subfolder is valid or not ?
	# # Remote source dir (cached).
	# elif [ -d "$SRC_ROOT/$pkg_name/${dest:+"$dest/"}$src_current" ]; then
	#     _res=$SRC_ROOT/$pkg_name/${dest:+"$dest/"}$src_current
	#     _target_name="."
	#     _local_dir=$SRC_ROOT/$pkg_name/${dest:+"$dest/"}$src_current

	# Remote source archive/files.
	elif null "${src_url##*://*}"; then
		_res_type="url"
		# _res="url+$src_url"
		_res="$src_url"
		_target_name="$src_name"
		_local_dir="$ARCHIVE_ROOT/$pkg_name${dest:+"/$dest"}"

		[ -f "$archive_local" ] &&
		! is_archive "$archive_local" &&
		[ ! -z "${KISS_FORCE+x}" ] && {
			_res_type="absolute_file"
			_res="$archive_local"
			_target_name="$src_name"
			# Don't polute the $src_dir
			# _local_dir="$src_dir${dest:+"/$dest"}"
			_local_dir="${_res%/*}"
		}

	# Local relative dir.
	# "$repo_urn/patches folder dest_dir"
	# "$repo_urn/files   folder dest_dir"
	elif [ -d "$repo_urn/$src_url" ]; then
		_res_type="relative_dir"
		_res="$repo_urn/$src_url"
		_target_name="."
		_local_dir="$_res"

	# Local absolute dir.
	elif [ -d "/${src_url##/}" ]; then
		_res_type="absolute_dir"
		_res="/${src_url##/}"
		_target_name="."
		_local_dir="$_res"

	# Local relative file (/repo_urn/files/filename).
	# "$repo_urn/patches/00.patch file dest_dir"
	# "$repo_urn/files/01.txt     file dest_dir"
	elif [ -f "$repo_urn/$src_url" ]; then
		_res_type="relative_file"
		_res="$repo_urn/$src_url"
		# _target_name="${_res##*/}"
		_target_name="$src_name"
		_local_dir="${_res%/*}"

	# Local absolute file (/files/filename).
	elif [ -f "/${src_url##/}" ]; then
		_res_type="absolute_file"
		_res="/${src_url##/}"
		# _target_name="${_res##*/}"
		_target_name="$src_name"
		_local_dir="${_res%/*}"

	else
		// die "$pkg_name" "No local file '$src_url'"
	fi

	// log '$action' "$action"
	// log '$_res_type' "$_res_type"

	ok "$action" || // log '$_res' "$_res"

	// log '$_target_name' "$_target_name"
	// log '$_local_dir' "$_local_dir"
	// log '$action' "$action"

	printf "\n%s$FS%s$FS%s$FS%s" \
		"$_local_dir" "$_res_type" "$_res" "$_target_name"
}

# Download any remote package sources. The existence of local files is
# also checked.
# $1 repo_urn  : package repo url/uri
# $2 action    : action name
pkg_download() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local pkg_name_string="$(echo "$pkg_name" | sed -e 's/-/_/g' -e 's/./_/g')"
	is_repos "$repo_urn" ||
	repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	local action="${2-}"

	// log '$pkg_name' "$pkg_name"
	// log '$action' "$action"

	// debug '$repo_urn' "$repo_urn"

	# Support packages without sources. Simply do nothing.
	[ -f "$repo_urn/sources" ] ||
	{ // war 'sources' "'$repo_urn/sources' does not exist"; return 0; }

	// log "$pkg_name" "reading sources"

	local src_dir="$SRC_ROOT/$pkg_name"
	// mkcd "$src_dir"

	while read -r src_url dest || ok "${src_url%%\#*}"; do
		ok "${src_url%%\#*}" || continue
		// log '$src_url' "$src_url"
		// log '$dest' "$dest"
		/ "IFS=$(printf '%b' "$FS") \
		read -r _local_dir _res_type _res _target_name \
			<< $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest" \
			"$action")"
		> /dev/null || // die "local_route" "failed"

		// log '$_res_type' "$_res_type"
		// log '$_res' "$_res"
		// log '$_local_dir' "$_local_dir"

		# arg1: pre-source
		# arg2: package name
		# arg3: verbatim source
		# arg4: resolved source
		// run_hook pre-source "$pkg_name" "$src_url" "$_res"

		# '$2' is set when this function is called from 'kiss c' and it is used
		# here to skip calling the Git code.
		# local _res_type="${_res%%+*}"
		# // log '$_res_type' "$_res_type"

		local repo_ver= repo_rel=

		# If the Internet won't work temporarily, use the local sources
		[ -n "${KISS_FORCE+x}" ] &&
		! empty "$_local_dir" &&
		{
			[ "git" = "$_res_type" ] ||
			{
				[ "url" = "$_res_type" ] &&
				{
					equ "$_target_name" "." ||
					[ -s "$_local_dir/$_target_name" ]
				}
			}
		} ||
		# Did the same check in download_git(). Because the
		# git rev-parse --is-inside-work-tree
		# will be cheated by upper directory git repos
		case ${action}$_res_type in
			"${action}archive")
				# / "IFS=$(printf '%b' "$FS") \
				# read -r _local_dir _res_type _res _target_name \
				# << $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest" \
				#   "$action")"
				# > /dev/null || // die "local_route" "failed"

				# // log '$_res_type' "$_res_type"
				# // log '$_res' "$_res"
				# // log '$_local_dir' "$_local_dir"

				# case $_res in
				#   *.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z|*.zip)
				#       [ -f "$_res" ] || // die "$_res" "is not locally ready"
				#       # Moved to pkg_load()
				#       // extract_tar "$pkg_name" "$_local_dir" "$_res"
				# esac

				/ "export synchronized_${pkg_name_string}=1"

				;;
			"${action}url")
				# git source version might have changed by current design
				# case $_res in "url+"*|"git+"*)
				// log "download_url" "beginning"
				# For download_url and download_git
				local tar_file="$(// delegate -- download_url "$pkg_name" "$_local_dir" "$_res")"

				# / "IFS=$(printf '%b' "$FS") \
				# read -r _local_dir _res_type _res _target_name \
				# << $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest" "$action")"
				# > /dev/null || // die "local_route" "failed"

				# // log '$_res_type' "$_res_type"
				# // log '$_res' "$_res"
				# // log '$_local_dir' "$_local_dir"

				# case $_res in
				#   *.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z|*.zip)
				#       # Moved to pkg_load()
				#       // extract_tar "$pkg_name" "$_local_dir" "$tar_file"
				# esac

				/ "export synchronized_${pkg_name_string}=1"

				;;
			"git")
				/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
				<< $(// here_doc -- download_git "$repo_urn" "$_local_dir" "$_res")"
				2>/dev/null || // die "download_git" "failed"

				/ "export synchronized_${pkg_name_string}=1"

				;;
			"${action}git")
				/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
				<< $(// here_doc -- remote_sync "$repo_urn" "1" "$_local_dir" "$_res")"
				2>/dev/null || // die 'remote_sync' "failed"

				# IFS="$(printf '%b' "$FS")" read -r repo_ver repo_rel \
				#     < <(// delegate -- remote_sync "$repo_urn" "1" "$_local_dir" \
				#         "$_res") 2>/dev/null || // die 'remote_sync' "failed"

				// log '$repo_ver' "$repo_ver"
				// log '$repo_rel' "$repo_rel"

				/ "export synchronized_${pkg_name_string}=1"
		esac

		[ -z "${KISS_FORCE+x}" ] ||
		[ -n "$(/ echo \${synchronized_${pkg_name_string}-})" ] ||
		case ${action}$_res_type in
			"${action}git")
				# IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
				#     < <(// delegate -- remote_sync "$repo_urn" "" "$_local_dir" \
				#         "$_res") 2>/dev/null || // die 'remote_sync' "failed"

				/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
				<< $(// here_doc -- remote_sync "$repo_urn" "" "$_local_dir" "$_res")"
				2> /dev/null || // die 'remote_sync' "failed"

				# / "IFS=$(printf '%b' "$FS") \
				#     read -r test_local_dir test_res_type test_res test_target_name \
				#     << $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest" \
				#     "$action")"
				# > /dev/null || // die "local_route" "failed"

				# // log '$test_res_type' "$test_res_type"
				# // log '$test_res' "$test_res"
				# // log '$test_target_name' "$test_target_name"
				# // log '$test_local_dir' "$test_local_dir"
				// log '$repo_ver' "$repo_ver"
				// log '$repo_rel' "$repo_rel"
		esac

		[ -n "${src_url##*"$pkg_name"*}" ] ||
		[ "$_res_type" != "git" ] || {
			local repo_dir= ver= rel= repo_alias= repo_url= reference_type=
			/ "IFS=$(printf '%b' "$FS") read -r \
				repo_dir ver rel dir \
				repo_alias repo_url reference_type \
				<< $(// here_doc -- pkg_version "$repo_urn")"
			2> /dev/null || { // die 'pkg_version' "failed"; exit 1; }
			// log '$ver' "$ver"
			// log '$rel' "$rel"

			[ "$ver" = "$repo_ver" ] &&
			[ "$rel" = "$repo_rel" ] ||
			# [ "$rel" == "$repo_rel" ] &&
			# [ "$dir" == "$repo_dir" ] ||
			// ver_update "$repo_urn" "$repo_ver" "$repo_rel"
		}

		# arg1: post-source
		# arg2: package name
		# arg3: verbatim source
		# arg4: resolved source
		// run_hook post-source "$pkg_name" "$src_url" "$_local_dir/$_target_name"
	done < "$repo_urn/sources"
}

download_url() {
	_level_1
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	shift 1
	local _local_dir="$1"
	local _res="$2"
	local src_name="${_res##*/}"
	src_name="${src_name%\?*}"

	// log '$_local_dir' "$_local_dir"
	// log '$_res' "$_res"
	# Let's say: libdrm-2.4.116.tar.xz
	// log '$src_name' "$src_name"

	// mkcd "$_local_dir"

	// log '$pkg_name' "$pkg_name"
	local download_impl="${cmd_get##*/}"
	// log '$download_impl' "$download_impl"
	# Set the arguments based on found download utility.
	case $download_impl in
		aria2c|axel) set -- -o   "$_local_dir/$src_name" "$_res" ;;
			   curl) set -- -fLo "$_local_dir/$src_name" "$_res" ;;
		 wget|wget2) set -- -O   "$_local_dir/$src_name" "$_res" ;;
	esac

	# Opening output file $_local_dir/$src_name
	# Error opening local file
	# /usr/bin/kiss: line 1198: -o: not found

	// log '$LOGNAME' "$LOGNAME"
	# axel on www.netfilter.org
	# ERROR 403: Forbidden.
	"$cmd_get" "$@" || {
		rm -f "$_local_dir/$src_name"
		! equ "$download_impl" "axel" || {
			// war "$download_impl" "Failed to download $_res"
			cmd_get="$( \
				command -v /usr/bin/wget   ||
				command -v /usr/bin/wget2  ||
				command -v /usr/bin/curl   ||
				command -v /usr/bin/aria2c
			)" || // die 'download utility' "not found (curl, wget, wget2)"
			# // download_url "$pkg_name" "$_local_dir" "$_res"
			download_impl="${cmd_get##*/}"
			case $download_impl in
				aria2c)     set -- -o   "$_local_dir/$src_name" "$_res" ;;
				curl)       set -- -fLo "$_local_dir/$src_name" "$_res" ;;
				wget|wget2) set -- -O   "$_local_dir/$src_name" "$_res" ;;
			esac
			"$cmd_get" "$@" || {
				\rm -f "$_local_dir/$src_name"
				// die "$download_impl" "Failed to download $_res"
			}
		}
	}
	[ -f "$_local_dir/$src_name" ] ||
		// die '$_local_dir/$src_name' "'$_local_dir/$src_name' download failed"
	printf '\n%s' "$_local_dir/$src_name"
}

remote_sync() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	// log '$pkg_name' "$pkg_name"
	// log '$repo_urn' "$repo_urn"
	shift 1
	local force_fetch
	if [ "$#" -ge "1" ]; then
		force_fetch="$1"
		shift 1
	else
		force_fetch=
	fi
	local _local_dir
	local _res
	if [ "$#" -ge "2" ]; then
		local _local_dir="$1"
		local _res="$2"
	else
		local src_url dest
		while read -r src_url dest || ok "${src_url%%\#*}"; do
			ok "${src_url%%\#*}" || continue

			local key="${pkg_name%%-*}"
			null "${src_url##*"$key"*}" || continue

			// log '$src_url' "$src_url"
			// log '$dest' "$dest"

			/ "IFS=$(printf '%b' "$FS") read -r _local_dir _ _res _ \
				<< $(// here_doc -- local_route "$repo_urn" "$src_url" \
				"$dest" "$action")"
			> /dev/null || // die "local_route" "failed"

			// log '$_res' "$_res"
			// log '$_local_dir' "$_local_dir"

			break
		done < "$repo_urn/sources"
	fi

	ok "$_local_dir" ||
	// die '$_local_dir' "can not figure out \$_local_dir of \"$pkg_name\""

	// log '$SRC_ROOT' "$SRC_ROOT"
	// log '$SRC_USER' "$SRC_USER"

	set --
	equ "$LOGNAME" "$SRC_USER" ||
	set -- $(// delegate -- as_user "$SRC_USER")

	# Remove "/."
	// log '$_local_dir' "$_local_dir"

	// mkcd "$_local_dir"

	local url="${_res%[\#@]*}"
	# url="${url%.git}.git"

	// log '$url' "${url}"
	// log '$PWD' "$PWD"

	# Might be empty
	local upstream_name=
	[ -n "${_res##*[@\#]*}" ] || upstream_name="${_res##*[@\#]}"
	local target=
	// log '$upstream_name' "$upstream_name"
	# [ "$("$@" git -C "$_local_dir" rev-parse --is-inside-work-tree 2>/dev/null)" = "true" ] &&
	# ! empty "$_local_dir" || {
	#     "$@" find "$_local_dir" -mindepth 1 -delete
	#     "$@" git clone --recursive --depth 1 "${url}" "$_local_dir" ||
	#     "$@" git clone --branch "$target" "${url}" "$_local_dir" 2>/dev/null ||
	#     // die "git clone --recursive --depth 1 \"${url}\" \"$_local_dir\"" "failed"
	# }
	# null "$force_fetch" || "$@" git fetch --tags --prune

	# target="$("$@" git describe --tags $("$@" git rev-list --tags --max-count=1))"
	# "$target" is the tag or branch name
	/ "IFS=$(printf '%b' "$FS") read -r reference_type target \
		<< $(// here_doc -- track_type \
			"$upstream_name" "$_local_dir" "$url" "$force_fetch")"
		> /dev/null || // die 'track_type' "failed"

	// log '$reference_type' "$reference_type"
	// log '$target' "$target"

	local repo_ver=
	local repo_rel=0

	/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		<< $(// here_doc -- synchronize "$reference_type" \
		"$target" "$_local_dir" "$url" "$force_fetch")"
	> /dev/null || // die 'synchronize' "failed"

	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"

	# Might be illigal values
	# is_version "$repo_ver" || // die '$repo_ver' "${repo_ver:+"${repo_ver} "}got wrong value"
	# is_version "$repo_rel" || // die '$repo_rel' "${repo_rel:+"${repo_rel} "}got wrong value"

	printf "\n%s$FS%s" "$repo_ver" "$repo_rel"
}

# /mnt/init/editor/vim/pack/packager/start/vim-clap/install.sh
remote_tag() {
	local latest_tag
	local url="$1"
	local upstream_name="${2-}"

	[ -n "${UNUSE_LATEST_TAG:+x}" ] || upstream_name=

	set --
	equ "$LOGNAME" "$SRC_USER" ||
	set -- $(// delegate -- as_user "$SRC_USER")
	# git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags "$url" 'v0.*'
	# git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags "$url" refs/tags/*"${upstream_name}"* | awk -F "/" '{print $NF}'
	# git -c 'versionsort.suffix=-' ls-remote --exit-code --refs --sort='version:refname' --tags "$url" | grep "${upstream_name}" | awk -F "/" '{print $NF}'

	# Fro linux kernel
	# e42df5dc5f39a088f3611d9f09619f53dd6d3a5d        refs/tags/v6.5-rc6
	local tag_list=
	tag_list="$( \
		"$@" git -c 'versionsort.suffix=-' ls-remote --exit-code --refs \
		--sort='version:refname' --tags "$url" 2> /dev/null |
		awk '{print $2}' || {
			# awk 'BEGIN{ FS = "/" } {print $NF}' 2> /dev/null || {
			"$@" git config --local --unset remote.origin.tagopt > /dev/null 2>&1
			"$@" git config --local --unset remote.origin.fetch > /dev/null 2>&1
			"$@" git config --local remote.origin.fetch \
				"+refs/heads/*:refs/remotes/origin/*" > /dev/null 2>&1
			# local result="$( \
			"$@" git -c 'versionsort.suffix=-' ls-remote --exit-code --refs \
				--sort='version:refname' --tags "$url" 2> /dev/null |
				awk '{print $2}'
				# awk 'BEGIN{ FS = "/" } {print $NF}' 2> /dev/null
			# )"
			# printf '%s' "$result"
		}
	)"

	[ -z "${upstream_name:+x}" ] ||
		tag_list="$(printf '%s\n' "$tag_list" |
				grep "$upstream_name")"

	latest_tag="$( \
		printf '%s' "$tag_list" | tail -n 1
		# tail -n 1 |
		# awk -F "/" '{print $NF}'
	)"
	printf '\n%s' "$latest_tag"
}

# Determine <latest tag name>/<branch name> at this function
# Never has tried to modify local resource
# upstream_name  : "$1"
# _local_dir     : "$2"
# url            : "$3"
# force_fetch    : "$4"
track_type() {
	_level_2
	local upstream_name="$1"
	local _local_dir="$2"
	local url="$3"
	[ -n "${url:+x}" ] || // die '$url' "\"$url\" is invalid"
	shift 3
	local force_fetch
	if [ "$#" -ge "1" ]; then
		force_fetch="$1"
		shift 1
	else
		force_fetch=
	fi
	local reference_type=
	local target=
	// log '$SRC_USER' "$SRC_USER"
	set --
	equ "$LOGNAME" "$SRC_USER" ||
	# set +f -- $(// delegate -- as_user "$SRC_USER")
	set -- $(// delegate -- as_user "$SRC_USER")
	# [ "$#" -eq "0" ] ||
	// log 'set privilege' "$(esceval "$@")"

	[ "$PWD" = "$_local_dir" ] || {
		[ -d "$_local_dir" ] || "$@" \mkdir -p "$_local_dir"
		// cd "$_local_dir" || // die 'failed to cd to' "$_local_dir"
	}

	inner_query_tag() {
		// log '$url' "$url"
		// log '$force_fetch' "$force_fetch"
		// log '$SRC_USER' "$SRC_USER"
		local result=0
		# set +f --
		# set --
		# equ "$LOGNAME" "$SRC_USER" ||
		# # set +f -- $(// delegate -- as_user "$SRC_USER")
		# set -- $(// delegate -- as_user "$SRC_USER")
		# [ "$#" -eq "0" ] ||
		// log 'set privilege' "$(esceval "$@")"

		[ -n "${PREFER_TAG+x}" ] || { result=1; return $result; }

		reference_type="tag"

		# Whatever, local codebase must exist
		[ "$("$@" git -C "$_local_dir" rev-parse \
				--is-inside-work-tree 2>/dev/null)" == "true" ] &&
		! empty "$_local_dir" || {

			# "$@" find "$_local_dir" -mindepth 1 -delete

			target_ref="$(// delegate -- remote_tag "$url" "$upstream_name")"
			target="$(printf '%s' "$target_ref" | awk 'BEGIN{ FS = "/" } {print $NF}' 2> /dev/null)"

			# [ -n "${target_ref:+x}" ] && {
			#   // fetch_tag "$target" "$url"
			# }
			[ -n "${target_ref:+x}" ] || {
				reference_type="branch"
				result=1
				return $result
			}
		}

		# Query remote tags if $upstream_name given
		# Merged into remote_tag()
		# null "$force_fetch" ||
		# [ -n "${UNUSE_LATEST_TAG:+x}" ] ||
		# [ -z "${upstream_name:+x}" ] ||
		# for item in $("$@" git ls-remote "${url}" --tags \
		#             "refs/tags/*"${upstream_name}"*" | awk '{print $2}'); do
		#     // log 'check target with $upstream_name' "$upstream_name"
		#     [ -n "${item:+x}" ] || continue
		#     [ -z "${item##*"${upstream_name}"*}" ] || continue
		#     target="${item##"refs/tags/"}"
		#     // log '$target' "$target"
		#     break
		#     return 0
		# done

		ok "$("$@" git -P tag 2>&1)" ||
		null "$force_fetch" || {
			target_ref="$(// delegate -- remote_tag "$url" "$upstream_name")"
			target="$(printf '%s' "$target_ref" | awk 'BEGIN{ FS = "/" } {print $NF}' 2> /dev/null)"
			# Might be neovim::v0.9.1

			[ -n "${target:+x}" ] || {
				reference_type="branch"
				result=1
				return $result
			}

			// log '$reference_type' "$reference_type"
			// log '$target' "$target"
		}

		# ok "$("$@" git -P tag 2>&1)" ||
		# # Time consuming operation
		# # "$@" git fetch --all --tags --prune
		# # null "$force_fetch" ||
		# {
		#   // log 'fetch' "refs/tags/$target"
		#   // fetch_tag "$target" "$url"
		# }

		# https://stackoverflow.com/questions/21439488/find-latest-git-tag-from-the-remote-git-repository
		# Leaving ^0 at the end of tags
		# target="$("$@" git rev-list --tags --timestamp \
		# --no-walk | sort -nr | head -n1 | cut -f 2 -d ' ' | \
		# xargs "$@" git describe --contains)"
		# https://stackoverflow.com/questions/1404796/how-can-i-get-the-latest-tag-name-in-current-branch-in-git
		# local target_local="$("$@" git tag -l | sort | tail -n 1)"
		local target_local=
		# Will get Neovim nightly
		target_local="$("$@" git describe --tags \
				"$("$@" git rev-list --tags --max-count=1)"
		)" || // war 'woops' "not a tag type repo"

		local repo_ver_local= repo_rel_local=
		[ -n "${target_local:+x}" ] && {
			for item in $(
				"$@" git tag -l | sort -V -r); do target_local="$item"
				break; done
			# target_local="$("$@" git tag -l | sort | tail -n 1)"
			#
			/ "IFS=$(printf '%b' "$FS") read -r repo_ver_local repo_rel_local \
				<< $(// here_doc -- ver_parse "$target_local")"
			> /dev/null || // die 'ver_parse' "failed"
		} || {
			# At this moment, let's say it is a branch at least
			reference_type="branch"
			result=1
			// log '$reference_type' "$reference_type"
			// log '$target' "$target"
			return $result
		}

		local repo_ver= repo_rel=
		[ -z "${target:+x}" ] ||
		# is_version "$target" ||
		/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
				<< $(// here_doc -- ver_parse "$target")"
		> /dev/null || // die 'ver_parse' "failed"

		// log '$target_local' "$target_local"

		# target="$target_local"
		// log '$repo_ver' "$repo_ver"
		// log '$repo_ver_local' "$repo_ver_local"
		! is_version "$repo_ver" ||
		! is_version "$repo_ver_local" || {

			local repo_ver_last="$( \
				tail -n 1 << EOF
				$(sort -V << EOF
$repo_ver
$repo_ver_local
EOF
				)
EOF
			)"

			// log '$repo_ver_last' "$repo_ver_last"
			[ "$repo_ver_last" = "$repo_ver" ] ||
				ok "$upstream_name" ||
				target="$target_local"
		}
		[ -n "${target:+x}" ] || [ -z "${target_local:+x}" ] || target="$target_local"
		[ -n "${target:+x}" ] || {
			reference_type="branch"
			result=1
			return $result
		}
		// log '$reference_type' "$reference_type"
		// log '$target' "$target"
		return $result

	}

	inner_query_branch() {
		# "$@" is empty by now
		#
		# set --
		# equ "$LOGNAME" "$SRC_USER" ||
		# # set +f -- $(// delegate -- as_user "$SRC_USER")
		# set -- $(// delegate -- as_user "$SRC_USER")
		# [ "$#" -eq "0" ] ||
		// log 'set privilege' "$(esceval "$@")"

		local branch_list=

		[ "$("$@" git -C "$_local_dir" rev-parse \
				--is-inside-work-tree 2>/dev/null)" == "true" ] &&
		! empty "$_local_dir" || {

			# "$@" find "$_local_dir" -mindepth 1 -delete

			branch_list="$( \
			"$@" git -c 'versionsort.suffix=-' ls-remote --exit-code --refs \
				--sort='version:refname' --heads "$url" 2> /dev/null |
				awk '{print $2}')" || // die 'git ls-remote' "failed"
		}

		[ -n "${target:+x}" ] ||
		null "$force_fetch" || {
			branch_list="$("$@" git ls-remote "${url}" --heads \
						"refs/heads/*" 2> /dev/null | awk '{print $2}')"
			for item in $branch_list; do
				[ -n "${item:+x}" ] || continue
				{ [ -n "${upstream_name:+x}" ] &&
					[ -z "${item##*"${upstream_name}"*}" ]; } || continue
				target="${item##"refs/heads/"}"
				// log '$target' "$target"
				reference_type="branch"
				// log '$reference_type' "$reference_type"
				break
				return 0
			done
			for item in $branch_list; do
				[ -n "${item:+x}" ] || continue
				[ -z "${item##*"master"*}" ] || [ -z "${item##*"main"*}" ] ||
				[ -z "${item##*"stable"*}" ] || continue
				target="${item##"refs/heads/"}"
				// log '$target' "$target"
				reference_type="branch"
				// log '$reference_type' "$reference_type"
				break
				return 0
			done
		}

		[ -n "${target:+x}" ] || {
			target="$("$@" git -P branch | grep \* | awk "{print \$2}")"
			// log '$target' "$target"
			reference_type="branch"
			// log '$reference_type' "$reference_type"
			return 0
		}

		# [ -n "${target:+x}" ] ||

		"$@" git stash --all > /dev/null || :

		// log '$reference_type' "$reference_type"
		// log '$target' "$target"
	}

	inner_query_tag "$@" || inner_query_branch "$@"

	[ -n "${target:+x}" ] || {
		// war "branch/tag '$upstream_name' doesn't exist" \
			"might because \".git\" issue in url"
		if null "${url##*".git"*}"; then
			url="${url%".git"}"
		else
			url="${url}.git"
		fi

		# force_fetch=1
		local remote_url="$("$@" git -C "$_local_dir" remote -v | \
				grep fetch | grep origin | awk '{print $2}')"
		[ "$remote_url" == "$url" ] ||
		"$@" git remote set-url origin "${url}" 2>&1 ||
		"$@" git remote add origin "${url}" 2>&1 ||
		// die "git remote set-url origin \"${url}\"" "failed"

		inner_query_tag "$@" || inner_query_branch "$@"
	}

	[ -n "${target:+x}" ] ||
	// die "branch/tag '$upstream_name' doesn\'t exist" "check the url, please"

	# Don't do it here
	# [ -n "${target##*"/"*}" ] || target="${target##*/}"

	printf "\n%s$FS%s" "$reference_type" "$target"
}

# / "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
#         << $(// here_doc -- synchronize "$reference_type" \
#     "$target" "$_local_dir" "$url" "$force_fetch")"
# > /dev/null || // die 'synchronize' "failed"
synchronize() {
	_level_2
	local reference_type="$1"
	local target="$2"
	[ -n "${target:+x}" ] || // die '$target' "\"$target\" is invalid"
	// log '$target' "$target"
	local _local_dir="$3"
	local url="$4"
	[ -n "${url:+x}" ] || // die '$url' "\"$url\" is invalid"
	shift 4
	local force_fetch
	if [ "$#" -ge "1" ]; then
		force_fetch="$1"
		shift 1
	else
		force_fetch=
	fi

	local repo_ver_string

	set --
	equ "$LOGNAME" "$SRC_USER" ||
		set -- $(// delegate -- as_user "$SRC_USER")

	[ "$PWD" = "$_local_dir" ] || // cd "$_local_dir"

	if [ "$reference_type" = "branch" ]; then
		null "$force_fetch" || {
			# [ -z "$target" ] ||
			"$@" git remote set-branches origin "$target" ||
			// die "git remote set-branches origin $target" "failed"

			// log 'fetch' "${url}"
			"$@" git fetch --depth 1 "${url}" "$target" 2>&1 ||
			"$@" git fetch "${url}" "$target" ||
			// die "git fetch --depth 1 \"${url}\" $target" "failed"
			# generate branch "$terget" in .git/config
			"$@" git fetch --depth 1 origin "$target"

		}
		local target_ref="$("$@" git -P branch | grep -v remotes | \
				grep \* | awk '{print $2}')"
		# fatal: a branch named 'master' already exists when "$target" = "$target_ref"
		[ "$target" = "$target_ref" ] || {
			[ "$("$@" git -P branch | grep -v remotes | grep "$target" |
				awk '{print $1}')" == "$target" ] ||
			# fatal: a branch named 'master' already exists
			"$@" git -P branch "$target" FETCH_HEAD 2>&1 ||
			# fatal: 'origin/master' is not a commit and a branch 'master' cannot be created from it
			"$@" git checkout -b "$target" --track origin/"$target" 2>&1 ||
			// die "git checkout -b $target --track origin/$target" "failed"

			"$@" git -P branch | grep -q "$target" && {
				# "$@" git switch "$target" --no-show-forced-updates 2> /dev/null ||
				"$@" git checkout "$target" 2>&1 ||
				// die "git switch $target" "failed"
			} ||
			# "$@" git switch "$target" --no-show-forced-updates 2> /dev/null ||
			# "$@" git switch -c "$target" ||    # Already on 'master'
			"$@" git checkout -b "$target" 2>&1 ||    # Already on 'master'
			// die "git switch $target" "failed"

			target_ref="$("$@" git -P branch | grep -v remotes | \
				grep \* | awk '{print $2}')"
			[ "$target_ref" == "$target" ] ||
			// die "[ \"$target_ref\" == \"$target\" ]" "failed"
		}

		// log '$target_ref' "$target_ref"

		"$@" git -P branch "--set-upstream-to=origin/$target" "$target"
		# fatal: the requested upstream branch 'origin/master' does not exist
		"$@" git reset --hard "origin/$target" 2>&1 ||
		// die "git reset --hard origin/$target" "failed"

		"$@" git stash --all 2>&1 || :

		# repo_ver_string="$(printf "%s\n" "$(
		#     "$@" git rev-parse --short 'HEAD@{upstream}' 2>/dev/null)")"
		repo_ver_string="$(printf "%s\n" "$( \
			"$@" git rev-parse --short 'HEAD' 2>/dev/null)")"

	else
		local target_local="$("$@" git -P branch | grep -v remote |
			grep "$target" | tr -d "*" | awk '{$1=$1}1')"
		# null "$force_fetch" &&
		ok "$target_local" || {
			# local targets="$("$@" git tag)"
			# contains "$targets" "$target" ||
			#
			# "$@" git fetch --all --tags  --prune
			#
			# "$@" git fetch --no-tags --depth 1 "${url}" \
			"$@" git fetch --depth 1 "${url}" \
				"+refs/tags/$target:refs/tags/$target" 2>&1 ||
			# "$@" git fetch --no-tags --depth 1 "${url}" tag "$target" 2>&1 ||
			"$@" git fetch --depth 1 "${url}" tag "$target" 2>&1 ||
			# "$@" git fetch --no-tags "${url}" tag "$target" 2>&1 ||
			"$@" git fetch "${url}" tag "$target" 2>&1 ||
			# "$@" git fetch --no-tags --tags --prune "${url}" 2>&1 ||
			"$@" git fetch --tags --prune "${url}" 2>&1 ||
			// die "git fetch \"${url}\" tag $target" "failed"

		}

		local target_ref="$( \
			"$@" git -P branch | grep -v remotes | grep \* | awk '{print $2}')"

		[ -n "${target_ref:+x}" ] ||
			// die '$target_ref' "\"$target_ref\" is invalid"
		# Not on $target
		[ -z "${target_ref##*"${target}"*}" ] || {
			# git show-ref "$target"
			#
			# # This is creating a new branch
			# # "$@" git checkout "tags/$target" -b "$target"
			# "$@" git checkout refs/tags/"$target" -b "$target" 2>&1 ||
			# "$@" git checkout "$target" -b "$target" 2>&1 ||
			# // die "git checkout refs/tags/$target" "failed"
			#
			# null "$target_local" ||
			"$@" git checkout "$target" --force 2>&1 ||
			// die "git checkout $target --force" "failed"
		}

		target_ref="$( \
			"$@" git -P branch | grep -v remotes | grep \* | awk '{print $2}')"

		[ -z "${target_ref##*"${target}"*}" ] ||
		# [ "$("$@" git -P branch | grep -v remotes |
		#     grep "$target" | awk '{print $2}')" == "$target" ] ||
		"$@" git switch "$target" 2>&1 ||
		"$@" git switch -c "$target" 2>&1 ||    # Already on 'master'
		// die "git switch $target" "failed"

		target_ref="$( \
			"$@" git -P branch | grep -v remotes | grep \* | awk '{print $2}')"

		[ -z "${target_ref##*"${target}"*}" ] ||
		// die "[ -z \"${target_ref##*"${target}"*}\" ]" "failed"

		// log '$target_ref' "$target_ref"

		"$@" git reset --hard tags/"$target" 2>&1 ||
		// die "git reset --hard tags/$target" "failed"

		"$@" git stash --all 2>&1 || :

		repo_ver_string="$target"
	fi

	local repo_ver repo_rel
	# is_version "$repo_ver_string" ||
	/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		<< $(// here_doc -- ver_parse "$repo_ver_string")"
	> /dev/null || // die 'ver_parse' "failed"

	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"

	is_version "$repo_ver" ||
	// die '$repo_ver' "${repo_ver:+"${repo_ver} "}got wrong value"
	is_version "$repo_rel" ||
	// die '$repo_rel' "${repo_rel:+"${repo_rel} "}got wrong value"

	printf "\n%s$FS%s" "$repo_ver" "$repo_rel"
}

fetch_tag() {
	local target="$1"
	local url="${2-}"
	[ ! -z "${url:+x}" ] || url="origin"

	set --
	equ "$LOGNAME" "$SRC_USER" ||
		set -- $(// delegate -- as_user "$SRC_USER")
	#
	# "$@" git fetch --no-tags origin +refs/tags/"$target":refs/tags/"$target" 2>&1 ||
	# "$@" git fetch origin +refs/tags/"$target":refs/tags/"$target" 2>&1 ||
	# # "$@" git fetch origin "+refs/heads/*:refs/remotes/origin/*" 2>&1 ||
	# "$@" git fetch origin "+refs/heads/$target:refs/remotes/origin/$target" 2>&1 ||
	# "$@" git fetch --tags --prune origin 2>&1 ||
	# "$@" git fetch --tags --force origin 2>&1 ||
	# // die "git fetch $url \"+$target_ref:$target_ref\"" "failed"

	# "$@" git fetch $url "+$target_ref:$target_ref" --no-tags ||
	"$@" git fetch $url "+refs/tags/$target:refs/tags/$target" --no-tags 2>&1 ||
	"$@" git fetch $url "+refs/tags/$target:refs/tags/$target" 2>&1 ||
	# "$@" git fetch $url "+refs/heads/*:refs/remotes/origin/*" 2>&1 ||
	"$@" git fetch $url "+refs/heads/$target:refs/remotes/origin/$target" 2>&1 ||
	"$@" git fetch --tags --prune $url 2>&1 ||
	"$@" git fetch --tags --force $url 2>&1 ||
	// die "git fetch $url \"+$target_ref:$target_ref\"" "failed"
}

#
# remote_sync   ->track_type ->synchronize
# download_git  ->track_type ->synchronize
#
download_git() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	// log '$repo_urn' "$repo_urn"
	shift 1
	local _local_dir="$1"
	local _res="$2"

	// log '$SRC_ROOT' "$SRC_ROOT"
	// log '$SRC_USER' "$SRC_USER"

	set --
	equ "$LOGNAME" "$SRC_USER" ||
		set -- $(// delegate -- as_user "$SRC_USER")

	# // log '$_local_dir' "$_local_dir"
	# "$SRC_ROOT/$pkg_name/${dest:+"$dest/"}."

	# Remove "/."
	// log '$_local_dir' "$_local_dir"
	// mkcd "$_local_dir"

	# Might be empty
	local upstream_name=
	[ -n "${_res##*[@\#]*}" ] || upstream_name="${_res##*[@\#]}"

	local url="${_res%[\#@]*}"
	[ -n "${url:+x}" ] || // die '$url' "\"$url\" is invalid"
	url="$(standardize "$url")"
	null "${url##*".git"*}" ||
	ok "${url##*"github"*}" ||
	url="${url}.git" # url="${url%.git}.git"

	// log '$upstream_name' "$upstream_name"
	// log '$url' "${url}"
	// log '$PWD' "$PWD"

	local reference_type=
	local target=
	local force_fetch="1"

	/ "IFS=$(printf '%b' "$FS") read -r reference_type target \
		<< $(// here_doc -- track_type \
			"$upstream_name" "$_local_dir" "$url" "$force_fetch")"
		2> /dev/null || // die 'track_type' "failed"

	// log '$target' "$target"
	// log '$reference_type' "$reference_type"

	local repo_ver=
	local repo_rel=0

	if [ "$("$@" git -C "$_local_dir" rev-parse \
			--is-inside-work-tree 2>/dev/null)" = "true" ] &&
		! empty "$_local_dir"; then

		# Synchronizing already exists git repo

		local remote_url="$("$@" git -C "$_local_dir" remote -v | \
				grep fetch | grep origin | awk '{print $2}')"
		# [ "$remote_url" == "$url" ] ||
		#     ! "$@" git remote remove origin || "$@" git remote add origin "${url}" ||
		#     // die "git remote set-url origin \"${url}\"" "failed"

		[ "$remote_url" == "$url" ] ||
		"$@" git remote set-url origin "${url}" 2>&1 ||
		"$@" git remote add origin "${url}" 2>&1 ||
		// die "git remote set-url origin \"${url}\"" "failed"

		/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		<< $(// here_doc -- synchronize "$reference_type" \
			"$target" "$_local_dir" "$url" "1")"
		> /dev/null || // die 'synchronize' "failed"

		"$@" git rev-parse --short HEAD ||
		// war 'git rev-parse --short HEAD' "failed"
		"$@" git describe --always || // war 'git describe --always' "failed"

		"$@" git submodule deinit --all -f
		"$@" git submodule init
		"$@" git submodule sync
		"$@" git submodule update --init --remote --recursive --force
	else

		# Initializing git repo

		#
		"$@" find "$_local_dir" -mindepth 1 -delete
		#

		# https://github.blog/2020-12-21-get-up-to-speed-with-partial-clone-and-shallow-clone/
		"$@" git clone --depth 1 --single-branch --branch "$target" "${url}" "$_local_dir" 2>&1 ||
		# "$@" git clone --recursive --no-tags --depth 1 "${url}" "$_local_dir" 2>&1 ||
		"$@" git clone --branch "$target" "${url}" "$_local_dir" 2>&1 ||
		"$@" git clone --depth 1 "${url}" "$_local_dir" 2>&1 ||
		# "$@" git clone --recursive --depth 1 --single-branch --branch "$target" "${url}" "$_local_dir" 2>/dev/null ||
		# "$@" git clone --recursive --filter=tree:0 --branch "$target" "${url}" "$_local_dir" 2>/dev/null ||
		# "$@" git clone --recursive --filter=blob:none --branch "$target" "${url}" "$_local_dir" 2>/dev/null ||
		"$@" git clone "${url}" "$_local_dir" 2>&1 ||
			// die "git clone --branch \"$target\" \"${url}\" \"$_local_dir\"" "failed"
			# // die "git clone --recursive --depth 1 --branch \
			# \"$target\" \"${url}\" \"$_local_dir\"" "failed"

		if [ "$reference_type" = "branch" ]; then
			# repo_ver="$(// delegate -- "$@" git rev-parse --short 'HEAD' 2>/dev/null)"
			repo_ver="$(printf '%s\n' "$( \
				"$@" git rev-parse --short 'HEAD' 2>/dev/null)")"
		else
			repo_ver="$target"
		fi
	fi

	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"

	# Might be illigal values
	# is_version "$repo_ver" || // die '$repo_ver' "${repo_ver:+"${repo_ver} "}got wrong value"
	# is_version "$repo_rel" || // die '$repo_rel' "${repo_rel:+"${repo_rel} "}got wrong value"

	printf "\n%s$FS%s" "$repo_ver" "$repo_rel"

}

# Cloninng a repo as a reference
git_sync() {
	local candidates_name="$1"
	local alias="$2"
	local url="$3"
	local target="$4"

	set --
	local repo_owner="$(// delegate owner "$REPO_ROOT")"
	[ "$LOGNAME" = "$repo_owner" ] ||
	set -- "$(// delegate as_user $repo_owner)"

	local candidates_value=
	local _local_dir=

	for item in $("$@" find -L "$REPO_ROOT/" -type d -name ".git"); do
		local parent_dir="${item%/*}"
		[ "$("$@" git -C "$parent_dir" rev-parse \
				--is-inside-work-tree 2>/dev/null)" == "true" ] || continue
		local item_url="$("$@" git -C "$parent_dir" remote -v |
			grep "fetch" | grep "origin" |
			awk '{print $2}'
		)"
		[ "$item_url" = "$url" ] || continue
		candidates_value="$("$@" find -L "$parent_dir" -type d -name "$alias")"
		[ -z "${candidates_value:+x}" ] || { _local_dir="$parent_dir"; break; }
	done

	[ -n "${_local_dir:+x}" ] || {
		local _des_folder="$(printf '%s' "$url" |
			sed -e 's/https\:\/\///g'  -e 's/.git//g'  -e 's/\//\./g'
		)"

		_local_dir="$$REPO_ROOT/$_des_folder"

		"$@" git clone --depth 1 --single-branch --branch "$target" "${url}" "$_local_dir" 2>&1 ||
		"$@" git clone --depth 1 --branch "$target" "${url}" "$_local_dir" 2>&1 ||
		"$@" git clone "${url}" "$_local_dir" 2>&1 ||
		// die "git clone --depth 1 --branch \"$target\" \
					\"${url}\" \"$_local_dir\"" "failed"
		candidates_value="$("$@" find -L "$parent_dir" -type d -name "$alias")"
	}

	[ "$candidates_name" = '_' ] ||
		/ "$candidates_name=\"$candidates_value\""

	return 0
}

ver_update() {
	_level_2

	local repo_urn="$1"
	local ver="$2"
	local rel="$3"
	# local repo_ver="$2"
	# local repo_rel="$3"
	// log '$ver' "$ver"
	// log '$rel' "$rel"

	# local format="$(// delegate -- pkg_format "$repo_urn")"
	local format= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		format reference_type \
		<< $(// here_doc -- pkg_format "$repo_urn")"
	> /dev/null || { // die 'pkg_format' "failed"; exit 1; }

	equ "$format" "git" ||
		// die '$format' "'$format' is not git"
	# null "$ver" && null "$rel" && {
	#   equ "$format" == "git" ||
	#   // die '$ver-$rel' "both are empty and $repo_urn is not a git repo"
	# }

	# local repo_dir="$4"
	local repo_ver= repo_rel=

	# Repo maintainer defined the function "version"
	[ ! -f "$repo_urn/definition" ] || . "$repo_urn/definition"

	is_function "version" && {
		# IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		#     < <(// delegate -- version "$SRC_ROOT/$pkg_name") 2>/dev/null ||
		# // die 'version' "failed"
		/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		<< $(// here_doc -- version "$SRC_ROOT/$pkg_name")"
		2>/dev/null || // die 'version' "failed"
	} ||
	# Parse the versions by package manager
	/ "IFS=$(printf '%b' "$FS") read -r repo_ver repo_rel \
		<< $(// here_doc -- ver_parse "$ver" "$rel")"
	> /dev/null || // die 'ver_parse' "failed"

	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"
	is_version  "$repo_ver" || // die '$repo_ver' "$repo_ver"
	is_version  "$repo_rel" || // die '$repo_rel' "$repo_rel"

	# Read the version file
	local ver_origin rel_origin \
		alias_origin repo_url reference_type
	IFS=$' ' read -r ver_origin rel_origin \
		alias_origin repo_url reference_type 2>/dev/null \
		< "$repo_urn/version" ||
	// die "$pkg_name" "failed to read $repo_urn/version"

	// log '$ver_origin' "$ver_origin"
	// log '$rel_origin' "$rel_origin"
	// log '$alias_origin' "$alias_origin"

	local repo_alias="$alias_origin"
	[ -n "${repo_url:+x}" ] || repo_alias=

	# Compare differences between the parsing result and the version file
	! { equ "$ver_origin" "$repo_ver" &&
		equ "$rel_origin" "$repo_rel" &&
		equ "$alias_origin" "$repo_alias"; } ||
	{
		// log 'version update' "is not necessary"
		return 0
	}

	# Check the design
	is_writable "$repo_urn" || // die 'version file' "is readonly"

	local repo_url_encoded="$repo_url"
	case "$repo_url" in
		*"$REPO_URL"*)
			repo_url_encoded="$( \
			// delegate -- bicode "edoc" "$repo_url" "REPO_URL" "$REPO_URL")"
	esac

	// log '$repo_urn' "$repo_urn"
	// log '$repo_ver' "$repo_ver"
	// log '$repo_rel' "$repo_rel"
	// log '$repo_alias' "$repo_alias"

	is_version "$repo_ver" || repo_ver=0
	is_version "$repo_rel" || repo_rel=0

	# Write the version info to file
	/usr/bin/printf '%s %s %s %s %s\n' \
		"$repo_ver" \
		"$repo_rel" \
		"$repo_alias" \
		"$repo_url_encoded" "$reference_type" |
		// as_own "$repo_urn/version" tee "$repo_urn/version" ||
		// die 'permission denied' "on writting version to file $repo_urn/version"

	# Reading back to verify it
	local _ver _rel _repo_urn _alias _url _reference_type
	IFS=$' ' read -r _ver _rel \
		_alias _url _reference_type < "$repo_urn/version" 2>/dev/null ||
	// die "$pkg_name" "failed to read $repo_urn/version"

	local _url_decoded="$_url"
	case "$repo_url" in
		*"REPO_URL"*)
			_url_decoded="$( \
				// delegate -- bicode "code" "$_url" "REPO_URL" "$REPO_URL")" ;;
		*) nohup git_sync \
			_ "$_alias" "$_url" "$_reference_type" \
			> /dev/null 2>&1 & ;;
	esac

	[ "$_ver"   == "$repo_ver" ] &&
	[ "$_rel"   == "$repo_rel" ] &&
	[ "$_alias" == "$repo_alias" ] &&
	[ "$_url"   == "$repo_url_encoded" ] &&
	is_repos "$repo_urn" || {
		// log '$_ver' "$_ver"
		// log '$_rel' "$_rel"
		// log '$_alias' "$_alias"
		# // log '$_repo_dir_decoded' "$_repo_dir_decoded"
		// log '$_url' "$_url"
		// log '$reference_type' "$reference_type"

		// die 'version update' "failed"
	}
	# // density_out "$repo_urn" "${target_source-}"
	# // density_out "$repo_urn" "$repo_urn"

}

# ver_input_______________________________________
#     |         |          |           |         |
# repo_major repo_minor repo_patch repo_ident repo_suffix
#                                      |         |
# rel_input---------------------------------------
ver_parse() {
	_level_2
	local ver_input="$1"
	readonly ver_input
	local rel_input="${2-}"
	readonly rel_input
	# Medium variables
	local repo_ver="$ver_input" repo_rel="$rel_input"
	# Final result
	local ver_output= rel_output=
	// log '$ver_input' "$ver_input"
	// log '$rel_input' "$rel_input"
	# -n without :+x might get wrong result!!!
	# [ -n "${repo_ver:+x}" || repo_ver="9999.9999.9999.9999"
	# ! -z don't need :+x under this scenario
	# [ ! -z "${ver_input:+x}" ] || repo_ver="9999.9999.9999.9999"
	# [ ! -z "${rel_input:+x}" ] || repo_rel="0"
	# The following two lines require extremely strong specification
	# repo_ver="${ver_input%%-*}"
	# repo_rel="${ver_input##*-}"

	while
		case "$repo_ver" in
			"v"*)
				repo_ver="${repo_ver##"v"}"
				# echo "$repo_ver"
				// log '$repo_ver' "$repo_ver [leading \"v\" removed]"
				;;
			*)
				break
		esac
	do
		:
	done

# Does Semantic Versioning allow 4 components in version numbers?
# https://softwareengineering.stackexchange.com/questions/298720/does-semantic-versioning-allow-4-components-in-version-numbers
	case "$repo_ver" in
		*"-"*|*"."*|*"+"*|*"_"*|*"/"*)
			local repo_major_parse= repo_minor_parse= \
				repo_patch_parse= repo_ident_parse= repo_suffix_parse=
			/ "IFS=$(printf '%b' "$FS") read -r repo_major_parse \
				repo_minor_parse repo_patch_parse \
				repo_ident_parse repo_suffix_parse \
				<< $(// here_doc -- ver_split "$repo_ver")"
			> /dev/null || // die 'ver_split' "failed"

			readonly repo_major_parse repo_minor_parse \
				repo_patch_parse repo_ident_parse repo_suffix_parse

			! is_integer "$repo_major_parse" ||
				ver_output="$repo_major_parse"

			! is_integer "$repo_minor_parse" ||
				ver_output="${ver_output:+"${ver_output}."}$repo_minor_parse"

			! is_integer "$repo_patch_parse" ||
				ver_output="${ver_output:+"${ver_output}."}$repo_patch_parse"

			! is_integer "$repo_ident_parse" ||
				ver_output="${ver_output:+"${ver_output}."}$repo_ident_parse"
			;;
		*)
			# User defined version
			[ -z "${ver_input:+x}" ] ||
				// war '$ver_input' "'$ver_input' format is not standardized"
	esac

	local dot_counts="$(// delegate -- occurrences "$ver_output" ".")"

	rel_output="$repo_rel"
	[ -n "${repo_suffix_parse:+x}" ] &&
		rel_output="$repo_suffix_parse" || {
		[ ! -z "${rel_input:+x}" ] ||
		[ -z "${repo_ident:+x}" ] || {
			rel_output="$repo_ident"
			# [ "$dot_counts" -lt "3" ] || {
			#   ver_output="${ver_output%.*}"
			#   : $((dot_counts -= 1))
			# }
		}
	}

	# Completments
	# 3 fields/components in version numbers (which comes with 2 dots)
	while [ "$((2 - dot_counts))" -gt "0" ]; do
		ver_output="${ver_output:+"${ver_output}."}0"
		: $((dot_counts += 1))
	done

	is_version "$ver_output" || ver_output="9999.9999.9999.9999"

	readonly ver_output

	[ -n "${rel_output:+x}" ] || rel_output="0"

	// log '$ver_output' "$ver_output"
	// log '$rel_output' "$rel_output"

	printf "\n%s$FS%s" "$ver_output" "$rel_output"
}

# $1 repo_urn     : package repo url/uri
# $2 $_local_dir  : decompress target
# $3 $_res        : local tar_file
extract_tar() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	shift 1
	local _local_dir="$1"
	local _res="$2"

	[ -n "${_local_dir:+x}" ] || // die '$_local_dir' "$_local_dir"
	local _local_dir_tmp="/tmp/$LOGNAME/kiss/extract/$pkg_name"
	# [ -n "${_local_dir##*"$DES_ROOT"*}" ] || {
	[ -d "$_local_dir_tmp" ] &&
		// ownership "$LOGNAME" "$_local_dir_tmp" ||
		// as "$LOGNAME" \mkdir -p "$_local_dir_tmp"
	# }

	// mkcd "$_local_dir_tmp"

	# find . -mindepth 1 -maxdepth 1 -delete
	for item in $(find "$_local_dir_tmp" -mindepth 1 -maxdepth 1); do
		# [ ! -e "$item" ] || [ ! -h "$item" ] || [ ! -d "$item" ] || {
		// log 'removing' "$item"
		\rm -rf "$item"
		# }
	done

	// log '$0' "$0"
	// log '$_res' "$_res"
	// log '$_local_dir' "$_local_dir"
	// log '$_local_dir_tmp' "$_local_dir_tmp"
	// log '$pkg_name' "$pkg_name"

	# "leading components"
	# This is a portable shell implementation of GNU tar's
	# '--strip-components 1'. Use of this function denotes a
	# performance penalty.
	local tarball="$(// delegate -- slot_aquire \
		"$pkg_name" "$_local_dir_tmp/tarball"
	)"
	// log '$tarball' "$tarball"
	local tarball_manifest="$(// delegate -- slot_aquire \
		"$pkg_name" "$_local_dir_tmp/tarball-manifest")"
	// log '$tarball_manifest' "$tarball_manifest"

	// decompress "$_res" > "$tarball" || {
		\rm -f "$tarball"
		// die "$pkg_name" "Failed to decompress \
		\"$_res\" to \"$tarball\" and deleted."
	}

	tar xf "$tarball" ||
		// die "$pkg_name" "Failed to extract $_res"

	# The sort command filters out all duplicate top-level
	# directories from the tarball's manifest. This is an optimization
	# as we avoid looping (4000 times for Python(!)).
	tar tf "$tarball" | sort -ut / -k1,1 > "$tarball_manifest" ||
		// die "$pkg_name" "Failed to extract manifest"

	# Iterate over all directories in the first level of the
	# tarball's manifest. Each directory is moved up a level.
	while IFS=/ read -r dir _; do case "${dir#.}" in *?*)
		# Skip entries which aren't directories.
		[ -d "$dir" ] || continue
		// log '$dir' "$dir"
		# Move the parent directory to prevent naming conflicts
		# with the to-be-moved children.
		\mv -f "$dir" "$KISS_PID-$dir"

		local ifs="$IFS"
		local IFS="$newline"
		local index=0
		for item in $(find "$KISS_PID-$dir/." ! -name . -prune); do
			: $((index += 1))
			// log '$(find "$KISS_PID-$dir/." ! -name . -prune)' "$item"
			[ "$index" -le 10 ] || break
		done
		[ -z "${KISS_DEBUG:+x}" ] ||
		(IFS=$', |' && list_contains "$FUNCNAME" $KISS_DEBUG) || {
			local index=0
			for item in $(find "$KISS_PID-$dir/." ! -name . -prune \
				-exec sh -c 'echo "\$0 = $0" "\$@ = $@"' {} +); do
				: $((index += 1))
				// log '$(find "$KISS_PID-$dir/." ! -name . -prune)' "$item"
				[ "$index" -le 10 ] || break
			done
		}
		IFS="$ifs"

		# https://unix.stackexchange.com/questions/696537/how-does-find-type-f-print-o-name-o-prune-actually-work
		# Move all children up a directory level. If the mv command
		# fails, fallback to copying the remainder of the files.
		#
		# We can't use '-exec {} +' with any arguments between
		# the '{}' and '+' as this is not POSIX. We must also
		# use '$0' and '$@' to reference all arguments.
		find "$KISS_PID-$dir/." ! -name . -prune \
			-exec sh -c 'mv -f "$0" "$@" .' {} + 2>/dev/null ||
		find "$KISS_PID-$dir/." ! -name . -prune \
			-exec sh -c 'cp -fRp "$0" "$@" .' {} +

		# Remove the directory now that all files have been
		# transferred out of it. This can't be a simple 'rmdir'
		# as we may leave files in here if any were copied.
		\rm -rf "$KISS_PID-$dir"
	esac done < "$tarball_manifest"

	# Remove the tarball now that we are done with it.
	\rm -f "$tarball"

	[ "$_local_dir_tmp" = "$_local_dir" ] || {
		mkcd "$_local_dir"
		// ownership "$_local_dir" "$_local_dir_tmp"
		// as_own "$_local_dir" rsync -aqz \
			--remove-source-files "$_local_dir_tmp/." "$_local_dir/"
	}
}

# Load all source files to the "make" dir
# $1 repo_urn : package repo url/uri
# Suppose the source is a git repo, then your diff list is:
# git -C "$make_dir" status | grep "modified" | awk "{print \$2}"
# By putting the built binaries under $OBJ_ROOT/$pkg_name to
# keep the repo's "files" "patches" folders orgnized,
# the "$make_dir" is maintained as a patching plant / breadboard
# Putting the repo's "files" "patches" folders under the $make_dir
# is a historical convention
pkg_load() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	local repo_dir="${repo_urn%/*}"
	# Extract all source archives to the build directory and copy over any
	# local repository files.
	#
	# NOTE: repo_urn comes from caller.
	// log "$pkg_name" "extracting sources"

	# arg1: pre-extract
	# arg2: package name
	# arg3: path to DESTDIR
	// run_hook pre-extract "$pkg_name" "$PKG_ROOT/$pkg_name"

	local src_dir="$SRC_ROOT/$pkg_name"
	local temp_loading="$TEMP_ROOT/$pkg_name/loading"
	local make_dir="$MAKE_ROOT/$pkg_name"

	// mkcd "$src_dir" "$temp_loading" "$make_dir"

	# ash: getcwd: No such file or directory
	# Keep the empty folders for debugging convenienceA ?
	# You could use an additional build path (OBJ_ROOT) to keep a pure patched source here (out of source build)
	# find "$make_dir" \( -type f -o -type l \) -exec \rm -f {} +
	# find "$make_dir" -maxdepth 1 -mindepth 1 -exec \rm -rf {} +
	find "$make_dir" -mindepth 1 -delete

	while read -r src_url dest || ok "${src_url%%\#*}"; do
		ok "${src_url%%\#*}" || continue
		# Local files relative to $repo_urn
		// log '$src_url' "$src_url"
		/ "IFS=$(printf '%b' "$FS") read -r \
			_local_dir _res_type _res _target_name \
			<< $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest")"
			> /dev/null || // die "local_route" "failed"

		// log '$_res_type' "$_res_type"
		// log '$_res' "$_res"
		// log '$_local_dir' "$_local_dir"

		# Create the source's directories if not null.
		ok "$_res" || continue
		# Local files relative to $repo_urn
		// log '$_res' "$_res"
		// log '$_res_type' "$_res_type"
		# Local files absolute path
		// log '$_res [extract]' "$_res"

		# Should be ready
		[ -d "$_local_dir" ] ||
		// die '$_local_dir' "not a directory: \"$_local_dir\""

		# local dest_dir="$MAKE_ROOT/$pkg_name${dest:+"/$dest"}"
		local dest_dir="$src_dir${dest:+"/$dest"}"

		[ "$dest_dir" != "$_local_dir" ] ||
		[ "$_res_type" = "url" ] ||
		[ "$_res_type" = "archive" ] || continue

		dest_dir="$(standardize "$dest_dir")"
		// log '$dest_dir' "$dest_dir"

		# Extra preparations for updating
		case "$_res_type" in
			# Do it in the download stage
			# $_res_type == git, _res is a remote git repository link but it has been sychronized locally
			# $_res_type == url, _res is a remote archive link but it has been sychronized locally
			# "git"|"url"|"archive") ;;
			# "git"|"url")
			"url")
				local src_name="${src_url##*/}"
				src_name="${src_name%\?*}"
				local archive_local="$ARCHIVE_ROOT/$pkg_name/${dest:+"$dest/"}$src_name"

				[ -f "$archive_local" ] ||
					local tar_file="$(// delegate -- download_url "$pkg_name" "$_local_dir" "$_res")"

				# Might outdated
				is_archive "$archive_local" ||
				[ ! -z "${KISS_FORCE+x}" ] ||
				# ok "(ls -l --time-style=+'%d-%m-%Y' "$archive_local" | awk -v d=$(date +%d-%m-%Y) '$6==d')" ||
				[ "$(date -d @$(stat -c %Y "$archive_local") +%d-%m-%Y)" = "$(date +%d-%m-%Y)" ] ||
				// delegate -- download_url "$pkg_name" "$_local_dir" "$_res"

				! is_archive "$archive_local" ||
					// extract_tar "$pkg_name" "$dest_dir" "$_res"
				;;
			"archive")
					// extract_tar "$pkg_name" "$dest_dir" "$_res"
				;;
			# Direct repository files
			*)
				// log '$_res' "$_res got updated in extra preparations"
				# equ "$_target_name" "." ||
				# For example:
				# Source: $ARCHIVE_ROOT/$pkg_name/file.c
				# Target: $SRC_ROOT/$pkg_name${dest:+"/$dest"}
				#
				# local _target_dir="$SRC_ROOT/$pkg_name${dest:+"/$dest"}"
				# local _target_dir="$MAKE_ROOT/$pkg_name${dest:+"/$dest"}"
				local _target_dir="$temp_loading${dest:+"/$dest"}"
				// log '$_target_dir' "$_target_dir"
				# [ -n "${_res##*"${repo_dir}"*}" ] ||
				# [ "$_local_dir/$_target_name" == "$_res" ] ||
				# ! rsync -aqz "$_res" "$_local_dir/" || ! sync ||
				! rsync -aqz "$_res" "$_target_dir/" ||
					! // sync ||
					! // empty "$_target_dir" ||
					// die '$_target_dir' "empty directory $_target_dir"
		esac

		# Should cold be ready
		# [ -d "$_des_dir" ] ||
		# // die '$_des_dir' "not a directory: \"$_des_dir\""

		# local dest_dir="$make_dir/$pkg_name${dest:+"/$dest"}"
		# dest_dir="$(standardize "$dest_dir")"
		# // log '$dest_dir' "$dest_dir"

		# Change to target build directory
		# // mkcd "$dest_dir"

		# ! empty "$_local_dir" ||
		#   // die '$_local_dir' "empty directory: $_local_dir"
		#
		# equ "$_target_name" "." ||
		# [ -f "$_local_dir/$_target_name" ] ||
		#   // die '$_local_dir/$_target_name' \
		#       "'$_local_dir/$_target_name' does not exist"
		# // log '$_local_dir/$_target_name' \
		#   "\"$_local_dir/$_target_name\" as the copy source"

		# # Do the copy job
		# # Source: $SRC_ROOT/$pkg_name${dest:+"/$dest"}
		# # Target: $MAKE_ROOT/$pkg_name${dest:+"/$dest"}
		# ! rsync -aqz "$_local_dir/$_target_name" ./ || ! sync ||
		# ! empty "$dest_dir" ||
		#   // die '$dest_dir' "empty directory $dest_dir"

		# equ "$_target_name" "." ||
		# ! empty "$dest_dir/$_target_name" ||
		# [ -f "$dest_dir/$_target_name" ] ||
		#   // die '$dest_dir/$_target_name' \
		#       "'$dest_dir/$_target_name' empty directory\
		#       ${newline}or file does not exist"

		# // log 'copied' "from \"$_local_dir/$_target_name\"\
		#   ${newline}to\"$PWD/$_target_name\""

		# cd "$src_dir"

	done < "$repo_urn/sources" ||
	// die "$pkg_name" "Failed to extract $_res"
	# Use this rsync method to void deleting entire make folder
	#
	! rsync -aqz --delete "$src_dir/." --exclude="objects" --exclude="build" "$make_dir/" ||
		! sync ||
		! empty "$make_dir" ||
		// die '$make_dir' "empty directory $make_dir"

	! rsync -aqz "$temp_loading/." "$make_dir/" ||
		! // sync ||
		! // empty "$make_dir" ||
		// die '$make_dir' "empty directory $make_dir"

	// ownership "$VOLATILE" "$make_dir"

}

# Without "interrupt" in this recursive function ?
# $1 deps       : depends list
# $2 makedeps   : local host "make" depends list
# $3 explicit   : explicit build targets list
# shift 3
# $1 repo_urn   : package repo url/uri
# $2 policy     : raw/expl | policies
# $3 filter     : filter switch
# $4 appended   : dependencies appended
# $5 dep_stage  : dependent type/stage [build time / runtime]
pkg_depends() {
	_level_1
	local deps="$1"
	local makedeps="$2"
	local explicit="$3"
	shift 3
	# Going to be built
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	# is_repos "$repo_urn" ||
	#     repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	local policy="${2-}"
	local filter="${3-}"
	local appended="${4-}"
	local dep_stage="${5-}"

	local result=0

	# // log '$deps' "$deps"
	// log '$makedeps' "$makedeps"
	// log '$repo_urn' "$repo_urn [input]"
	// log '$pkg_name' "$pkg_name"
	// log '$policy' "$policy"
	// log '$filter' "$filter"
	# // log '$appended' "$appended"
	// log '$dep_stage' "$dep_stage"
	// log '$explicit' "$explicit"
	# TODO: Exclude the final target?
	local repo_target="$sys_db/$pkg_name"
	// log '$repo_target' "$repo_target"

	# Resolve all dependencies and generate an ordered list. The deepest
	# dependencies are listed first and then the parents in reverse order.
	! contains "$deps" "$repo_urn" || {
		printf "\n%s$FS%s" "$deps" "$makedeps"
		return $result
	}
	# Filter out non-explicit, already installed packages.
	null "$filter" || ok "$policy" || contains "$explicit" "$repo_urn" ||
	[ ! -d "$repo_target" ] || {
		printf "\n%s$FS%s" "$deps" "$makedeps"
		return $result
	}
	# Detect circular dependencies and bail out.
	# Looks for multiple repeating patterns of (dep dep_parent) (5 is max).
	local tail=${appended##* }
	case " ${appended} " in
		*" ${tail} "*" ${repo_urn} "*" ${tail} "*" ${repo_urn} "*" ${tail} "*" ${repo_urn} "*" ${tail} "*" ${repo_urn} "*" ${tail} "*" ${repo_urn} "*)
		// war "$pkg_name <> ${tail}" "circular dependency detected"
		printf "\n%s$FS%s" "$deps" "$makedeps"
		result=1
		return $result
	esac

	repo_urn="$repo_target"

	[ -d "$repo_target" ] || {
		repo_urn="$(// delegate -- repo_trace "$pkg_name")" || {
			// war '$pkg_name' "repo not found"
			printf "\n%s$FS%s" "$deps" "$makedeps"
			result=1
			# return $result
			interrupt
		}
		# [ -d "$repo_urn" ] || {
		#   // war "$pkg_name" 'is not yet installed'
		#   printf "\n%s$FS%s" "$deps" "$makedeps"
		#   result=1
		#   # return $result
		#   interrupt
		# }
	}

	// log '$repo_urn' "$repo_urn"
	// log '$KISS_ROOT' "$KISS_ROOT"

	# // log '$policy' "$policy"
	# // log '$filter' "$filter"

	local item
	for item in $appended; do
		// log '$appended' "$item"
	done

	make_depends() {
		_level_2
		local makedeps="$1"
		local repo_urn="$2"
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		local result=0
		# Only add to list once
		! contains "$makedeps" "$pkg_name" || {
			printf '\n%s' "$makedeps"
			return $result
		}
		# Filter already installed packages on build machine.
		[ ! -d "$sys_db/$pkg_name" ] || {
			printf '\n%s' "$makedeps"
			return $result
		}
		# Add to the list
		makedeps="${makedeps:+"${makedeps} "}$pkg_name"
		printf '\n%s' "$makedeps"
	}

	# Packages which exist and have depends.
	# ! // null "$(// delegate -- repo_trace "$pkg_name")" ||
	# // die '$pkg_name' "'$pkg_name' does not exist"
	is_repos "$repo_urn" || {
		// war '$pkg_name' "'$repo_urn' is not a valid repo"
		tree "$repo_urn"

		local content="$( \
		// delegate -- prompt "Delete the invalid packages? \
			${newline}'$repo_urn' \
			${newline}It has been backuped in '$REPO_MAIN/base' [*|n|ctrl+c]"
		)"
		expr "$content" : '[n|N]\+' > /dev/null ||
			\rm -rf "$repo_urn"

		printf "\n%s$FS%s" "$deps" "$makedeps"
		result=1
		return $result
	}

	local dep= dep_type=
	[ ! -e "$repo_urn/depends" ] ||
	# Recurse through the dependencies of the child packages.
	while read -r dep dep_type || ok "$dep"; do
		// log '$dep' "$dep"
		// log '$dep_type' "$dep_type"
		null "${dep##\#*}" || null "${dep##*/*}" ||
		contains "$appended" "$repo_urn" || {
			# KISS_ROOT         true            false
			# dep_type true     make_depends    pkg_depends
			# dep_type false    pkg_depends     pkg_depends
			ok "$dep_type" &&
			[ ! -z "${KISS_ROOT:+x}" ] &&
				# Host only dependencies
				makedeps="$(// delegate -- make_depends "$makedeps" "$dep")" ||
				/ "IFS=$(printf '%b' "$FS") read -r deps makedeps \
				<< $(// here_doc -- pkg_depends \
					"$deps" "$makedeps" "$explicit" \
					"$dep"  ""          "$filter" \
					"${appended:+"${appended} "}$repo_urn" "$dep_type")"
				> /dev/null || {
					// war 'pkg_depends' "failed"
					printf "\n%s$FS%s" "$deps" "$makedeps"
					result=1
					return $result
				}
		}
	done < "$repo_urn/depends" || :

	# Add parent to dependencies list.
	// equ "$policy" expl && {
		! equ "$dep_stage" make ||
		ok "$(// delegate -- pkg_cache "$repo_urn")"
	} ||
	# { [ -n "${deps:+x}" ] && [ -z "${deps##*"${repo_urn##*/}"*}" ]; } ||
	contains "$explicit" "$repo_urn" ||
	contains "$deps" "$repo_urn" ||
	deps="${deps:+"${deps} "}$repo_urn"

	item=
	for item in $deps; do
		// log '$deps' "$item"
	done
	# Return multi values without "process substitution".
	# But needs "eval" at the caller side
	# When return earlier, pay attention to print result, please
	printf "\n%s$FS%s" "$deps" "$makedeps"
	return $result
}

# "$@" : all packages
pkg_order() {
	_level_2
	local deps="$1"
	local makedeps="$2"
	shift 2
	local order=
	local redro=
	# Order a list of packages based on dependence and take into account
	# pre-built tarballs if this is to be called from 'kiss i'.
	local order= redro=
	for repo_urn do
		case $repo_urn in
			/*@*.tar.*|*/*)
				deps="${deps:+"${deps} "}$repo_urn" ;;
			*@*.tar.*)
				deps="${deps:+"${deps} "}$ppwd/$repo_urn" ;;
			# */*)
				# // die 'Not a package' "$repo_urn" ;;
			*)
				# // pkg_depends "deps" "makedeps" "$repo_urn" raw
				/ "IFS=$(printf '%b' "$FS") read -r "deps" "makedeps" \
				<< $(// here_doc -- pkg_depends \
						"$deps" "$makedeps" "$*" "$repo_urn" "raw")"
				> /dev/null || {
					// war 'pkg_depends' "failed"
					printf "\n%s$FS%s$FS%s$FS%s" "$order" "$redro" \
						"$deps" "$makedeps"
					interrupt
				}
				for item in $makedeps; do
					[ -d "$sys_db/$item" ] || (args i "$item")
				done
		esac
	done
	local index=0
	for item in $deps; do
		// log "\$deps $index" "$item"
		: $((index += 1))
	done

	// log '$*' "$*"
	# Filter the list, only keeping explicit packages. The purpose of these
	# two loops is to order the argument list based on dependence.
	for repo_urn in $@ $deps; do
		case " $* " in
			*" ${repo_urn} "*|*" ${repo_urn##*/} "*|*" ${repo_urn##"$ppwd/"} "*)
				contains "$order" "$repo_urn" ||
					order="${order:+"${order} "}$repo_urn"
				contains "$redro" "$repo_urn" ||
					redro="$repo_urn${redro:+" ${redro}"}"
		esac
	done

	// log '$order' "'$order'"
	// log '$redro' "'$redro'"

	# unset deps

	printf "\n%s$FS%s$FS%s$FS%s" "$order" "$redro" "$deps" "$makedeps"
}

pkg_strip() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	# Strip package binaries and libraries. This saves space on the system as
	# well as on the tarballs we ship for installation.
	[ ! -f "$MAKE_ROOT/$pkg_name/nostrip" ] || [ -z "${KISS_STRIP:+x}" ] ||
	! equ "${KISS_STRIP}" "0" || return 0

	// log "$1" "Stripping binaries and libraries"

	# Strip only files matching the below ELF types. This uses 'od' to print
	# the first 18 bytes of the file. This is the location of the ELF header
	# (up to the ELF type) and contains the type information we need.
	#
	# Static libraries (.a) are in reality AR archives which contain ELF
	# objects. We simply read from the same 18 bytes and assume that the AR
	# header equates to an archive containing objects (.o).
	#
	# Example ELF output ('003' is ELF type):
	# 0000000 177   E   L   F 002 001 001  \0  \0  \0  \0  \0  \0  \0  \0  \0
	# 0000020 003  \0
	# 0000022
	#
	# Example AR output (.a):
	# 0000000   !   <   a   r   c   h   >  \n   /
	# 0000020
	# 0000022
	while read -r file; do [ -h "$PKG_ROOT/$pkg_name$file" ] || case "$file" in
		# Look only in these locations for files of interest (libraries,
		# programs, etc). This includes all subdirectories. Old behavior
		# would run od on all files (upwards of 4000 for Python).
		*/sbin/?*[!/]|*/bin/?*[!/]|*/lib/?*[!/]|\
			*/lib??/?*[!/]|*/lib???/?*[!/]|*/lib????/?*[!/])

			case "$(od -A o -t c -N 18 "$PKG_ROOT/$pkg_name$file")" in
				# REL object files -- .o, static libraries -- .a.
				*"177"*"E"*"L"*"F"*"0000020\ 001\ "*|*"\!"*"\<"*"a"*"r"*"c"*"h"*"\>"*)
					// run strip -g -R .comment -R .note "$PKG_ROOT/$pkg_name$file" ;;

				# EXEC -- binaries, DYN -- shared libraries
				# Shared libraries keep global symbols in a separate ELF section
				# called '.dynsym'. '--strip-all/-s' does not touch the dynamic
				# symbol entries which makes this safe to do.
				*"177"*"E"*"L"*"F"*"0000020\ 00[23]\ "*)
					// run strip -s -R .comment -R .note "$PKG_ROOT/$pkg_name$file"
			esac
	esac done < "$PKG_ROOT/$pkg_name/$db/$pkg_name/manifest" || :
}

# could be subshell function before local version
# $1 repo_urn : package repo url/uri
pkg_fix_deps() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	# Dynamically look for missing runtime dependencies by checking each
	# binary and library with 'ldd'. This catches any extra libraries and or
	# dependencies pulled in by the package's build suite.
	// log "$pkg_name" "looking for dependencies (using ${cmd_elf##*/})"

	# "$PWD" == "$PKG_ROOT/$pkg_name/$db/$pkg_name"
	// log '$PWD' "$PWD"
	// log '$sys_db' "$sys_db"
	// log '$pkg_name' "$pkg_name"

	local depends_clone="$(// delegate -- slot_push "$pkg_name" "depends")"
	// log 'depends' "was pushed to \$depends_clone == \"$depends_clone\""

	local depends_fixed="$(// delegate -- slot_aquire "$pkg_name" "depends-fixed")"
	// log 'depends_fixed' "was aquired \$depends_fixed == \"$depends_fixed\""

	set +f
	set -f -- "$sys_db/"*/manifest

	local _fdep_seen= _file

	# False positive (not a write).
	# shellcheck disable=2094
	while read -r _file; do [ -h "$_file" ] || case "$_file" in
		# Look only in these locations for files of interest (libraries,
		# programs, etc). This includes all subdirectories. Old behavior
		# would run ldd on all files (upwards of 4000 for Python).
		*/sbin/?*[!/]|*/bin/?*[!/]|*/lib/?*[!/]|\
			*/lib??/?*[!/]|*/lib???/?*[!/]|*/lib????/?*[!/])

		// debug '$_file' "$_file"
		# [ "${_file:0:1}" == '/' ] || _file="${_file:1}"

		# The readelf mode requires ldd's output to resolve the library
		# path for a given file. If ldd fails, silently skip the file.
		local ldd=
		ldd="$(ldd -- "$PKG_ROOT/$pkg_name$_file" 2>/dev/null)" || continue

		# Attempt to get information from readelf. If this fails (or we
		# are in ldd mode), do full ldd mode (which has the downside of
		# listing dependencies of dependencies (and so on)).
		local elf=
		elf="$("$cmd_elf" -d "$PKG_ROOT/$pkg_name$_file" 2>/dev/null)" || elf=$ldd

		# Iterate over the output of readelf or ldd, extract file names,
		# resolve their paths and finally, figure out their owner.
		while read -r lib; do
			case "$lib" in *"NEEDED"*"\["*"\]"|*"=>"*)
				# readelf: 0x0000 (NEEDED) Shared library: [libjson-c.so.5]
				lib="${lib##*\[}"
				lib="${lib%%\]*}"

				# Resolve library path.
				# ldd: libjson-c.so.5 => /lib/libjson-c.so.5 ...
				case "$cmd_elf" in
					*"readelf")
						lib="${ldd#*"  $lib => "}" ;;
					*)
						lib="${lib##*"=> "}"
				esac
				lib="${lib%% *}"

				# Skip files owned by libc, libc++ and POSIX.
				case "${lib##*/}" in
					"ld-"*           |\
					"lib[cm].so"*    |\
					"libc++.so"*     |\
					"libc++abi.so"*  |\
					"libcrypt.so"*   |\
					"libdl.so"*      |\
					"libgcc_s.so"*   |\
					"libmvec.so"*    |\
					"libpthread.so"* |\
					"libresolv.so"*  |\
					"librt.so"*      |\
					"libstdc++.so"*  |\
					"libtrace.so"*   |\
					"libunwind.so"*  |\
					"libutil.so"*    |\
					"libxnet.so"*    |\
					"ldd")
						continue
				esac

				# Skip files we have seen before.
				case " $_fdep_seen " in
					*" $lib "*) continue ;;
					*) _fdep_seen="$_fdep_seen $lib"
				esac

				// resolve_path "$lib"

				# Skip file if owned by current package
				! // pkg_owner -e "$_rpath" manifest || continue

				! // pkg_owner -e "$_rpath" "$@" || printf '%s\n' "$_owns"

			esac
		done << EOF || :
$elf
EOF
		# esac done < <([ "$?" -eq 0 ] || :; printf "%s\n" "$elf") > /dev/null ||
		# // die 'printf "%s\n" "$elf"' "failed"
	esac done < manifest |
	# Sort the depends file (including the existing depends file) and
	# remove any duplicate entries. This can't take into account comments
	# so they remain rather than being replaced.
	sort -u -k 1,1 "$depends_clone" /dev/stdout > "$depends_fixed"

	[ ! -s "depends" ] || {
		local depends_list="$(cat depends)"
		for item in $depends_list; do
			// log "to fix" "$item"
		done
	}

	# If the depends file was modified, show a diff and replace it.
	[ ! -s "$depends_fixed" ] || {
		diff -U 3 "$depends_clone" "$depends_fixed" 2>/dev/null || :

		// log 'to be $depends_fixed' "$depends_fixed"
		# Replace the existing depends file if one exists, otherwise this
		# just moves the file to its final resting place.
		\mv -f "$depends_fixed" depends
		local depends_list="$(cat depends)"
		for item in $depends_list; do
			// log 'Fixed $item' "$item"
		done
		# Generate a new manifest as we may be the creator of the depends
		# file. This could otherwise be implemented by inserting a line
		# at the correct place in the existing manifest.
		# "$PWD" == "$PKG_ROOT/$pkg_name/$db/$pkg_name"
		// pkg_manifest "$PWD" "$PKG_ROOT"
	}
}

# Could be subshell function before local version
# $1 repo_urn                   : package repo url/uri
# $2 $PKG_ROOT / $EXTRACT_ROOT  : package directory / extracting directory
pkg_manifest() {
	_level_2
	# "$PKG_ROOT/$pkg_name/$db/$pkg_name"
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	# "$PKG_ROOT" or "$EXTRACT_ROOT"
	local repo_dir="$2"
	# "$PKG_ROOT/$pkg_name" or "$EXTRACT_ROOT/$pkg_name"
	local target_source="$repo_dir/$pkg_name"
	# Generate the package's manifest file. This is a list of each file
	# and directory inside the package. The file is used when uninstalling
	# packages, checking for package conflicts and for general debugging.
	// log "$pkg_name" "generating manifest"
	// log '$target_source' "$target_source"
	// log '$db' "$db"

	local manifest="$(// delegate -- slot_aquire "$pkg_name" "manifest")"
	local manifest_buffer="$(// delegate -- slot_aquire "$pkg_name" "manifest_buffer")"

	local version_list=
	for item in $(// as_own "$target_source" \
		find "$target_source/$db/$pkg_name" -mindepth 1 -maxdepth 1 -type d); do
		local folder="${item##*/}"
		// log '$folder' "$folder"
		[ ! -z "${folder##*"-"*}" ] || {
			// log '$folder' "$folder [selected]"
			local head="${folder%%-*}"
			local tail="${folder##*-}"
			echo "head: $head, tail $tail"
			! is_version "$head" || ! is_version "$tail" ||
			version_list="${version_list:+"$version_list$newline"}$folder"
		}
	done

	// log '$version_list' "$version_list"
	local folder_clause="find \"$target_source\" -type d -not \( -path \"$target_source\" -type d \)"
	local file_clause="! -type d -a ! -name \\*.la -a ! -name charset.alias"
	local ifs="$IFS"
	local IFS="$newline"
	local item
	for item in $version_list; do
		folder_clause="$folder_clause -not \( -path \"*/$item\" -type d -prune \)"
		file_clause="$file_clause -a ! -path \"*/$item/*\""
	done
	IFS="$ifs"
	local find_clause="$folder_clause -exec printf '%s/\n' {} + -o \( $file_clause \) -print"

	// log '$find_clause' "$find_clause"

	# Create a list of all files and directories. Append '/' to the end of
	# directories so they can be easily filtered out later. Also filter out
	# all libtool .la files and charset.alias.
	{
		printf '%s\n' "/$db/$pkg_name/manifest"

		[ ! -d "$target_source/etc" ] ||
		printf '%s\n' "/$db/$pkg_name/etcsums"

		# No folder printed
		# // as_own "$target_source" find "$target_source" \
		#   -type f \
		#   -not \( -path "$target_source" -o -path "*/*-*/*" \) -type d -prune \
		#   -exec printf '%s/\n' {} + \
		#   -o \( ! -type d -a ! -name \*.la -a ! -name charset.alias -a ! -path "*/*-*/*" \) \
		#   -print | sed "s#${target_source}##g"
		#
		# Don't quote $find_clause [ "command not found" error ]
		# / "// as_own \"$target_source\" \"$find_clause\" | sed \"s#${target_source}##g\""
		/ "// as_own \"$target_source\" $find_clause | sed \"s#${target_source}##g\""

		# Sort the output in reverse. Directories appear after their contents.
	} | sort -ur > "$manifest_buffer"

	local index=0
	while read -r line; do
		: $((index += 1))
		[ ! -z "${line##*"${target_source}"*}" ] || {
			// log '$manifest_buffer' "$(delegate -- format "$index") $line"
			# break
			// die '$manifest_buffer' \
				"'${target_source}' should not appear${newline}\
				Maybe the build script has PREFIX=\"\$1/usr\" which should be PREFIX=\"/usr\""
		}
	done < "$manifest_buffer"

	[ -s "$manifest_buffer" ] || // die '$manifest_buffer' "'$manifest_buffer' is empty"

	[ ! -s "$manifest" ] ||
	cat "$manifest" >> "$manifest_buffer"

	sort -ur < "$manifest_buffer" > "$manifest"

	# // log '$manifest' "$manifest"
	[ -s "$manifest" ] || // die '$manifest' "'$manifest' is empty"

	local index=0
	while read -r line; do
		: $((index += 1))
		// log '$manifest' "$(delegate -- format "$index") $line"
	done < "$manifest"

	// as "$SRC_USER" /usr/bin/touch "$target_source/$db/$pkg_name/manifest"
	# Remove the prefix from each line.
	while read -r file; do
		// as "$SRC_USER" printf '%s\n' "${file#"$target_source"}"
	done < "$manifest" > "$target_source/$db/$pkg_name/manifest"
}

# $1 $pkg_name
manifest_validate() {
	_level_2
	# NOTE: pkg_name comes from caller.
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	// log "$pkg_name" "checking if manifest valid"

	// log '$EXTRACT_ROOT/$pkg_name' "$EXTRACT_ROOT/$pkg_name"
	// log 'manifest file' "$db/$pkg_name/manifest"

	shift 1

	local tar_manifest="$EXTRACT_ROOT/$pkg_name/$db/$pkg_name/manifest"
	[ -f "$EXTRACT_ROOT/$pkg_name/$db/$pkg_name/manifest" ] ||
	// die '$tar_manifest' "'$tar_manifest' does not exist"
	local index=0
	while read -r line; do
		[ -e "$EXTRACT_ROOT/$pkg_name$line" ] ||
		[ -h "$EXTRACT_ROOT/$pkg_name$line" ] || {
			: $((index += 1))
			// log '$tar_manifest' "$(delegate -- format "$index") $line"
			set -- "$@" "$line"
		}
	done < "$tar_manifest"

	for f do
		// log '$f' "$f"
		// die "$pkg_name" "manifest contains $# non-existent files"
	done
}

manifest_replace() {
	_level_2
	# Replace the matching line in the manifest with the desired replacement.
	# This used to be a 'sed' call which turned out to be a little
	# error-prone in the some cases. This new method is a tad slower but ensures
	# we never wipe the file due to a command error.
	local manifest_replace_buffer="$( \
		// delegate -- slot_aquire "$pkg_name" "manifest-replace-${2##*/}")"

	while read -r line; do
		! equ "$line" "$2" || line=$3

		printf '%s\n' "$line"
	done < "$sys_db/$1/manifest" | sort -r > "$manifest_replace_buffer"

	mv -f "$manifest_replace_buffer" "$sys_db/$1/manifest"
}

# "$@" :
pkg_etcsums() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	# Generate checksums for each configuration file in the package's /etc/
	# directory for use in "smart" handling of these files.
	// log "$pkg_name" "generating etcsums"
	shift "$(($# >= 1? 1 : $#))"

	# Minor optimization - skip packages without /etc/.
	[ -d "$PKG_ROOT/$pkg_name/etc" ] || return 0

	# Create a list of all files in etc but do it in reverse.
	while read -r etc; do case "$etc" in "/etc/"*[!/])
		set -- "$PKG_ROOT/$pkg_name/$etc" "$@"
	esac done < "$PKG_ROOT/$pkg_name/$db/$pkg_name/manifest"

	local hash="$(// delegate -- "sh256" "$@")"
	as "$SRC_USER" sh -c "printf '%s\\n' \"$hash\" \
		> \"$PKG_ROOT/$pkg_name/$db/$pkg_name/etcsums\""
}

# $1 repo_urn : package repo url/uri
pkg_tar() {
	_level_2
	// log '$pkg_name' "$pkg_name [global]"
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	// log '$pkg_name' "$pkg_name [local]"

	# Create a tarball from the built package's files. This tarball also
	# contains the package's database entry.
	#
	# NOTE: repo_ comes from caller.
	// log "$pkg_name" "tarball creating"
	# tree "$PKG_ROOT"

	local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir repo_ver repo_rel \
		repo_alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn")"
		> /dev/null || // die 'pkg_version' "failed"
	ok "$repo_ver" || // die '$repo_ver' "$repo_ver"
	local file_name="$pkg_name@$repo_ver-$repo_rel.tar.$KISS_COMPRESS"
	local tar_file="$TAR_ROOT/$pkg_name/$file_name"

	set --
	local tar_dir_user="$(// delegate owner "$TAR_ROOT")"
	[ "$LOGNAME" = "$tar_dir_user" ] || {
		// ownership "$TAR_ROOT" "$PWD"
		set -- $(// delegate as_user "$tar_dir_user")
	}

	[ -d "$TAR_ROOT/$pkg_name" ] ||
		"$@" \mkdir -p "$TAR_ROOT/$pkg_name"
	local repofile="repo.index"

	# Use 'cd' to avoid needing tar's '-C' flag which may not be portable
	# across implementations.
	cd "$PKG_ROOT/$pkg_name" || // war '$repo_urn' "can not change directory to \"$repo_urn\""
	// log '$PWD' "$PWD"
	# Create a tarball from the contents of the built package.
	# /etc/... files miight need root privilege
	// as "root" /usr/bin/tar cf - . | case $KISS_COMPRESS in
		bz2)  "$@" bzip2  -z     ;;
		gz)   "$@" gzip   -6     ;;
		lzma) "$@" lzma   -zf    ;;
		lz)   "$@" lzip   -z     ;;
		xz)   "$@" xz     -zT0f  ;;
		zst)  "$@" zstd   -z     ;;
	esac > "$tar_file"

	# Remove any instances of this package in the index
	# This will leave only the latest version
	"$@" touch "$TAR_ROOT/$pkg_name/$repofile"
	"$@" sed -i "/$pkg_name@/d" "$TAR_ROOT/$pkg_name/$repofile"

	# Write the checksum to the repo file
	local cs="$(// delegate -- "_sh256" "$tar_file")"
	"$@" echo "$cs  $file_name" >> "$TAR_ROOT/$pkg_name/$repofile"
	// log "$pkg_name" "repo index updated"

	cd "$OLDPWD"

	// log "$pkg_name" "tarball created successfully"
	// log '$tar_file' "$tar_file"

	# arg1: post-package
	# arg2: package name
	# arg3: path to tarball
	// run_hook post-package "$pkg_name" "$tar_file"
}

# Make sure "$explicit" -- the return packages all was built
# "$@" packages repo url/name
build_all() {
	_level_2

	local action="build"
	# Implicit build packages
	local deps="$1"
	local makedeps="$2"
	shift 2
	# A minimal set of input packages
	local explicit=
	local expected_to_be_built_and_only_being_built="$*"
	local mandatory_explicit_build=

	# Build packages and turn them into packaged tarballs.
	# Order the argument list and filter out duplicates.

	# Mark packages passed on the command-line explicit.
	# Also resolve dependencies for all explicit packages.
	for repo_urn do
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		// pkg_dirs "$action" "$pkg_name"
		// pkg_clear "$action" "$repo_urn"
		/ "IFS=$(printf '%b' "$FS") read -r deps makedeps \
		<< $(// here_doc -- pkg_depends \
			"$deps" "$makedeps" "$*" "$repo_urn" "expl" "filter")" || {
			// war 'pkg_depends' "failed"
			interrupt
		}

		explicit="${explicit:+"${explicit} "}$repo_urn"
	done

	// log '$deps' "$deps"
	// log '$explicit' "$explicit"

	# If this is an update, don't always build explicitly passsed packages
	# and instead install pre-built binaries if they exist.
	[ -n "${prefer_cache:+x}" ] || mandatory_explicit_build=$explicit

	# Host dependencies
	# If cross building, make sure the build machine has the correct deps
	set -- $makedeps
	// log '$makedeps' "$makedeps"
	// log '$#' "$# after \"set -- \$makedeps\""
	[ "$#" -le 0 ] ||
	// die "You need the following packages on your build machine" "$*"

	set --

	# If an explicit package is a dependency of another explicit package,
	# remove it from the explicit list.
	for repo_urn in $explicit; do
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		contains "$deps" "$pkg_name" ||
		contains "$deps" "$repo_urn" ||
		set -- "$@" "$repo_urn"
	done
	explicit_count=$#
	explicit=$*

	// log '$explicit_count' "$explicit_count"

	// log 'explicit' "$(echo "$explicit" | tr ' ' "$newline")"
	// log 'implicit' "$(echo "$deps"     | tr ' ' "$newline")"

	# Intentional, globbing disabled.
	# shellcheck disable=2046,2086
	# pseudo code: set --  implicits explicits
	set -- $deps "$@"
	// log '$@' "$(esceval "$@")"
	# Ask for confirmation if extra packages need to be built.
	# equ "$#" "$explicit_count" ||
	# { // war 'targets' "$(echo "$*" | tr ' ' "$newline")"; // prompt; }
	equ "$#" "$explicit_count" ||
	local content="$(// delegate -- prompt \
			"\$explicit_count = $explicit_count <= \$# = $#${newline}\
			looks good, right?")"
	# // prompt "content" "(\$explicit_count == $explicit_count) != (\$# == $#)"

	! expr "$content" : '[n|N]\+' > /dev/null || return 0

	// log "checking for pre-built dependencies"
	# Percent of packages in "$@"
	# explicit             deps
	# \\\\\\\\\\\\\\\\\\\\ %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	# expected_to_be_built_and_only_being_built
	# \\\\\\\\\\\\\\\\\\\\ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
	# Install any pre-built dependencies if they exist in the binary
	# directory and are up to date.
	# Intended behavior.
	# shellcheck disable=2030,2031
	for repo_urn in $@; do
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"

		local format= reference_type=
		/ "IFS=$(printf '%b' "$FS") read -r \
			format reference_type \
			<< $(// here_doc -- pkg_format "$repo_urn")"
		> /dev/null || { // die 'pkg_format' "failed"; exit 1; }

		# local tar_file="$(// delegate -- pkg_cache "$repo_urn")"

		# // war  '$mandatory_explicit_build' "$mandatory_explicit_build"
		# if ! contains "$expected_to_be_built_and_only_being_built" "$repo_urn" &&
		if
			{ ! equ "git" "$format" || equ "tag" "$reference_type"; } &&
			! contains "$explicit" "$repo_urn" &&
			# ok "$tar_file" &&[ -z "${KISS_FORCE+x}" ]; then
			ok "$(// delegate -- pkg_cache "$repo_urn")"; then
			// log "$pkg_name" "found pre-built binary"

			# Refer to "expl_alter" -- that is to say,
			# remember to remove the current repo_urn from explicit list, please

			# Eg., for repos outside REPO_MAIN
			(export KISS_FORCE=; // args i "$repo_urn")
			# If use "$expected_to_be_built_and_only_being_built" as container
			# It might be empty (less than "$explicit")
			# local expl_alter=
			# for item in $explicit; do
			#     equ "$repo_urn" "$item" ||
			#     expl_alter="${expl_alter:+"${expl_alter} "}$item"
			# done
			# explicit="$expl_alter"
		else

			local pkg_name_string="$(echo "$pkg_name" | sed 's/-/_/g')"
			[ -n "$(/ echo \${synchronized_${pkg_name_string}-})" ] ||
			// pkg_download "$repo_urn"

			[ ! -f "$repo_urn/sources" ] ||
			[ "$format" = "git" ] ||
			// checksums_verify "$repo_urn"

			set -- "$@" "$repo_urn"
		fi
		shift
	done

	# Merged to upward
	# for repo_urn do
	#   local pkg_name="${repo_urn##*/}"

	#   local pkg_name_string="$(echo "$pkg_name" | sed 's/-/_/g')"
	#   [ -n "$(/ echo \${synchronized_${pkg_name_string}-})" ] ||
	#   // pkg_download "$repo_urn"

	#   pkg_name="${pkg_name%%@*}"

	#   is_repos "$repo_urn" ||
	#       repo_urn="$(// delegate -- repo_trace "$pkg_name")"

	#   # local format="$(// delegate -- pkg_format "$repo_urn")"
	#   local format= reference_type=
	#   / "IFS=$(printf '%b' "$FS") read -r \
	#       format reference_type \
	#       << $(// here_doc -- pkg_format "$repo_urn")"
	#   > /dev/null || { // die 'pkg_format' "failed"; exit 1; }

	#   [ ! -f "$repo_urn/sources" ] ||
	#   [ "$format" = "git" ] ||
	#   // checksums_verify "$repo_urn"
	# done

	[ -z ${KISS_ROOT:+x} ] || // log '$KISS_ROOT' "$KISS_ROOT"
	# Building on host (cross build)
	[ -z ${KISS_XBUILD_TRIPLE:+x} ] ||
	// log '$KISS_XBUILD_TRIPLE' "$KISS_XBUILD_TRIPLE"
	# Building for target (cross host)
	[ -z ${KISS_XHOST_TRIPLE:+x} ]  ||
	// log '$KISS_XHOST_TRIPLE' "$KISS_XHOST_TRIPLE"
	// log '$TAR_ROOT' "$TAR_ROOT"
	// log '$BIN_ROOT' "$BIN_ROOT"
	[ -z ${CC:+x} ]      || // log '$CC'       "$CC"
	[ -z ${CXX:+x} ]     || // log '$CXX'      "$CXX"
	[ -z ${CFLAGS+x} ]   || // log '$CFLAGS'   "$CFLAGS"
	[ -z ${CXXFLAGS+x} ] || // log '$CXXFLAGS' "$CXXFLAGS"
	[ -z ${LDFLAGS+x} ]  || // log '$LDFLAGS'  "$LDFLAGS"

	# Finally build and create tarballs for all passed packages and
	# dependencies.
	local _build_cur
	for repo_urn do
		// log '$repo_urn' \
			"building package \"$repo_urn\" ($((_build_cur+=1))/$#)"

		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		is_repos "$repo_urn" ||
			repo_urn="$(// delegate -- repo_trace "$pkg_name")"
		ok "$repo_urn" || // die '$repo_urn' "$repo_urn"

		# arg1: queue-status
		# arg2: package name
		# arg3: number in queue
		# arg4: total in queue
		// run_hook queue "$pkg_name" "$_build_cur" "$#"

		// log '$repo_urn' "$repo_urn [local]"
		[ -d "$repo_urn" ] ||
			// die '$repo_urn' "not found ${repo_urn:+"${repo_urn} "}[local]"
		[ ! -f "$repo_urn/sources" ] || // pkg_load "$repo_urn"

		// log '$db' "$db"
		// log '$PWD' "$PWD"
		// pkg_build "$repo_urn" || ! break
		// pkg_manifest "$repo_urn" "$PKG_ROOT"
		// pkg_strip "$repo_urn"

		cd "$PKG_ROOT/$pkg_name/$db/$pkg_name"
		// pkg_fix_deps "$repo_urn"
		// pkg_etcsums  "$repo_urn"
		// pkg_tar      "$repo_urn"

		# Broke the mandatory explicit build policy
		[ -z "${prefer_cache:+x}" ] &&
		contains "$explicit" "$repo_urn" || {
			// log "$repo_urn" "Needed as a dependency or has an update, installing"

			# Intended behavior.
			# shellcheck disable=2030,2031
			(export KISS_FORCE=""; // args i "$repo_urn")
		}
	done

	[ "$?" -eq "0" ] ||
		# // die 'pkg_build' "failed"
		interrupt

	for item in $explicit; do
		// log 'explicit' "$item"
	done

	# Intentional, globbing disabled.
	# shellcheck disable=2046,2086
	[ -z "${install_on_build:+x}" ] ||
	is_pick "$CROSS_ACTION" || {
		# KISS_PROMPT statement moved to prompt()
		# if [ -n "${KISS_PROMPT+x}" ] && equ "$KISS_PROMPT" 0; then
		#     (export KISS_FORCE=; // args i $explicit)
		# else
		# ! // prompt "content" "Install built packages? [$explicit]" ||
		# // prompt "content" "Install built packages? [$explicit]"
		local content="$(// delegate -- prompt "Install built packages? [$explicit]")"
		expr "$content" : '[n|N]\+' > /dev/null ||
		(export KISS_FORCE=""; // args i $explicit)
		# fi
	}
}

header_correct() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	shift 1
	set --
	local build_file_user="$(// delegate owner "$repo_urn/build")"
	// log '$LOGNAME' "$LOGNAME"
	// log '$build_file_user' "$build_file_user"
	[ "$LOGNAME" = "$build_file_user" ] ||
	set -- $(// delegate as_user "$build_file_user")
	// log '$@' "$(esceval "$@")"
	#
	# The "ENV" version needs build script header to be "#! /bin/sh -i"
	# Modify headers to "fail on error" and interactive mode

	// is_writable "$repo_urn" || return 0

	local expect_option_shebang="-e"
	[ -z "${USE_ENV+x}" ] || expect_option_shebang="-i"

	local found_plus_e=0
	local found_minus_e=0
	local found_expect_option_shebang=0

	local first_line
	first_line="$(sed "1q" "$repo_urn/build")"

	local cmd option_shebang
	cmd="$(printf %s "$first_line" |
	tr -d "#!" |
	awk "{print \$1}" | tr -d " ")"
	// log '$cmd' "$cmd"
	option_shebang="${first_line##* }" || // die '$first_line' "$first_line"
	// log '$option_shebang' "$option_shebang"
	[ -n "${first_line:+x}" ] &&
	[ -z "${first_line##*sh*}" ] &&
	command -v "$cmd" > /dev/null 2>&1 &&
	[ "$option_shebang" = "$expect_option_shebang" ] || {
		// war '$first_line' "'$first_line' looks not correct"
		case "$first_line" in
			*"/bin/sh"*|*"ash"*|*"sh"*|*"/env"*|*"/usr"*|*"/bin"*|*"/proc"*|*"/exe"*)
				# Redirection will not repect the current user's ownership
				"$@" sed -i -e "s|$first_line|#! /bin/sh $expect_option_shebang|g" "$repo_urn/build"
				# "$@" sed -e "s|$first_line|#! /bin/sh $expect_option_shebang|g" < "$repo_urn/build" > _
				# "$@" mv -f _ "$repo_urn/build"
				: $((found_expect_option_shebang += 1))
				;;
			*)
				# https://unix.stackexchange.com/questions/99350/how-to-insert-text-before-the-first-line-of-a-file
				"$@" sed -i "1 {i\\n#! /bin/sh -$expect_option_shebang}" "$repo_urn/build"
				# "$@" sed "1 {i\\n#! /bin/sh -$expect_option_shebang}" < "$repo_urn/build" > _
				# "$@" mv -f _ "$repo_urn/build"
				: $((found_expect_option_shebang += 1))
				;;
		esac
	}

	first_line="$(sed "1q" "$repo_urn/build")"
	// log '$first_line' "$first_line"
	option_shebang="${first_line##* }" || // die '$first_line' "$first_line"
	// log '$option_shebang' "$option_shebang"

	[ "$option_shebang" = "-e" ] && found_minus_e=1
	#
	local ifs="$IFS"
	local IFS="$newline"
	# Remove duplicated shebangs
	local index=0
	local option_line_number
	for option_line_number in $(
		grep -En "#! /bin/sh $expect_option_shebang" "$repo_urn/build" |
		awk -F ":" "{print \$1}"
	); do
		: $((index += 1))
		[ "$index" -le "1" ] ||
		"$@" sed -i -e "${option_line_number}d" "$repo_urn/build"
	done

	local option_line
	local index=0
	# while read -r option_line || [ -n "${option_line:+x}" ]; do
	for option_line in $(grep -E "set\ \+*" "$repo_urn/build" | grep -v "#"); do
		: $((index += 1))
		// log '$index : $option_line' "$index : $option_line"
		case "$option_line" in
			*"+e")
				: $((found_plus_e += 1))
				[ "$expect_option_shebang" = "-e" ] &&
				"$@" sed -i -e "/$option_line/d" "$repo_urn/build"
				# Rplace it
				[ "$expect_option_shebang" = "-i" ] && {
					"$@" sed -i -e "s|$option_line|set -e|g" "$repo_urn/build"
					: $((found_minus_e += 1))
				}
				# "$@" sed -e "s|$option_line|set -e|g" < "$repo_urn/build" > _
				# [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
				# // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
				# "$@" mv -f _ "$repo_urn/build"
				;;
			*"+"*"e"*)
				: $((found_plus_e += 1))
				# Append new set -e
#                         sed -e "/$option_line/s/.*/&\\
# set -e/" < "$repo_urn/build" > _
				# sed -e "/$option_line/s/.*/&\\nset -e/" < "$repo_urn/build" > _
				# : $((found_minus_e += 1))
				# Pick it out
				local option
				option="${option_line##* }" || // die '$option_line' "$option_line"
				option="$(echo "$option" | tr -d "e")"
				"$@" sed -i -e "s|$option_line|set $option|g" "$repo_urn/build"
				# "$@" sed -e "s|$option_line|set $option|g" < "$repo_urn/build" > _
				# [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
				# // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
				# "$@" mv -f _ "$repo_urn/build"
				;;
			*"-e")
				: $((found_minus_e += 1))
				[ "$found_minus_e" -le "1" ] || {
					# Remove it
					"$@" sed -i -e "/$option_line/d" "$repo_urn/build"
					# "$@" sed "/$option_line/d" < "$repo_urn/build" > _
					# [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
					# // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
					# "$@" mv -f _ "$repo_urn/build"
					: $((found_minus_e -= 1))
				}
				;;
			*"-"*"e"*)
				: $((found_minus_e += 1))
				[ "$found_minus_e" -le "1" ] || {
					# Pick it out
					local option
					option="${option_line##* }" || // die '$option_line' "$option_line"
					option="$(echo "$option" | tr -d "e")"
					"$@" sed -i -e "s|$option_line|set $option|g" "$repo_urn/build"
					# "$@" sed -e "s|$option_line|set $option|g" < "$repo_urn/build" > _
					# [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
					# // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
					# "$@" mv -f _ "$repo_urn/build"
					: $((found_minus_e -= 1))
				}
		esac
	done
	# done < <(printf '%s\n' "$(grep -E "set\ \+*" "$repo_urn/build" | grep -v "#")")
#   done << EOF
# $(grep -E "set\ \+*" "$repo_urn/build" | grep -v "#")
# EOF
# https://stackoverflow.com/questions/58619925/grep-words-with-spaces
# $(grep -E 'set +*' "$repo_urn/build" | grep -v "#")
# $(sed "2q" "$repo_urn/build")
#
	local IFS="$ifs"
	# Too simplistic
	# grep "set *" "$repo_urn/build" | awk "{print \$2}" | grep -v "#" | grep "-" | grep -q "e" || {
	#     sed -e "s|set -.*|set -e|g" < "$repo_urn/build" > _
	#     [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
	#     // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
	#     mv -f _ "$repo_urn/build"
	# }
	#
	# If USE_ENV, then mkae sure "set -e" must exist
	// log '$found_minus_e' "$found_minus_e"
	[ -z "${USE_ENV+x}" ] ||
	[ "$found_minus_e" -gt "0" ] || {
		# https://stackoverflow.com/questions/15559359/insert-line-after-match-using-sed
		# https://stackoverflow.com/questions/16202900/using-sed-between-specific-lines-only#
		"$@" sed -i -e '1,1 {/#! \/bin\/sh -i/s/.*/&\nset -e/}' "$repo_urn/build"
		# "$@" sed '1,1 {/#! \/bin\/sh -i/s/.*/&\nset -e/}' < "$repo_urn/build" > _
		# [ "$(wc -l _ | awk "{print \$1}")" -le "1" ] &&
		# // die 'file' "'$repo_urn/build' cleared by wrong operation" ||
		# "$@" mv -f _ "$repo_urn/build"
	}
}

# could be subshell function before local version
# $1 repo_urn : package repo url/uri
pkg_build() {
	_level_2
	local action="build"
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	ok "$repo_urn" || // die '$repo_urn' "$repo_urn"
	# Install built packages to a directory under the package name to
	# avoid collisions with other packages.

	local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
	/ "IFS=$(printf '%b' "$FS") read -r \
		repo_dir repo_ver repo_rel \
		repo_alias repo_url reference_type \
		<< $(// here_doc -- pkg_version "$repo_urn")"
	> /dev/null || // die 'pkg_version' "failed"

	// log '$PKG_ROOT' "$PKG_ROOT"
	// log '$TAR_ROOT' "$TAR_ROOT"
	// log '$OBJ_ROOT' "$OBJ_ROOT"
	// log '$BIN_ROOT' "$BIN_ROOT"
	// log '$log_dir' "$log_dir"
	// log '$PROC_ROOT/$pkg_name' "$PROC_ROOT/$pkg_name"
	// log '$MAKE_ROOT/$pkg_name' "$MAKE_ROOT/$pkg_name"
	// log '$repo_urn' "$repo_urn [local]"
	// log '$pkg_name' "$pkg_name"
	// log '$repo_ver' "$repo_ver"
	// log '$db' "$db"
	// log '$LOGNAME' "$LOGNAME"
	// log '$PKG_ROOT/$pkg_name/$db/$pkg_name' "$PKG_ROOT/$pkg_name/$db/$pkg_name"

	# empty "$PKG_ROOT/$pkg_name" ||
	# for item in $(// as_own "$PKG_ROOT" find "$PKG_ROOT/$pkg_name" -mindepth 1 -maxdepth 1); do
	#   // as_own "$item" \rm -rf "$item"; done

	// mkcd "$MAKE_ROOT/$pkg_name" "$PKG_ROOT/$pkg_name/$db/$pkg_name"

	// cue "$pkg_name" "starting build"

	[ -n "${REPO_DIR:+x}" ] || ! is_repos "$repo_urn" ||
	REPO_DIR="${repo_urn%/*}"

	// log '$REPO_DIR' "$REPO_DIR"

	# arg1: pre-build
	# arg2: package name
	# arg3: path to build directory
	// run_hook     pre-build "$pkg_name" "$MAKE_ROOT/$pkg_name"
	// run_hook_pkg pre-build "$pkg_name" "$repo_ver" "$repo_rel" "$MAKE_ROOT"

	# Attempt to create the log file early so any permissions errors are caught
	# before the build starts. 'tee' is run in a pipe and POSIX shell has no
	# pipe-fail causing confusing behavior when tee fails.
	# Log has been created when script booted
	# : > "$user_output"

	[ -z "${USE_GMAKE+x}" ] || {
		// log "GNU make used"
		[ "$(readlink -f "$BIN_ROOT/$pkg_name/gunzip")" = "/usr/bin/pigz"  ] ||
			// as "$SRC_USER" \
				/usr/bin/ln -sf "/usr/bin/pigz" "$BIN_ROOT/$pkg_name/gunzip"
		[ "$(readlink -f "$BIN_ROOT/$pkg_name/make")"   = "/usr/bin/gmake" ] ||
			// as "$SRC_USER" \
				/usr/bin/ln -sf "/usr/bin/gmake" "$BIN_ROOT/$pkg_name/make"
		export PATH="$BIN_ROOT/$pkg_name:$PATH"
	}

	local build_state=0
	printf '%s\n' "0" > "$KISS_TMPDIR/logs/build_state"

	# Call the build script, log the output to the terminal and to a file.
	# There's no PIPEFAIL in POSIX shell so we must resort to tricks like kill.
	# Will shield "set -e"
	# {

	// header_correct "$repo_urn"
	# // trap_on "$action" "$pkg_name"
	// log '$LOGNAME' "$LOGNAME"
	# // log '$LOGNAME' "$LOGNAME"
	// log '$_KISS_LVL' "$_KISS_LVL [before into \"$action\" subshell]"
	// log '$PWD' "$PWD"
	# Give the script a modified environment. Define toolchain program
	# environment variables assuming a generic environment by default.

	# COLOR_PARENT="$COLOR_PARENT" \
	# COLOR_CHILD="$COLOR_CHILD" \
	# COLOR_END="$COLOR_END" \
	# COLOR_LINE="$COLOR_LINE" \
	# KISS_COMPRESS="$KISS_COMPRESS" \
	# cmd_su="$cmd_su" \
	# cmd_elf="$cmd_elf" \
	# cmd_sha="$cmd_sha" \
	# cmd_get="$cmd_get" \
	# KISS_TMPDIR="$KISS_TMPDIR" \
	# PID_LOG="$PID_LOG" \
	# PID_SAY="$PID_SAY" \

	# [ -z "${KISS_INNER_PIPE:+x}" ] || {
	# PID_SAY="$PID_SAY" \
	# PID_LOG="$PID_LOG" \
	# }
	# Define DESTDIR and GOPATH to sane defaults as their use is mandatory
	# in anything using autotools, meson, cmake, etc. Define KISS_ROOT as
	# the sanitized value used internally by the package manager. This is
	# safe to join with other paths.
	#
	# KISS_PATH=\"$KISS_PATH\" \
	# _KISS_LVL=\"$((_KISS_LVL + 1))\" \
	# SESSION_PPID=\"$SESSION_PPID\" \
	# USER_OUTPUT=\"$USER_OUTPUT\" \
	# SHELL_OPTIONS=\"e$(printf '%s' "$-")\" \
	#
	# This step is useless for source build
	local env_variables=" AR=\"${AR:-ar}\" "
	env_variables="$env_variables CC=\"${CC:-cc}\" "
	env_variables="$env_variables CXX=\"${CXX:-c++}\" "
	env_variables="$env_variables CFLAGS=\"${CFLAGS:-" -O3 -pipe -fPIC "}\" "
	env_variables="$env_variables CXXFLAGS=\"${CXXFLAGS:-" -O3 -pipe -fPIC "}\" "
	env_variables="$env_variables LDFLAGS=\"${LDFLAGS-}\" "
	env_variables="$env_variables NM=\"${NM:-nm}\" "
	env_variables="$env_variables RANLIB=\"${RANLIB:-ranlib}\" "
	env_variables="$env_variables DES_ROOT=\"$DES_ROOT\" "
	env_variables="$env_variables RUSTFLAGS=\"--remap-path-prefix=$PWD=. ${RUSTFLAGS-}\" "
	env_variables="$env_variables GOFLAGS=\"-trimpath -modcacherw ${GOFLAGS-}\" "
	env_variables="$env_variables GOPATH=\"${GOPATH:-"$PWD/go"}\" "
	env_variables="$env_variables PATH=\"${GOPATH:-"$PWD/go"}/bin:$PATH\" "
	env_variables="$env_variables KISS_ROOT=\"$KISS_ROOT\" "
	env_variables="$env_variables REPO_MAIN=\"$REPO_MAIN\" "
	env_variables="$env_variables KISS_XHOST_ARCH=\"$KISS_XHOST_ARCH\" "
	env_variables="$env_variables KISS_XBUILD_ARCH=\"$KISS_XHOST_ARCH\" "
	env_variables="$env_variables CHOST=\"$KISS_XHOST_TRIPLE\" "
	env_variables="$env_variables CBUILD=\"$KISS_XBUILD_TRIPLE\" "
	env_variables="$env_variables KISS_XHOST_ABI=\"$KISS_XHOST_ABI\" "
	env_variables="$env_variables KISS_XBUILD_ABI=\"$KISS_XBUILD_ABI\" "
	env_variables="$env_variables KISS_XHOST_TRIPLE=\"$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI\" "
	env_variables="$env_variables KISS_XBUILD_TRIPLE=\"$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI\" "
	env_variables="$env_variables SESSION_PID=\"$SESSION_PID\" "
	env_variables="$env_variables KISS_PID=\"$KISS_PID\" "
	env_variables="$env_variables CROSS_ACTION=\"${CROSS_ACTION:-"$action"}\" "
	env_variables="$env_variables SHELL_OPTIONS=\"$SHELL_OPTIONS\" "
	env_variables="$env_variables REPO_BASE=\"$REPO_BASE\" "
	env_variables="$env_variables REPO_DIR=\"$REPO_DIR\" "
	env_variables="$env_variables SRC_ROOT=\"$SRC_ROOT\" "
	env_variables="$env_variables MAKE_ROOT=\"$MAKE_ROOT\" "
	env_variables="$env_variables OBJ_ROOT=\"$OBJ_ROOT\" "
	env_variables="$env_variables DESTDIR=\"$PKG_ROOT/$pkg_name\" "
	env_variables="$env_variables XBPS_CROSS_BASE=\"$KISS_ROOT\" "

	local go_depends=1
	[ ! -f "$repo_urn/depends" ] ||
	for item in $(cat "$repo_urn/depends" | awk '$2 != "" {print $2}'); do
		[ "$item" != "go" ] || { go_depends=0; break; }
	done
	[ "$pkg_name" != "go" ] &&
	[ "$go_depends" -eq "1" ] || {
		local ifs="$IFS"
		local IFS="$newline"
		for item in $(go env); do
			env_variables="$env_variables $(printf '%s' "$item") "
				# $(printf '%s' "$item" | awk 'gsub(/"/, "\\\"") {print $0}') \
		done
		IFS="$ifs"
	}
	[ -z "${DEBUG_AT_BACKGROUND+x}" ] ||
		env_variables="$env_variables DEBUG_AT_BACKGROUND=\"$DEBUG_AT_BACKGROUND\" "
	local result
	# run_series \
	set +f
	# [ -z "${USE_ENV+x}" ] && {
		# The non "ENV" version does not need build script header to be "#! /bin/sh -i"
		# Pay attention to name conflictions with the current environment
		// log 'sourcing' "/usr/include/kiss-abuild"
		# shellcheck source=/usr/include/kiss-abuild
		. "/usr/include/kiss-abuild" "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1
		// log 'sourcing' "/usr/include/kiss-vbuild"
		#
		# vbuild is not POSIX
		# shellcheck source=/usr/include/kiss-vbuild
		# . "/usr/include/kiss-vbuild" "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1
		#
		// log 'sourcing' "$repo_urn/build"
		// log '$env_variables' "$env_variables"
		# // log '$env_variables' "$(/ "printf '%s\n' \"$env_variables\"")"
		# // log '$env_variables' "$( \
		#   local ifs="$IFS"
		#   local IFS=$newline
		#   / "IFS=$newline printf '%s\n' \"$env_variables\""
		#   IFS="$ifs"
		# )"
		#
		# Won't interpret $newline
		# // log '$env_variables' "$(/ 'printf "%s\n" "$env_variables"')"
		#
		# export $env_variables || // die '$env_variables' "$env_variables"
		#
		# export    AR="${AR:-ar}"
		# export    CC="${CC:-cc}"
		# export    CXX="${CXX:-c++}"
		# export    CFLAGS="${CFLAGS:-" -O3 -pipe -fPIC "}"
		# export    CXXFLAGS="${CXXFLAGS:-" -O3 -pipe -fPIC "}"
		# export    NM="${NM:-nm}"
		# export    RANLIB="${RANLIB:-ranlib}"
		# export    DES_ROOT="$DES_ROOT"
		# export    RUSTFLAGS="--remap-path-prefix=$PWD=. ${RUSTFLAGS-}"
		# export    GOFLAGS="-trimpath -modcacherw ${GOFLAGS-}"
		# export    GOPATH="${GOPATH:-"$PWD/go"}"
		# export    PATH="${GOPATH:-"$PWD/go"}/bin:$PATH"
		# export    KISS_ROOT="$KISS_ROOT"
		# export    REPO_MAIN="$REPO_MAIN"
		# export    KISS_XHOST_ARCH="$KISS_XHOST_ARCH"
		# export    KISS_XBUILD_ARCH="$KISS_XHOST_ARCH"
		# export    CHOST="$KISS_XHOST_TRIPLE"
		# export    CBUILD="$KISS_XBUILD_TRIPLE"
		# export    KISS_XHOST_ABI="$KISS_XHOST_ABI"
		# export    KISS_XBUILD_ABI="$KISS_XBUILD_ABI"
		# export    KISS_XHOST_TRIPLE="$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI"
		# export    KISS_XBUILD_TRIPLE="$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI"
		# export    SESSION_PID="$SESSION_PID"
		# export    KISS_PID="$KISS_PID"
		# export    CROSS_ACTION="${CROSS_ACTION:-"$action"}"
		# export    SHELL_OPTIONS="$SHELL_OPTIONS"
		# export    REPO_BASE="$REPO_BASE"
		# export    REPO_DIR="$REPO_DIR"
		# export    SRC_ROOT="$SRC_ROOT"
		# export    MAKE_ROOT="$MAKE_ROOT"
		# export    DESTDIR="$PKG_ROOT/$pkg_name"
		# . "$repo_urn/build" "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1 ||

		# Double quotes won't stop on build failure when $env_variables
		# has or has not $newline
		/ "$env_variables \
			. \"$repo_urn/build\" \"$PKG_ROOT/$pkg_name\" \"$repo_ver\" 2>&1" ||
		# Same as above
		# / "$( \
		#   printf '%s' "$env_variables"
		# ) \
		# . \"$repo_urn/build\" \"$PKG_ROOT/$pkg_name\" \"$repo_ver\" 2>&1" ||

		#
		# This version works
		# AR="${AR:-ar}" \
		#   CC="${CC:-cc}" \
		#   CXX="${CXX:-c++}" \
		#   CFLAGS="${CFLAGS:-" -O3 -pipe -fPIC "}" \
		#   CXXFLAGS="${CXXFLAGS:-" -O3 -pipe -fPIC "}" \
		#   NM="${NM:-nm}" \
		#   RANLIB="${RANLIB:-ranlib}" \
		#   DES_ROOT="$DES_ROOT" \
		#   RUSTFLAGS="--remap-path-prefix=$PWD=. ${RUSTFLAGS-}" \
		#   GOFLAGS="-trimpath -modcacherw ${GOFLAGS-}" \
		#   GOPATH="${GOPATH:-"$PWD/go"}" \
		#   PATH="${GOPATH:-"$PWD/go"}/bin:$PATH" \
		#   KISS_ROOT="$KISS_ROOT" \
		#   REPO_MAIN="$REPO_MAIN" \
		#   KISS_XHOST_ARCH="$KISS_XHOST_ARCH" \
		#   KISS_XBUILD_ARCH="$KISS_XHOST_ARCH" \
		#   CHOST="$KISS_XHOST_TRIPLE" \
		#   CBUILD="$KISS_XBUILD_TRIPLE" \
		#   KISS_XHOST_ABI="$KISS_XHOST_ABI" \
		#   KISS_XBUILD_ABI="$KISS_XBUILD_ABI" \
		#   KISS_XHOST_TRIPLE="$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI" \
		#   KISS_XBUILD_TRIPLE="$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI" \
		#   SESSION_PID="$SESSION_PID" \
		#   KISS_PID="$KISS_PID" \
		#   CROSS_ACTION="${CROSS_ACTION:-"$action"}" \
		#   SHELL_OPTIONS="$SHELL_OPTIONS" \
		#   REPO_BASE="$REPO_BASE" \
		#   REPO_DIR="$REPO_DIR" \
		#   SRC_ROOT="$SRC_ROOT" \
		#   MAKE_ROOT="$MAKE_ROOT" \
		#   DESTDIR="$PKG_ROOT/$pkg_name" \
		#   . "$repo_urn/build" "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1 ||
	#   result=$?
	# } || {
	#   # Experimental design. Incomplete
	#   # The "ENV" version works but can not make use of current environment
	#   # Positional parameters processed in kiss-abuild should be moved into $env_variables
	#   / "env $env_variables \
	#       PKG_DIR=\"$PKG_ROOT/$pkg_name\" PKG_VER=\"$repo_ver\" \
	#       sh -i -c 'ENV=/usr/include/kiss-abuild \
	#       \"$repo_urn/build\"' "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1"
	#   result=$?
	# }

	# [ "$result" -eq "0" ] ||
	{

		# tee will mask build errrors, and run_series needs tweaks
		#     "$repo_urn/build" "$PKG_ROOT/$pkg_name" "$repo_ver" 2>&1 \| \
		#     tee -a "$USER_OUTPUT"
		# { "$pipestatus_1" && "$pipestatus_2"; } || {

		printf '%s\n' "1" > "$KISS_TMPDIR/logs/build_state"

		// war "$pkg_name" "build failed"
		# At this stage the package manager just writes to the "$PKG_ROOT/$pkg_name"
		# directory, and does not need to write anythind to the system directory,
		# so the system is clean (do not directly escalate to system administrator
		# privileges in the build script).
		// log "$pkg_name" "Don't worry, the system itself is clean so far."
		# ${newline}Unless you are using sysadmin privileges inappropriately at this stage"
		// log "$find_tip" "$user_output"

		[ -z "${KISS_INNER_PIPE:+x}" ] || {
			# [ -z "${USE_SAY_PIPE+x}" ] ||
			clear_outer "PID_SAY"
			clear_outer "PID_LOG"
		}

		# // kill_pipe 'PID_SAY' "$PID_SAY"
		# // kill_pipe 'PID_LOG' "$PID_LOG"

		# # kill 0 ||
		# // kill_subtree "$KISS_PID"
		# Won't kill upper processes
		# // die "$pkg_name" "quit current build process"
		[ -z "${KISS_INNER_PIPE:+x}" ] || {
			# [ -z "${USE_SAY_PIPE+x}" ] ||
			pipe_cancel "PID_SAY"
			pipe_cancel "PID_LOG"
		}

		# arg1: build-fail
		# arg2: package name
		# arg3: path to build directory
		(// run_hook build-fail "$pkg_name" "$MAKE_ROOT/$pkg_name")

		# ! pid_alive "$SESSION_PID" || kill -USR1 "$SESSION_PID"
		#
		# ! pid_alive "$SESSION_PID" || // as "root" kill -KILL -"$SESSION_PID"
		#
		# kill_tree "$$"
		# kill_tree "$SESSION_PPID"
		interrupt
		# kill 0
		# export KISS_DEBUG=
		# exit
	}   # | tee -a "$USER_OUTPUT"

	# // trap_off

	# build_state="$(cat "$KISS_TMPDIR/logs/build_state")"
	# equ "$build_state" 0 || {
	#     // war '$build_state' "$build_state"
	#     // war '$SESSION_PID' "$SESSION_PID"
	#     # kill_tree "$SESSION_PPID"
	#     interrupt
	#     # return "$build_state"
	#     # kill_name "$CROSS_ACTION" "$repo_urn"
	# }

	# } | tee -a "$USER_OUTPUT"

	build_state="$(cat "$KISS_TMPDIR/logs/build_state")"
	equ "$build_state" 0 || {
		// war '$build_state' "$build_state"
		// war '$SESSION_PID' "$SESSION_PID"
		# kill_tree "$SESSION_PPID"
		interrupt
		# kill_name "$CROSS_ACTION" "$pkg_name"
		# Will kill the main process
		# kill_tree "$SESSION_PPID"
		# return "$build_state"
	}

	# # Delete the log file if the build succeeded to prevent the directory
	# # from filling very quickly with useless logs.
	# Deprecated. Clear it at the next build
	# equ "$KISS_KEEPLOG" 1 || rm -f "$log_dir/$pkg_name/build.log"

	# Copy the repository files to the package directory.
	# // as "$SRC_USER" /usr/bin/cp -LRf "$repo_urn" "$PKG_ROOT/$pkg_name/$db/"
	// as "$SRC_USER" rsync -aqzL "$repo_urn" "$PKG_ROOT/$pkg_name/$db/"
	as "$SRC_USER" sync
	[ -d "$PKG_ROOT/$pkg_name/$db/$pkg_name" ] ||
	// die '$repo_urn' "$repo_urn copying failed"

	// log "$pkg_name" "successfully built"

	# arg1: post-build
	# arg2: package name
	# arg3: path to DESTDIR
	// run_hook_pkg post-build "$pkg_name" "$repo_ver" "$repo_rel" "$repo_dir"
	// run_hook     post-build "$pkg_name" "$PKG_ROOT/$pkg_name"
}

pkg_checksum() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	local pkg_name_string="$(echo "$pkg_name" | sed -e 's/-/_/g' -e 's/./_/g')"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
	repo_urn="$(// delegate -- repo_trace "$pkg_name")"

	// pkg_dirs "$action" "$pkg_name"

	[ -n "$(/ echo \${synchronized_${pkg_name_string}-})" ] ||
	// pkg_download "$repo_urn" c

	// log '$repo_urn' "$repo_urn"
	[ -f "$repo_urn/sources" ] || return 0

	local hash="$(// delegate -- "checksum_gen" "$repo_urn")"

	if ok "$hash"; then
		set --
		[ "$LOGNAME" == "$(// delegate -- owner "$repo_urn")" ] ||
			set -- $(delegate -- as_owner "$repo_urn")
		// log '$@' "$(esceval "$@")"
		[ -f "$repo_urn/checksums" ] || "$@" touch "$repo_urn/checksums"
		as_own "$repo_urn/checksums" \
			sh -c "/usr/bin/printf '%s\n' \"$hash\" > \"$repo_urn/checksums\""
		// log "$pkg_name" "checksums generated"

	else
		// log "$pkg_name" "no sources needing checksums"
	fi
}

# $1 repo_urn : package repo url/uri
checksum_gen() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"
	// log '$repo_urn' "$repo_urn"
	# Generate checksums for packages.
	#
	# NOTE: repo_ comes from caller.
	while read -r src_url dest || ok "${src_url%%\#*}"; do
		/ "IFS=$(printf '%b' "$FS") read -r _ _res_type _res _ \
			<< $(// here_doc -- local_route "$repo_urn" "$src_url" "$dest")"
			> /dev/null || // die "local_route" "failed"

		# case ${_res##git+*} in */*[!.])
		case "$_res_type" in
			"git");;
			*) set -- "$@" "$_res"
		esac
	done < "$repo_urn/sources"

	# sh256 "$hash_name" "$@"
	local hash="$(// delegate -- sh256 "$@")"
	printf '\n%s' "$hash"
}

# $1 repo_urn : package repo url/uri
checksums_verify() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"

	# Verify all package checksums. This is achieved by generating a new set
	# of checksums and then comparing those with the old set.
	#
	// log "$pkg_name" "verifying sources"

	# Generate a new set of checksums to compare against.
	local hash="$(// delegate -- "checksum_gen" "$pkg_name")"
	// log '$hash' "$hash"

	# Intentional, globbing disabled.
	# shellcheck disable=2038,2086
	set -- $hash
	local checksums="$repo_urn/checksums"
	[ -z "${KISS_FORCE+x}" ] ||    # [ -s "$checksums" ] &&
	! is_writable "$repo_urn" || {
		// log '$hash' "${hash:+"${hash}"}"
		// as_own "${checksums%/*}" touch "$checksums"
		for hash_item in $@; do
			// as_own "${checksums%/*}" sh -c "printf '%s\n' \"$hash_item\" >> \"$checksums\"" ||
			// die 'permission denied' "on writting version to file $checksums"
		done
	}

	# Check that the first column (separated by whitespace) match in both
	# checksum files. If any part of either file differs, mismatch. Abort.
	[ -z "${1:+x}" ] || while read -r check _ || [ -n "${1:+x}" ]; do
		# printf '%s\n%s\n' "- ${check:-missing}" "+ ${1:-no source}"
		// log '$check' "${check:-missing}"
		// log '$hash' "${1:-no source}"
		local hash_item="${1:-"no source"}"
		equ "$hash_item-${check:-null}" "$check-$hash_item" ||
		equ "$hash_item-${check:-null}" "$hash_item-SKIP" ||
		[ -n "${KISS_FORCE+x}" ] || // die "$pkg_name" "checksum mismatch"
		shift "$(($# != 0))"
	done < "$checksums"
}

# $1 repo_urn : package repo url/uri
conflicts() {
	_level_2
	# Check to see if a package conflicts with another.
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"

	// log "$pkg_name" "checking for package conflicts"

	local manifest_files="$( \
		// delegate -- slot_aquire "$pkg_name" "manifest-files")"
	local found_conflicts="$( \
		// delegate -- slot_aquire "$pkg_name" "found-conflicts")"
	local tar_manifest="$EXTRACT_ROOT/$pkg_name/$db/$pkg_name/manifest"
	[ -f "$tar_manifest" ] || // die "$tar_manifest" "does not exist"
	[ -s "$tar_manifest" ] || // die '$tar_manifest' "'$tar_manifest' is empty"
	# Filter the tarball's manifest and select only files. Resolve all
	# symlinks in file paths as well.
	while read -r file; do case "$file" in *[!/])
		// resolve_path "$file"
		printf '%s\n' "$_rpath"
	esac done < "$tar_manifest" > "$manifest_files"

	[ -s "$manifest_files" ] || // die '$tar_manifest' "'$tar_manifest' is empty"

	cd "$EXTRACT_ROOT/$pkg_name"
	set +f
	# All installed packages manifest
	set -f "$sys_db"/*/manifest

	# Remove the current package from the manifest list.
	local complement="$( \
		// delegate -- replace " $* " " " " $sys_db/$pkg_name/manifest ")"

	# Intentional, globbing disabled.
	# shellcheck disable=2046,2086
	set -- $complement
	# // log '$@' "$(esceval "$@")"
	# Return here if there is nothing to check conflicts against.
	! equ "$#" 0 || return 0

	# Store the list of found conflicts in a file as we'll be using the
	# information multiple times. Storing things in the cache dir allows
	# us to be lazy as they'll be automatically removed on script end.
	grep -Fxf "$manifest_files" -- "$@" 2>/dev/null > "$found_conflicts" || :

	local safe=
	# Enable alternatives automatically if it is safe to do so.
	# This checks to see that the package that is about to be installed
	# doesn't overwrite anything it shouldn't in '$sys_db'.
	grep -q ":$sys_db/" "$found_conflicts" || safe=1

	[ -s "$found_conflicts" ] || return 0

	// war '$found_conflicts' "$found_conflicts"
	local index=0
	while read -r line; do
		: $((index += 1))
		// log '$found_conflicts' "$(delegate -- format "$index") $line"
	done < "$found_conflicts"

	[ -z "${KISS_CHOICE+x}" ] || ! equ "$safe" 1 || {
		// log "Package '$pkg_name' conflicts with another package" "!>"
		// log "Run 'KISS_CHOICE= kiss i $pkg_name' to add conflicts" "!>"
		// die "as alternatives." "!>"
	}

	# [ -z "${KISS_CHOICE+x}" ] && equ "$safe" 1 && [ -s "$found_conflicts" ]
	# This is a novel way of offering an "alternatives" system.
	# It is entirely dynamic and all "choices" are created and
	# destroyed on the fly.
	#
	# When a conflict is found between two packages, the file
	# is moved to a directory called "choices" and its name
	# changed to store its parent package and its intended
	# location.
	#
	# The package's manifest is then updated to reflect this new location.
	#
	# The 'kiss alternatives' command parses this directory and
	# offers you the CHOICE of *swapping* entries in this
	# directory for those on the filesystem.
	#
	# The alternatives command does the same thing we do here,
	# it rewrites manifests and moves files around to make this work.
	#
	# Pretty nifty huh?
	local source
	while IFS=: read -r _ source; do
		source="$(standardize "$source")"
		local nominal_target_dir="${source%/*}"
		local real_source="$PWD$source"
		local db_target="$PWD/$db/$pkg_name"
		// log 'conflict source' "$real_source"
		# Create the "choices" directory inside of the tarball.
		# This directory will store the conflicting file.
		mkdir -p "$PWD/$cho_db"

		# Construct the file name of the "db" entry of the
		# conflicting file. ($pkg_name>usr>bin>ls)
		local fake_route="$(// delegate -- replace "$source" '>' '/')"

		# [ -d "$real_source" ] || // mkdir -p "$real_source"
		[ -e "$real_source" ] ||
		[ -h "$real_source" ] || // die '$real_source' "'$real_source' does not exist"
		# rsync -aqz --rsync-path="mkdir -p ${real_source%/*} && rsync" \
		#     "$source" "$real_source" ||
		# // die 'rsync' "failed"

		# Move the conflicting file to the choices directory
		# and name it according to the format above.
		[ -z "${real_source##*"$db_target"*}" ] ||
		mv -f "$real_source" "$PWD/$cho_db/$pkg_name$fake_route" 2>/dev/null || {
			// log "File must be in $nominal_target_dir and not a symlink to it"
			// die "This usually occurs when a binary is installed to /sbin" \
				"instead of /usr/bin (example)"
		}
	done < "$found_conflicts"

	// log "$pkg_name" "converted all conflicts to choices (kiss a)"

	# Rewrite the package's manifest to update its location
	# to its new spot (and name) in the choices directory.
	// pkg_manifest "$repo_urn" "$EXTRACT_ROOT"
}

# Both are repos and not the same one
# Readonly
# $1 diff source
# $2 diff target
is_mirror() (
	_level_2
	local a="$1"
	local b="$2"
	local result=1

	is_repos "$a" || return $result
	is_repos "$b" || return $result

	# ! equ "$a" "$b" || // die '$a == $b' \
	#     "Physical '$a' == '$b' is not one of the designed semantics"
	! equ "$a" "$b" || return $result
	local pkg_name="${a##*/}"
	equ "$pkg_name" "${b##*/}" || return "$result"
	local differences=
	# while IFS=$' ' read -r _ file_a _ file_b _ && [ -e "$file_a" ] && [ -e "$file_b" ]; do
	while IFS=$' ' read -r line; do
		[ -n "${line:+x}" ] || cotinue
		local file_name="$(awk "{print \$2}" <(printf '%s\n' "$line") | tr -d ':')"
		[ -n "$file_name" ] && [ -n "${file_name##*"$pkg_name"*}" ] || continue
		# diff errors like this:
		# diff: /var/db/kiss/lm/extra/cmake/patches: No such file or directory
		# [ -n "${line##*"No such file or directory"*}" ] || :
		local base_name="${file_name##*/}"
		case "$base_name" in
			"version"|"keys"|"manifest"|"etcsums"|"checksums"|"depends") ;;
			*)
				differences="$file_name${differences:+" ${differences}"}"
				// log "diff [$base_name]" "$file_name"
		esac
	done < <(diff -qrN "$a" "$b" 2>&1) 2>/dev/null || // die 'diff' "failed"
	ok "$differences" || result=0
	return "$result"
)

# Repo is in writable location
is_writable() {
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	local result=1

	[ -n "${repo_urn:+x}" ] || return "$result"

	[ -n "${repo_urn##*"$sys_db"*}" ] &&
		{ [ -n "${repo_urn##*"${REPO_MAIN}"*}" ] ||
			[ -z "${repo_urn##*"modules"*}" ]; } ||
			result=0

	// log '$result' "$result"

	return "$result"
}

# Readonly functiion
# Neither in $sys_db nor $REPO_DIR
# Repo is in $REPO_MAIN
# -- just because $KISS_PATH is defined only contains $REPO_MAIN
is_in_main() (
	_level_2
	local repo_urn="$1"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	local result=1
	# Without this local definition,
	# repo_in_main in caller/parent functions might be modified.
	# So I made the fuction readonly
	local repo_in_main
	# // war '$kiss_path_repo_list_origin' "$kiss_path_repo_list_origin"
	for repo_in_main in $(
			// delegate -- repo_trace "$pkg_name" "pure" "-d" "$KISS_PATH"); do
		// debug '$repo_in_main' \
			"${repo_in_main:+"${repo_in_main} "}inside pure repo_trace"
		[ "$repo_urn" == "$repo_in_main" ] || continue
		result=0
		break
	done
	return $result
)

ver_outdate() {
	_level_2
	local ver_target="$1"
	local rel_target="$2"
	[ -z "${rel_target:+x}" ] && rel_target=0 ||
	# is_integer "$rel_target" || die '$rel_target' "'$rel_target' is not an integer"
	is_integer "$rel_target" || rel_target=9999
	local ver_source="$3"
	local rel_source="$4"
	[ -z "${rel_source:+x}" ] && rel_source=0 ||
	# is_integer "$rel_source" || die '$rel_source' "'$rel_source' is not an integer"
	is_integer "$rel_source" || rel_source=9999

	# IFS=.+-_ read -r major_target minor_target patch_target ident_target \
	#     < <(printf '%s\n' "$ver_target") > /dev/null || // die "printf '%s\\n' \"$ver_target\"" "failed"

	local major_target= minor_target= patch_target= ident_target= suffix_target=
	/ "IFS=$(printf '%b' "$FS") read -r major_target minor_target \
	patch_target ident_target suffix_target \
		<< $(// here_doc -- ver_split "$ver_target")"
	> /dev/null || // die 'ver_split' "failed"

	# IFS=.+-_ read -r major_source minor_source patch_source ident_source \
	#     < <(printf '%s\n' "$ver_source") > /dev/null || // die "printf '%s\\n' \"$ver_source\"" "failed"
	local major_source= minor_source= patch_source= ident_source= suffix_source=
	/ "IFS=$(printf '%b' "$FS") read -r major_source minor_source \
	patch_source ident_source suffix_source \
		<< $(// here_doc -- ver_split "$ver_source")"
	> /dev/null || // die 'ver_split' "failed"

	greater_than() {
		local left="$1"
		local right="$2"
		is_integer "$left" &&
		is_integer "$right" &&
		[ "$left" -gt "$right" ]
	}

	greater_than "$major_source" -gt "$major_target" ||
	greater_than "$minor_source" -gt "$minor_target" ||
	greater_than "$patch_source" -gt "$patch_target" ||
	greater_than "$ident_source" -gt "$ident_target" ||
	greater_than "$rel_source" -gt "$rel_target"
}

pkg_update() {
	_level_2
	local deps="$1"
	local makedeps="$2"
	shift 2
	// log "updating" "repositories"
	[ -n "${1:+x}" ] ||
	# Create a list of all repositories.
	# Intentional, globbing disabled.
	# shellcheck disable=2046,2086
	{ local ifs="$IFS"; local IFS=:; set -- $KISS_PATH; IFS="$ifs"; }
	local repo=
	# Update each repository in '$KISS_PATH'.
	for repo do
		local pkg_name="${repo##*/}"
		local repo_target= target_source=
		[ -n "${repo##*"${sys_db}"*}" ] || repo_target="$repo"
		[ -z "${repo##*"/"*}" ] || repo_target="$sys_db/$pkg_name"

		local ver_target= rel_target= ver_source= rel_source=
		local repo_dir= repo_alias= repo_url= reference_type=
		/ "IFS=$(printf '%b' "$FS") read -r \
			repo_dir ver_target rel_target \
			repo_alias repo_url reference_type \
			<< $(// here_doc -- pkg_version "$pkg_name" "" "" "$sys_db")"
			> /dev/null || // die 'pkg_version' "failed"

		[ -d "$repo_dir/$pkg_name" ] || {
			local repo_dir_source= alias_source= url_source= reference_type_source=
			/ "IFS=$(printf '%b' "$FS") read -r \
				repo_dir_source ver_source rel_source \
				alias_source url_source reference_type_source \
				<< $(// here_doc -- pkg_version "$pkg_name")"
				> /dev/null || // die 'pkg_version' "failed"
		}
		[ -d "$repo_dir_source/$pkg_name" ] || // war '$repo' "'$repo' not found"
		[ -z "${repo##*"/"*}" ] || repo="$repo_dir_source/$pkg_name"
		// log '$repo' "$repo"
		local repo_type=
		# if git -C "$repo" rev-parse 'HEAD@{upstream}' >/dev/null 2>&1; then
		if git -C "$repo" rev-parse 'HEAD' >/dev/null 2>&1; then
			repo_type="git"

			# Get the Git repository root directory.
			local subm="$(git -C "$repo" rev-parse --show-superproject-working-tree)"
			repo="$(git -C "${subm:-"$repo"}" rev-parse --show-toplevel)"

		elif [ ! -d "$repo" ]; then
			// war '$repo' "'$repo' is not installed"
			continue
		else
			# For -u shell option, we don't want to unset
			# unset repo_type
			{ [ -n "${ver_source:+x}" ] && [ -n "${rel_source:+x}" ]; } ||
			/ "IFS=$(printf '%b' "$FS") read -r \
				repo_dir_source ver_source rel_source \
				alias_source url_source reference_type_source \
				<< $(// here_doc -- pkg_version "$pkg_name")"
				> /dev/null || // die 'pkg_version' "failed"
			// ver_outdate "$ver_target" "$rel_target" "$ver_source" "$rel_source" ||
			continue
		fi

		// pkg_update_repo "$repo_type" "$repo"
	done

	// pkg_upgrade "$deps" "$makedeps"
}

# $1 repo_type
# $2 repo
pkg_update_repo() {
	_level_2
	local repo_type="$1"
	local repo="$2"
	cd "$repo" || // die '$repo' "Repository ${repo:+"\"${repo}\" "}inaccessible"

	local repos=
	contains "$repos" "$PWD" || {
		repos="${repos:+"${repos} "}$PWD"

		// log '$PWD' "$PWD"

		/ "IFS=$(printf '%b' "$FS") read -r  pwd_user _  \
			<< $(// here_doc -- owner_group "$PWD")"
		> /dev/null || // die 'owner_group' "failed"
		equ "pwd_user" "$LOGNAME" || {
			// log 'needs to update from "$user" to' "$pwd_user"
			set -- $(// delegate -- as_user "$pwd_user")
		}

		# arg1: pre-update
		# arg2: need su?
		# arg3: owner
		# env:  PWD is path to repository
		// run_hook pre-update "$#" "$pwd_user"

		case "$repo_type" in "git")
			// pkg_update_git "$@"
		esac

		# arg1: post-update
		# env:  PWD is path to repository
		// run_hook post-update
	}
}

pkg_update_git() {
	_level_2
	# Display whether or not signature verification is enabled.
	case $(git config --get merge.verifySignatures) in true)
		// log 'signature verification" "enabled'
	esac

	"$@" git pull
	"$@" git submodule update --remote --init -f
}

pkg_upgrade() {
	_level_2
	local deps="$1"
	local makedeps="$2"
	shift 2
	local action="upgrade"

	// log "versions" "checking for new package"
	set +f

	local repo_orphans

	for pkg_name in "$sys_db/"*; do set -f
		// pkg_dirs "$action" "$pkg_name"
		// pkg_clear "$action" "$repo_urn"

		local repo_dir_pre= ver_pre= rel_pre= alias_pre= url_pre= reference_type_pre=
		/ "IFS=$(printf '%b' "$FS") read -r \
			repo_dir_pre ver_pre rel_pre \
			alias_pre url_pre reference_type_pre \
			<< $(// here_doc -- pkg_version "${pkg_name##*/}" "" "" "$sys_db")"
		> /dev/null || // die 'pkg_version' "failed"

		# Detect repository orphans (installed packages with no
		# associated repository).
		case $repo_dir_pre in *"$sys_db/"*)
			repo_orphans="$repo_orphans$newline${pkg_name##*/}"
		esac

		local repo_dir= repo_ver= repo_rel= repo_alias= repo_url= reference_type=
		/ "IFS=$(printf '%b' "$FS") read -r \
			repo_dir repo_ver repo_rel \
			repo_alias repo_url reference_type \
			<< $(// here_doc -- pkg_version "${pkg_name##*/}")"
			> /dev/null || // die 'pkg_version' "failed"

		# Compare installed packages to repository packages.
		equ "$ver_pre-$rel_pre" "$repo_ver-$repo_rel" || {
			set -- "$@" "${pkg_name##*/}"

			// log "${pkg_name##*/}" "$ver_pre-$rel_pre => $repo_ver-$repo_rel"
		}
	done

	case "$repo_orphans" in *"?"*)
		// war "packages without repository" "$repo_orphans"
	esac

	local install_on_build=""
	prefer_cache=1

	! contains "$*" kiss || {
		// log "package manager update" "detected"
		// log "the package manager" "will be updated first"

		# // prompt "content" "Upgrade kiss first"
		local content="$(// delegate -- prompt "Upgrade kiss first")"
		! expr "$content" : '[n|N]\+' > /dev/null || return 0

		// build_all "$deps" "$makedeps" kiss

		// log "the package manager" "updated"
		// log "re-run 'kiss update'" "to update your system"
		return 0
	}

	for _ do
		/ "IFS=$(printf '%b' "$FS") read -r order redro deps makedeps \
			<< $(// here_doc -- pkg_order "$deps" "$makedeps" "$@")"
			> /dev/null || // die 'pkg_order' "failed"

		# Intentional, globbing disabled.
		# shellcheck disable=2046,2086
		set -- $order

		# // prompt "content" "Packages to update ($#): $*"
		local content="$(// delegate -- prompt "Packages to update ($#): $*")"
		! expr "$content" : '[n|N]\+' > /dev/null || continue

		// build_all "$deps" "$makedeps" "$@"

		# for repo_urn in $@; do // pkg_install "$repo_urn"; done
		// alter "install" "$@" 2>&1 || :
		// log "all packages" "updated"
		return 0
	done
	set -f
	// log "nothing" "to do"
}

# $1 action
# $2 pkg_name_00
# $3 pkg_name_00
# ...
# Claen all? "$@" might has multiple packages
clean_all() {
	_level_2
	# Clean up on exit or error. This removes everything related to the build.
	# If _KISS_LVL is (0) we are on the bottom-level process - the entire cache will
	# be removed. If _KISS_LVL is any other value, remove only the tar directory.

	local action="${1-}"
	shift "$(($# >= 1? 1 : $#))"
	# Second parameter is index
	! is_pick "$action" || set -- "$1"
	for repo_urn in $@; do
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		[ -n "${pkg_name:+x}" ] || // die '$pkg_name' "\"$pkg_name\" is wrong calculated"
		# https://stackoverflow.com/questions/32107041/how-to-check-if-a-string-only-contains-digits-numerical-characters
		# [ $(expr "x$pkg_name" : "x[0-9]*$") -gt 0 ] || continue
		// log '$action' "$action"
		// log '$pkg_name' "$pkg_name"
		[ -d "$PROC_ROOT" ] || // die '$PROC_ROOT' "$PROC_ROOT"
		// debug '$EXTRACT_ROOT' "$EXTRACT_ROOT"
		// debug '$KISS_DEBUG' "${KISS_DEBUG-}"
		// debug '$_KISS_LVL' "$_KISS_LVL"

		case $action in
			i|install)
				local log_dir="$cache_dir/logs/$pkg_name"
				[ -d "$log_dir" ] || \mkdir -p "$log_dir"
				local log_target="$log_dir/build.log"
				: > "$log_target"
				# log_dumped "$log_target" ||
				// log_shift "$log_target" "$user_output"
		esac

		case ${KISS_DEBUG-}-${_KISS_LVL:-0} in
			-0) [ -z "${PROC_ROOT:+x}" ] || [ "$(standardize "$PROC_ROOT")" = "/proc" ] ||
				// pkg_clear "$action" "$repo_urn" ;;
			-*) [ -z "${EXTRACT_ROOT:+x}" ] || [ "$EXTRACT_ROOT" == "/" ] ||
				[ "$(// delegate -- occurrences "$EXTRACT_ROOT" "/")" -le "1" ] ||
				[ "$(// delegate -- occurrences "$EXTRACT_ROOT/$pkg_name" "/")" -le "1" ] ||
				[ ! -d "$EXTRACT_ROOT/$pkg_name" ] || [ "$EXTRACT_ROOT" = "/extract" ] ||
				# // as_own "$EXTRACT_ROOT" find "$EXTRACT_ROOT/$pkg_name" -mindepth 1 -delete
				for item in $(// as_own "$EXTRACT_ROOT" \
					find "$EXTRACT_ROOT/$pkg_name" -mindepth 1); do
					# choices folder items won't accept removing by normal users even it's is owned by the normal user
					// as "root" \rm -rf "$item"; done
		esac
	done
	sync
}

# "$@" :
pkg_help_ext() {
	_level_2
	// debug '$#' "$#"
	// debug 'extensions (kiss-*) in' "$(echo $PATH | sed 's/:/\n/g')"
	// log 'extensions (kiss-*) in $PATH'
	set +f
	# Intentional, globbing disabled.
	# shellcheck disable=2046,2030,2031
	while read -r item; do
		// debug '$item' "$item"
		set -- "$@" "$item"
	done << EOF || :
$(// repo_trace "kiss-*" "all" -x "$PATH")
EOF
# $(// repo_trace kiss-* "" -x "$PATH")
	// debug '$#' "$#"
	// debug '$@' "$(esceval "$@")"
	# ok "$1" || // die 'kiss-*' "$1"

	local path_list=
	local seen=
	# To align descriptions figure out which extension has the longest
	# name by doing a simple 'name > max ? name : max' on the basename
	# of the path with 'kiss-' stripped as well.
	#
	# This also removes any duplicates found in '$PATH', picking the
	# first match.
	for path do
		p="${path#*/kiss-}"
		# pick up files only
		[ ! -d "$path" ] || continue
		// debug '$path' "$path"

		case " $seen " in *" $p "*)
			shift
			continue
			;;
			*) path_list="${path_list:+"${path_list}${newline}"}$path"
		esac

		seen=" $seen $p "
		max="$((${#p} > max ? ${#p}+1 : max))"
	done
	# local ifs="$IFS"
	set -- $path_list
	# local IFS="$newline" set -- $path_list
	# [ "$ifs" == "$IFS" ] || // die '$IFS' "permanently changed"
	// log '$#' "$#"
	// debug '$@' "$(esceval "$@")"

	local ifs="$IFS"
	local IFS=\#$IFS

	# Print each extension, grab its description from the second line
	# in the file and align the output based on the above max.
	for path do
		// debug '$path' "$path"
		# Open the extension as a file descriptor.
		exec 3< "$path"

		# Grab the second line in the extension.
		{ read -r _ && IFS=\#$IFS read -r _ cmt; } <&3

		# printf "%b->%b %-${max}s %s\\n" "$color_parent" "$color_end" "${path#*/kiss-}" "$cmt"
		// log "${path#*/kiss-}" "$cmt"
	done >&2
	IFS="$ifs"
	set -f
}

trap_on() {
	# _level_0
	# Catch errors and ensure that build files and directories are cleaned
	# up before we die. This occurs on 'Ctrl+C' as well as success and error.
	# trap on_int INT TERM QUIT
	# exec 2>"$ERR_OUTPUT"
	[ -z "${KISS_INNER_PIPE+x}" ] || listen "on_int"
	# trap '// on_int' INT TERM
	trap "// on_exit $KILL_LIST" EXIT
}

on_int() {
	# _level_0
	export KISS_DEBUG=
	// run_hook SIGINT
	exit 1
}

on_exit() {
	# _level_0
	# export KISS_DEBUG=
	# For debugging, we might don't want to delete the crime scene immediately
	# // clean_all "$@"
	// run_hook SIGEXIT
	[ -z "${KISS_INNER_PIPE:+x}" ] || // clean
}

trap_off() {
	_level_0
	# Block being able to abort the script with 'Ctrl+C'. Removes all risk of
	# the user aborting a package install/removal leaving an incomplete package
	# installed.
	trap > "/tmp/${LOGNAME}/trap.txt"
	local sig
	for sig in $(
			awk 'BEGIN{ RS = "\n"; FS = " " }{print $NF}' \
				< "/tmp/${LOGNAME}/trap.txt")
	do
		// log '$sig' "$sig"
		[ "$sig" != "EXIT" ] && [ "$sig" != "ERR" ] || continue
		// war '$sig' "$(delegate -- format "$sig") is going to be cleared"
		trap '' $sig
	done
	# Will ruin read_line()
	# trap "" INT TERM QUIT PIPE EXIT
}

share_link() {
	_level_2
	[ "$#" -ge "5" ] || // die '$#' "input arguments $# less than 5"
	local body_root_name="$1"
	local anchor_root_name="$2"
	local parent_dir="$3"
	local parent_user="$(// delegate -- owner "$parent_dir")"
	local cache_dir="$4"
	local anchor_folder="$5"

	/ ": \"\${$body_root_name:=\"$parent_dir/$anchor_folder\"}\""
	# / "true \"\${$body_root_name:=\"$parent_dir/$anchor_folder\"}\""
	# / "$body_root_name=\"$parent_dir/$anchor_folder\""
	# local body_root_value="$(/ "printf '%s' \"\$$body_root_name\"")"
	/ "local body_root_value=\$$body_root_name"
	#                   name            value
	// log "$body_root_name" ">o< $body_root_value"
	[ "$body_root_value" = "$parent_dir/$anchor_folder" ] ||
	// die "$body_root_name" "$body_root_value"

	[ -d "$body_root_value" ] ||
		// as "$parent_user" /usr/bin/mkdir -p "$body_root_value" ||
		// die 'mkdir' "'$body_root_value' failed"

	/ "$anchor_root_name=\"$cache_dir/$anchor_folder\""
	# local anchor_root_value="$(/ "printf '%s' \"\$$anchor_root_name\"")"
	/ "local anchor_root_value=\$$anchor_root_name"
	#                   name            value
	// log "$anchor_root_name" "<x> $anchor_root_value"
	[ "$anchor_root_value" = "$cache_dir/$anchor_folder" ] ||
	// die "$anchor_root_name" "$anchor_root_value"

	{ [ -L "$anchor_root_value" ] &&
		[ "$body_root_value" = "$(readlink -f "$anchor_root_value")" ]; } || {
			# Is false link       Is real dir
			[ ! -d "$anchor_root_value" ] || [ -L "$anchor_root_value" ] || {
				# Is real dir
				[ "$(stat -c '%U' "$anchor_root_value")" = "$parent_user" ] ||
				// as "root" /usr/bin/chown -R "$parent_user":users "$anchor_root_value" ||
				// die 'chown' "'$anchor_root_value' failed"

				// as "$parent_user" /usr/bin/rsync -aqz "$anchor_root_value/." "$body_root_value/"
				// as "$parent_user" sync
			}
			{ [ ! -d "$anchor_root_value" ] && [ ! -L "$anchor_root_value" ]; } ||
			// as "root" /usr/bin/rm -rf "$anchor_root_value" ||
			// die 'rm -rf' "'$anchor_root_value' failed"
			ln -sf "$body_root_value" "$anchor_root_value"
		}
	/ "$anchor_root_name=\"$body_root_value\""
}

# package is git or not
# Usage
# local format= reference_type=
# / "IFS=$(printf '%b' "$FS") read -r \
#   format reference_type \
#   << $(// here_doc -- pkg_format "$repo_urn")"
# > /dev/null || { // die 'pkg_format' "failed"; exit 1; }
pkg_format() {
	_level_2
	local pkg_name
	local repo_urn="$1"
	// debug '$repo_urn' "$repo_urn"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"
	is_repos "$repo_urn" ||
		repo_urn="$(// delegate -- repo_trace "$pkg_name")"

	local format=
	local reference_type=

	// debug '$pkg_name' "$pkg_name"
	case "$pkg_name" in
		*.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z|*.zip)
			local src_name="${pkg_name##*/}"
			src_name="${src_name%\?*}"
			format="${src_name##*.}"
			printf "%s" "$format"
			return 0
	esac

	[ "$scope" != "local_route" ] || { printf '%s' "$format"; return 0; }

	[ ! -f  "$repo_urn/sources" ] ||
	while read -r src_url dest || ok "${src_url%%\#*}"; do
		ok "${src_url%%\#*}" || continue

		local key="${pkg_name%%-*}"
		null "${src_url##*"$key"*}" || continue

		// debug '$src_url' "$src_url"
		// debug '$dest' "$dest"
		case $src_url in
			"git+"*)
				[ -n "${src_url##*"$key"*}" ] || {
					format="git"
					/ "IFS=$(printf '%b' "$FS") read -r _local_dir _ _res _ \
						<< $(// here_doc -- local_route "$repo_urn" "$src_url" \
						"$dest" "$action")"
					> /dev/null || // die "local_route" "failed"

					local url="${_res%[\#@]*}"
					local upstream_name=
					[ -n "${_res##*[@\#]*}" ] || upstream_name="${_res##*[@\#]}"

					/ "IFS=$(printf '%b' "$FS") read -r reference_type _ \
						<< $(// here_doc -- track_type \
							"$upstream_name" "$_local_dir" "$url")"
						> /dev/null || // die 'track_type' "failed"
				} ;;

			*"://"*)
				local src_name="${src_url##*/}"
				src_name="${src_name%\?*}"
				format="${src_name##*.}" ;;

			*)
				local src_name="${src_url##*/}"
				src_name="${src_name%\?*}"
				[ -n "${src_url##*"$key"*}" ] || {
					format="${src_name##*.}"
				} ;;
		esac
		# Use the first element
		break
	done < "$repo_urn/sources"

	// debug '$format' "$format"

	printf "\n%s$FS%s" "$format" "$reference_type"
}

[ -z "${KEEP_DEPRECATED+x}" ] ||
# Deprecated
repo_resolve() {
	_level_2
	local pkg_name
	local repo_urn="$1"
	[ -n "${repo_urn:+x}" ] || // die '$repo_urn' "\"$repo_urn\" is invalid"
	// debug '$repo_urn' "$repo_urn"
	local search_dir="$2"
	// debug '$search_dir' "$search_dir"
	repo_urn="$(standardize "$repo_urn")"
	pkg_name="${repo_urn##*/}"
	// debug '$pkg_name' "$pkg_name"

	[ "$scope" != "repo_trace" ] || { printf "\n%s$FS%s$FS%s" "$pkg_name" "" ""; return 0; }

	local repo_dir
	local repo_urn_output

	[ -n "${repo_urn##*"/"*}" ] ||
	[ ! -d "${repo_urn}" ] ||
	! command -v "$repo_urn/build" > /dev/null 2>&1 ||
	[ ! -f "$repo_urn/version" ] ||
	[ ! -f "$repo_urn/sources" ] ||
	{
		repo_dir="${repo_urn%/*}"
		repo_urn_output="$repo_urn"
		printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
		return 0
	}

	[ -n "${repo_dir:+x}" ] ||
	null "$search_dir" || {
		[ -z "${search_dir##*:*}" ] ||
		[ ! -d "$search_dir/$pkg_name" ] || {
			repo_dir="$search_dir"
			repo_urn_output="$repo_dir/$pkg_name"
			printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
			return 0
		}

		[ -n "${repo_dir:+x}" ] || {
			# repo_trace will search $sys_db also
			repo_urn_output="$(// delegate -- repo_trace "$pkg_name" "" "-d" "$search_dir")"
			repo_dir="${repo_urn_output%/*}"
			printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
			return 0
		}
	}

	[ -n "${repo_dir:+x}" ] ||
	[ -z "${REPO_DIR:+x}" ] ||
	[ ! -d "$REPO_DIR/$pkg_name" ] || {
		// debug '$REPO_DIR' "$REPO_DIR"
		repo_dir="$REPO_DIR"
		repo_urn_output="$repo_dir/$pkg_name"
		printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
		return 0
	}

	# [ -n "${repo_dir:+x}" ] ||
	# [ -z "${KISS_PATH##*:*}" ] ||
	# [ ! -d "$KISS_PATH/$pkg_name" ] || {
	#     // debug '$KISS_PATH' "$KISS_PATH"
	#     repo_dir="$KISS_PATH"
	# }

	[ -n "${repo_dir:+x}" ] || {
		# repo_trace will search $sys_db also
		repo_urn_output="$(// delegate -- repo_trace "$pkg_name" "" "-d" "$KISS_PATH")"
		repo_dir="${repo_urn_output%/*}"
		printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
		return 0
	}

	[ -z "${repo_dir:+x}" ] ||
	[ -n "${repo_urn_output:+x}" ] || repo_urn_output="$repo_dir/$pkg_name"

	// debug '$repo_dir' "$repo_dir"
	// debug '$repo_urn_output' "$repo_urn_output"

	printf "\n%s$FS%s$FS%s" "$pkg_name" "$repo_dir" "$repo_urn_output"
}

[ -z "${KEEP_DEPRECATED+x}" ] ||
# Deprecated
# Pay attention to name overriding (use local keyword as much as possible)
# When there is an upper-scope variable has the same name with the current
# scope variable, and in the current scope it was defined as local variable,
# the upper-scope variable will not be modiffied
repo_resolve_no_subshell() {
	_level_2
	[ "$1" == "_" ] || [ -z "$1" ] || local pkg_name_name="${1#*" "}"
	local repo_urn="$2"
	[ -n "${repo_urn:+x}" ] || // die '$repo_urn' "\"$repo_urn\" is invalid"
	// debug '$repo_urn' "$repo_urn"

	repo_urn="$(standardize "$repo_urn")"
	local pkg_name_value="${repo_urn##*/}"
	# // log '$pkg_name_value' "$pkg_name_value"
	[ -z "${pkg_name_name:+x}" ] || {
		/ "$pkg_name_name=\"$pkg_name_value\""
		/ debug "$pkg_name_name" "\"\$$pkg_name_name\""
	}

	[ "$scope" != "repo_trace" ] || return 0

	[ "$3" == "_" ] || [ -z "$3" ] || local repo_dir_name="$3"
	[ "$4" == "_" ] || [ -z "$4" ] || local repo_urn_name="$4"

	[ -n "${repo_dir_name:+x}" ] || [ -n "${repo_urn_name:+x}" ] || return 0

	[ -z "${repo_dir_name:+x}" ] ||
	/ "local repo_dir_value=\"\$$repo_dir_name\""
	[ -z "${repo_urn_name:+x}" ] ||
	/ "local repo_urn_value=\"\$$repo_urn_name\""

	if [ -z "${repo_urn##*"/"*}" ] && [ -d "${repo_urn}" ]; then
		{ [ -z "${repo_dir_name:+x}" ] && [ -z "${repo_urn_name:+x}" ]; } ||
		local repo_dir_value="${repo_urn%/*}"
		[ -z "${repo_urn_name:+x}" ] || local repo_urn_value="$repo_urn"
	else
		{ [ -z "${repo_dir_name:+x}" ] && [ -z "${repo_urn_name:+x}" ]; } || {

			# [ -n "${repo_dir_value:+x}" ] ||
			# [ -z "${REPO_DIR:+x}" ] || {
			#     // log '$REPO_DIR' "$REPO_DIR"
			#     local repo_dir_value="$REPO_DIR"
			# }

			# [ -n "${repo_dir_value:+x}" ] ||
			# [ -z "${KISS_PATH##*:*}" ] ||
			# [ ! -d "$KISS_PATH/$pkg_name_value" ] || {
			#     // log '$KISS_PATH' "$KISS_PATH"
			#     local repo_dir_value="$KISS_PATH"
			# }

			[ -n "${repo_dir_value:+x}" ] || {
				// repo_urn_value="$(// delegate -- repo_trace \
						"$pkg_name_value" "" "-d" "$KISS_PATH")"
				local repo_dir_value="${repo_urn_value%/*}"
			}
		}
		[ -z "${repo_urn_name:+x}" ] ||
		local repo_urn_value="$repo_dir_value/$pkg_name_value"
	fi
	[ -z "${repo_dir_name:+x}" ] || {
		// log '$repo_dir_value' "$repo_dir_value"
		/ "$repo_dir_name=\"$repo_dir_value\""
	}
	[ -z "${repo_urn_name:+x}" ] || {
		// log '$repo_urn_value' "$repo_urn_value"
		/ "$repo_urn_name=\"$repo_urn_value\""
	}
}

# File Hierarchy
#
#  VOLATILE          DES_ROOT:/working/kiss          db_root:var/db/kiss
#     |                      |                               |
#     |             ______________________           _______________________
#     |             |        |           |           |       |      |      |
#     |         SRC_ROOT ARCHIVE_ROOT PROC_ROOT  REPO_ROOT sys_db choices hooks
#     |                                  |
#     |___________________           ____|_______________________
#     |         |        |           |         |       |        |
# MAKE_ROOT TEMP_ROOT OBJ_ROOT PKG_ROOT EXTRACT_ROOT BIN_ROOT TAR_ROOT
# sys_db ("var/db/installed" based on $KISS_ROOT is the only thing the target
# machine is supposed to get)
init_dirs() {
	local level=0
	[ "$level" -eq "-1" ] ||
	_level_2
	local ppwd="$1"
	shift 1

	# Environment and development
	#
	# Defined in ${LAYOUT_INIT:="/etc/profile.d/share"}
	# MNG_ROOT  -- package manager root (where this file comes from, optional, for developers)
	#
	# Defined in $LAYOUT_INIT
	# REPO_ROOT_DEV -- package repositories root (could be symbol link, readonly except git repo package version updating)
	# Should inside pick_up's searching $KISS_PATH
	#
	# Defined in $LAYOUT_INIT
	# DES_ROOT  -- package building stages resource root (heavily reading/writting)
	#
	# Defined by kiss manager users like
	# KISS_ROOT=/opt/kiss BOOTSTRAP= kiss
	# KISS_ROOT means TARGET_ROOT, (XHOST_ROOT by Glasnost Linux)
	#
	# Target system 
	#
	# Defined in $LAYOUT_INIT
	# REPO_ROOT/db_root -- package deployment configuration root (what target machine should know)

	[ -z "${MNG_ROOT:+x}" ] || // log '$MNG_ROOT' "$MNG_ROOT"
	: "${REPO_ROOT_DEV:?"KISS requires REPO_ROOT_DEV be set"}"
	// log '$REPO_ROOT_DEV' "$MNG_ROOT"

	# Thinking about DESTDIR
	: "${DES_ROOT:?"KISS requires DES_ROOT be set (prefer a normal user's share folder)"}"
	DES_ROOT="$(standardize "$DES_ROOT")"

	[ -d "$DES_ROOT" ] || {
		local des_parent="${DES_ROOT%/*}"
		[ "$des_parent" != "/" ] || des_parent="/working/kiss"
		// as_own "$des_parent" \mkdir -p "$DES_ROOT"
	}

	[ -n "${des_user:+x}" ] ||
	des_user="$(stat -c '%U' "$(readlink -f "$DES_ROOT")")"

	# proc_volatile="$KISS_TMPDIR/proc"
	: ${VOLATILE:="$KISS_TMPDIR"} && export VOLATILE
	[ -d "$VOLATILE" ] || \mkdir -p "$VOLATILE"

	# Move to user_log::$SESSION_PPID
	# // cue 'New session' "started at $KISS_PID"

	# Root directory standardization
	# KISS_ROOT means TARGET_ROOT, XHOST_ROOT
	KISS_ROOT=${KISS_ROOT%"${KISS_ROOT##*[!/]}"}
	kiss_root_user="$(// delegate -- owner "$KISS_ROOT/root")"
	# This allows for automatic setup of a KISS chroot and will
	# do nothing on a normal system.
	[ -d "$KISS_ROOT/" ] ||
		// as_own "$KISS_ROOT/" /usr/bin/mkdir -p "$KISS_ROOT/" 2>/dev/null || :

	# System package database.root
	# "/var/db/kiss"
	: "${REPO_ROOT:="/var/db/kiss"}" && export REPO_ROOT
	# For history compatibility ?
	# "var/db/kiss"
	: "${db_root:="${REPO_ROOT#*/}"}" && export db_root
	# : "${db_root:="/var/db"}" && export db_root
	[ -d "$KISS_ROOT/$db_root" ] ||
		# // die '$REPO_ROOT' "'$REPO_ROOT' does not exist"
		// as_own "$KISS_ROOT/" \mkdir -p "$KISS_ROOT/$db_root"


	# For kiss usage, not final addresses
	# "var/db/kiss/installed"
	: "${db:="$db_root/installed"}"
	# "/var/db/installed"
	: "${sys_db:="/${db}"}"
	[ -d "$KISS_ROOT/$sys_db" ] || // as_own "$KISS_ROOT/" \mkdir -p "$KISS_ROOT/$sys_db"

	# From this location isolation, we can keep kiss independent to deployed machines
	: "${REPO_MAIN:="$REPO_ROOT/system"}" && export REPO_ROOT
	[ -d "$KISS_ROOT/${REPO_MAIN#*/}" ] || {
		# Link to local development repo root
		# Actually it is a recommended way to avoid maintaining a seperate repo
		[ -e "$REPO_ROOT_DEV/system" ] ||
			// die '$REPO_ROOT_DEV/system' "'$REPO_ROOT_DEV/system' does not exist${newline}\
			and you should better create it manually"

		// as_own "$KISS_ROOT/" \ln -sf "$REPO_ROOT_DEV/system" "$KISS_ROOT/${REPO_ROOT}/"
	}

	# For kiss usage, not final addresses
	# "var/db/choices"
	: "${cho_db:="$db_root/choices"}"
	# "$KISS_ROOT/var/db/choices"
	: "${sys_ch:="/${cho_db}"}"
	[ -d "$sys_ch" ] ||
	[ -L "$sys_ch" ] || {
		[ -e "$REPO_ROOT_DEV/choices" ] ||
		// as_own "$REPO_ROOT_DEV/" \mkdir -p "$REPO_ROOT_DEV/choices"

		// as_own "$KISS_ROOT/" \ln -sf "$REPO_ROOT_DEV/choices" "$KISS_ROOT/${REPO_ROOT}/"
		# // as_own "$KISS_ROOT/" \mkdir -p "$sys_ch"
	}

	# For kiss usage, not final addresses
	# "var/db/hooks"
	: "${hook_db:="$db_root/hooks"}"
	: "${sys_hk:="/${hook_db}"}"
	[ -d "$sys_hk" ] ||
	[ -L "$sys_hk" ] || {
		[ -e "$REPO_ROOT_DEV/hooks" ] ||
		// as_own "$REPO_ROOT_DEV/" \mkdir -p "$REPO_ROOT_DEV/hooks"

		// as_own "$KISS_ROOT/" \ln -sf "$REPO_ROOT_DEV/hooks" "$KISS_ROOT/${REPO_ROOT}/"
	}

	# For kiss usage, not final addresses
	// log '$db' "$db"
	// log '$cho_db' "$cho_db"

	// log '$hook_db' "$hook_db"

	[ -n "${REPO_MAIN:+x}" ] ||
	{ [ "$action" != "i" ] && [ "$action" != "install" ]; } ||
	// die '$REPO_MAIN' "'$REPO_MAIN' should be defined for reverse copying${newline}\
	sys_db/repo to the main repo during installation"

	# Top-level cache directory.
	cache_home=${XDG_CACHE_HOME:-"${HOME%"${HOME##*[!/]}"}/.cache"}
	cache_dir=${cache_home%"${cache_home##*[!/]}"}/kiss
	[ -d "$cache_dir" ] || mkdir -p "$cache_dir"
	cache_user="$(stat -c '%U' "$cache_dir")"

	# : "${share_src:="$DES_ROOT/sources"}"
	// share_link "share_src" "SRC_ROOT" "$DES_ROOT" "$cache_dir" "sources"

	[ -n "${SRC_USER:+x}" ] ||
	SRC_USER="$(stat -c '%U' "$(readlink -f "${SRC_ROOT}")")"
	export SRC_USER
	readonly SRC_USER

	# : "${share_proc:="$DES_ROOT/proc"}"
	# $cache_dir does not share, so share_proc must be a link point
	// share_link "share_proc" "PROC_ROOT" "$DES_ROOT" "$cache_dir" "proc"
	# Downloaded archives
	# : "${share_archive:="$DES_ROOT/archive"}"
	// share_link "share_archive" "ARCHIVE_ROOT" "$DES_ROOT" "$cache_dir" "archive"

	[ ! -L "$PROC_ROOT" ] || {
		PROC_ROOT="$(readlink -f "$PROC_ROOT")";
		[ -d "${PROC_ROOT}" ] || // as_own "${DES_ROOT%/*}" \mkdir -p "$PROC_ROOT"
	}

	# Temporary cache directories.
	MAKE_ROOT="$VOLATILE/make" && export MAKE_ROOT
	TEMP_ROOT="$VOLATILE/tmp"  && export TEMP_ROOT
	OBJ_ROOT="$VOLATILE/objects" && export OBJ_ROOT
	# log_dir="$VOLATILE/logs"

	PKG_ROOT="$PROC_ROOT/pkg" && export PKG_ROOT
	# Binary extract (usr, var, etc.)
	EXTRACT_ROOT="$PROC_ROOT/extract" && export EXTRACT_ROOT
	BIN_ROOT="$PROC_ROOT/bin" && export BIN_ROOT
	# Generated tar files
	TAR_ROOT="$PROC_ROOT/tar" && export TAR_ROOT

	# set +e will bypass the following line and without exit
	# [ -d "${PROC_ROOT}" ] && equ "reset" "$2" && \rm -rf "$PROC_ROOT" && exit 1

	# Using 'as $some_dir_to_be_made_user' of 'as_owner "$some_dir_to_be_made"'
	# all will fail because they pick up the new $some_dir_to_be_made to
	# display content. But that location does not exist yet
	\mkdir -p \
		"$MAKE_ROOT" \
		"$TEMP_ROOT" \
		"$OBJ_ROOT" ||
	// die 'mkdir' "'$MAKE_ROOT', '$TEMP_ROOT', '$OBJ_ROOT' failed"
	# "$log_dir" \

	as "$SRC_USER" \mkdir -p \
		"$PKG_ROOT" \
		"$EXTRACT_ROOT" \
		"$TAR_ROOT" \
		"$BIN_ROOT" ||
	// die 'mkdir' "'$PKG_ROOT', '$EXTRACT_ROOT', '$TAR_ROOT', '$BIN_ROOT' failed"

	[ -z "${CROSS_ACTION:+x}" ] || // log '$CROSS_ACTION' "$CROSS_ACTION"
	// log '$LOGNAME'       "$LOGNAME"
	// log '$DES_ROOT'      "$DES_ROOT"
	// log '$KISS_ROOT'     "$KISS_ROOT"
	// log '$SRC_ROOT'      "$SRC_ROOT"
	// log '$SRC_USER'      "$SRC_USER"
	// log '$time'          "$time"
	// log '$sys_db'        "$sys_db"
	// log '$KISS_TMPDIR'   "$KISS_TMPDIR"
	// log '$VOLATILE'      "$VOLATILE"
	// log '$_KISS_LVL'     "$_KISS_LVL"

}

pkg_clear() {
	_level_2

	local action="$1"
	local repo_urn="$2"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	# // cue '$pkg_name' "'$pkg_name' clear performed"
	[ -n "${pkg_name:+x}" ] || // die '$pkg_name' "should not be empty"

	# Let build functions do it
	# [ -n "${MAKE_ROOT:+x}" ] || // die '$MAKE_ROOT' "should not be empty"
	# [ ! -d "$MAKE_ROOT/$pkg_name" ] || [ "$MAKE_ROOT" = "/" ] || [ "$MAKE_ROOT" = "/make" ] ||
	# [ "$(// delegate -- occurrences "$MAKE_ROOT/$pkg_name" "/")" -le "1" ] ||
	# // as_own "$MAKE_ROOT" find "$MAKE_ROOT/$pkg_name" -mindepth 1 -delete

	[ -n "${TEMP_ROOT:+x}" ] || // die '$TEMP_ROOT' "should not be empty"

	[ ! -d "$TEMP_ROOT/$pkg_name" ] || [ "$TEMP_ROOT" = "/" ] || [ "$TEMP_ROOT" = "/tmp" ] ||
	[ "$(// delegate -- occurrences "$TEMP_ROOT/$pkg_name" "/")" -le "1" ] || {
		// cue '$TEMP_ROOT/$pkg_name' "$TEMP_ROOT/$pkg_name clear performed"
		// as_own "$TEMP_ROOT" find "$TEMP_ROOT/$pkg_name" -mindepth 1 -delete
	}

	# Istallation might need these pacakges for dependencies
	! is_pick "$action" || return 0

	[ "build" != "$action" ] || [ "b" != "$action" ] ||
	[ ! -d "$PKG_ROOT/$pkg_name" ] || [ "$PKG_ROOT" = "/pkg" ] ||
	empty "$PKG_ROOT/$pkg_name" || {
		// cue '$PKG_ROOT/$pkg_name' "$PKG_ROOT/$pkg_name clear performed"
		# // as_own "$PKG_ROOT" find "$PKG_ROOT/$pkg_name" -mindepth 1 -delete
		# Directories like this can't be deleted with normal rm
		# '/working/kiss/proc/extract/neovim/var/db/kiss/choices/neovim>usr>bin>c99'
		# rm: can't remove '/working/kiss/proc/extract/neovim/var/db/kiss/choices/neovim>usr>bin>c99': Permission denied
		# for item in $(find "$PKG_ROOT/$pkg_name" -type d -mindepth 1 -maxdepth 1); do
		for item in $(// as_own "$PKG_ROOT" \
			find "$PKG_ROOT/$pkg_name" -mindepth 1 -maxdepth 1); do
			# [ ! -e "$item" ] || [ ! -h "$item" ] ||
		// as_own "$item" \rm -rf "$item"; done
	}

	[ "install" != "$action" ] || [ "i" != "$action" ] ||
	[ ! -d "$EXTRACT_ROOT/$pkg_name" ] || [ "$EXTRACT_ROOT" = "/extract" ] ||
	empty "$EXTRACT_ROOT/$pkg_name" || {
		// cue '$EXTRACT_ROOT/$pkg_name' "$EXTRACT_ROOT/$pkg_name clear performed"
		# // as_own "$EXTRACT_ROOT" find "$EXTRACT_ROOT/$pkg_name" -mindepth 1 -delete
		# for item in $(find "$EXTRACT_ROOT/$pkg_name" -type d -mindepth 1 -maxdepth 1); do
		for item in $(// as_own "$EXTRACT_ROOT" \
			find "$EXTRACT_ROOT/$pkg_name" -mindepth 1 -maxdepth 1); do
			# choices folder items won't accept removing by normal users even it's is owned by the normal user
			# [ ! -e "$item" ] || [ ! -h "$item" ] ||
		// as "root" \rm -rf "$item"; done
	}

	# For pick_up to do a series of operations, we don't delete the results
	# tar_file in $TAR_ROOT/$pkg_name mean building succeeded
	# [ ! -d "$TAR_ROOT/$pkg_name" ] || [ "$TAR_ROOT" = "/tar" ] ||
	# find "$TAR_ROOT/$pkg_name" -mindepth 1 -delete

	# [ "$SRC_ROOT/$pkg_name" = "/$pkg_name" ] ||
	# find "$SRC_ROOT/$pkg_name"  -mindepth 1 -delete

	# [ ! -d "${KISS_TMPDIR}/proc" ] ||
	# for item in $(\ls -x "${KISS_TMPDIR}/proc"); do [ "$item" = "$pkg_name" ] || \rm -rf "${KISS_TMPDIR}/proc/$item"; done
}

# make or point to pkg_name related dirs
# $1 action    : args action
# $1 pkg_name  : package repo url/uri
pkg_dirs() {
	_level_2

	local action="$1"
	local repo_urn="$2"
	local pkg_name="${repo_urn##*/}"
	pkg_name="${pkg_name%%@*}"

	[ -n "${SRC_USER:+x}" ] ||
	/ "IFS=$(printf '%b' "$FS") read -r  SRC_USER _ \
		<< $(// here_doc -- owner_group "$SRC_ROOT")"
	> /dev/null || // die 'owner_group' "failed"

	// debug '$pkg_name' "$pkg_name"
	{
		ok "$log_dir" || // die '$log_dir' "${log_dir:+"${log_dir} "} is not defined"

		[ -d "$PROC_ROOT" ] || // die '$PROC_ROOT' "'$PROC_ROOT' dir does not exist"
		[ ! -z "${pkg_name:+x}" ] || // die '$pkg_name' "does not exist"

		// ownership "$PKG_ROOT"     "$PKG_ROOT/$pkg_name"
		// ownership "$EXTRACT_ROOT" "$EXTRACT_ROOT/$pkg_name"
		// ownership "$TAR_ROOT"     "$TAR_ROOT/$pkg_name"
		// ownership "$BIN_ROOT"     "$BIN_ROOT/$pkg_name"
		// ownership "$SRC_ROOT"     "$SRC_ROOT/$pkg_name"
		// ownership "$ARCHIVE_ROOT" "$ARCHIVE_ROOT/$pkg_name"

		# // pkg_clear "$action" "$repo_urn"

		mkdir -p \
			"$TEMP_ROOT/$pkg_name" \
			"$MAKE_ROOT/$pkg_name" \
			"$OBJ_ROOT/$pkg_name"

		as "$SRC_USER" mkdir -p \
			"$PKG_ROOT/$pkg_name" \
			"$EXTRACT_ROOT/$pkg_name" \
			"$TAR_ROOT/$pkg_name" \
			"$BIN_ROOT/$pkg_name"

		// log 'dirs initializd' "$repo_urn"
	}

	// debug '$TEMP_ROOT'    "$TEMP_ROOT"
	// debug '$MAKE_ROOT'    "$MAKE_ROOT"
	// debug '$OBJ_ROOT'     "$OBJ_ROOT"
	// debug '$SRC_ROOT'     "$SRC_ROOT"
	// debug '$PKG_ROOT'     "$PKG_ROOT"
	// debug '$EXTRACT_ROOT' "$EXTRACT_ROOT"
	// debug '$TAR_ROOT'     "$TAR_ROOT"
	// debug '$BIN_ROOT'     "$BIN_ROOT"
	// debug '$ARCHIVE_ROOT' "$ARCHIVE_ROOT"

	# printf "%s" "$PROC_ROOT"
}

subshell_all() {
	_level_2
	[ -t 0 ] || { // war 'fd 0' "recovered"; exec </dev/tty; }
	local action="$1"
	shift 1
	if equ "$#" "1"; then
		// log '$#' "$# package needs to be proceeded"
	elif [ "$#" -gt "1" ]; then
		// log '$#' "$# packages need to be proceeded"
	fi
	// log '$_KISS_LVL' "$_KISS_LVL [before enter \"$action\" subshell]"

	# printf '%s' "" | as_own "$KISS_ROOT/" tee "$ROOT_OUTPUT"
	# // log '$USER_OUTPUT' "$USER_OUTPUT"
	# // log '$ROOT_OUTPUT' "$ROOT_OUTPUT"

	# // kill_pipe 'PID_LOG' "$PID_LOG"
	# // kill_pipe 'PID_SAY' "$PID_SAY"

	local install_state=0
	# printf '%s\n' "$install_state" > "$KISS_TMPDIR/logs/install_state"

	// trap_off
	local index=0
	# {} | tee -a "$user_output" will disable colors and lost variable modifications
	# {
	for repo_urn do
		local pkg_name="${repo_urn##*/}"
		pkg_name="${pkg_name%%@*}"
		// log '$index' "$index"
		# Current file name with full path
		// log '$0' "$0"
		// log '$action' "$action"
		// log '$repo_urn' "$repo_urn"
		// log '$pkg_name' "$pkg_name"
		[ -n "${REPO_DIR:+x}" ] || REPO_DIR=""
		! is_repos "$repo_urn" || REPO_DIR="${repo_urn%/*}"
		// log '$REPO_DIR' "$REPO_DIR"

		# Let real local whoami determine who am I. Don't set it from outside
		# LOGNAME="$LOGNAME" \
		# HOME="$HOME" \
		# XDG_CACHE_HOME="$XDG_CACHE_HOME" \
		# KISS_TMPDIR="$KISS_TMPDIR" \
		# KISS_FORCE="${KISS_FORCE-}" \
		# KISS_CHOICE="${KISS_CHOICE-}" \
		# KISS_COLOR="${KISS_COLOR-}" \
		# PID_SAY="$PID_SAY" \
		# PID_LOG="$PID_LOG" \

		# Modifying "readonly USER_OUTPUT" in "as root env" calling is not a good design
		# USER_OUTPUT=\"$ROOT_OUTPUT\" \

		# Readonly
		# KISS_PATH=\"$KISS_PATH\" \
		# _KISS_LVL=\"$((_KISS_LVL + 1))\" \
		# SESSION_PPID=\"$SESSION_PPID\" \
		# SHELL_OPTIONS=\"e$(printf '%s' "$-")\" \

		local env_variables=" RUSTFLAGS=\"--remap-path-prefix=${PWD=.} ${RUSTFLAGS-}\" "
		env_variables="$env_variables KISS_XHOST_ARCH=\"$KISS_XHOST_ARCH\" "
		env_variables="$env_variables KISS_XBUILD_ARCH=\"$KISS_XHOST_ARCH\" "
		env_variables="$env_variables CHOST=\"${KISS_XHOST_TRIPLE}\" "
		env_variables="$env_variables CBUILD=\"${KISS_XBUILD_TRIPLE}\" "
		env_variables="$env_variables KISS_XHOST_ABI=\"$KISS_XHOST_ABI\" "
		env_variables="$env_variables KISS_XBUILD_ABI=\"$KISS_XBUILD_ABI\" "
		env_variables="$env_variables KISS_XHOST_TRIPLE=\"$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI\" "
		env_variables="$env_variables KISS_XBUILD_TRIPLE=\"$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI\" "
		env_variables="$env_variables DES_ROOT=\"$DES_ROOT\" "
		env_variables="$env_variables KISS_COMPRESS=\"$KISS_COMPRESS\" "
		env_variables="$env_variables KISS_ROOT=\"$KISS_ROOT\" "
		env_variables="$env_variables REPO_MAIN=\"$REPO_MAIN\" "
		env_variables="$env_variables SESSION_PID=\"$SESSION_PID\" "
		env_variables="$env_variables KISS_PID=\"$KISS_PID\" "
		env_variables="$env_variables CROSS_ACTION=\"${CROSS_ACTION:-"$action"}\" "
		env_variables="$env_variables SHELL_OPTIONS=\"$SHELL_OPTIONS\" "
		env_variables="$env_variables REPO_BASE=\"$REPO_BASE\" "
		env_variables="$env_variables REPO_DIR=\"$REPO_DIR\" "
		env_variables="$env_variables SRC_ROOT=\"$SRC_ROOT\" "
		env_variables="$env_variables MAKE_ROOT=\"$MAKE_ROOT\" "
		env_variables="$env_variables OBJ_ROOT=\"$OBJ_ROOT\" "
		env_variables="$env_variables DESTDIR=\"$PKG_ROOT/$pkg_name\" "

		[ -z "${DEBUG_AT_BACKGROUND+x}" ] ||
			env_variables="$env_variables DEBUG_AT_BACKGROUND=\"$DEBUG_AT_BACKGROUND\" "
		[ -z "${KISS_FORCE+x}" ] ||
			env_variables="$env_variables KISS_FORCE=\"$KISS_FORCE\" "
		# Pipe design hides the standard output
		# $ROOT_OUTPUT is not necessary
		# as_own "$KISS_ROOT/" sh -c "tee -a $ROOT_OUTPUT < $pipe" &

		env_variables="$env_variables KISS_ALTER_AS_LIBRARY=\"\" "

		/ "$env_variables \
			. \"/usr/bin/kiss-alter\" \"$action\" \"$repo_urn\" 2>&1" && {

		# / "as_own \"$KISS_ROOT/\" \
		#   env \
		#   $env_variables \
		#     \"/usr/bin/kiss-alter\" \"$action\" \"$repo_urn\" 2>&1" && {

			// cue '$pkg_name' "'$pkg_name' $action succeeded"
			// log '$repo_urn' "$repo_urn"
			// log 'test' "test_-2"
			: $((index += 1))
			// log '$index' "$index"
			// log 'test' "test_-1"
		} || {
			# \"/usr/bin/kiss\" \"$action\" \"$repo_urn\" 2>&1" || {

			# sh -c -e '/usr/bin/kiss $action $repo_urn > $pipe' 2>&1" || {
			# "$0" "$action" "$repo_urn" 2>&1 || {

			// war '$repo_urn' "subshell install failed"
			// log '$index' "$index"
			// log '$0' "$0"
			// log '$action' "$action"
			// log '$repo_urn' "$repo_urn"

			[ -z "${KISS_INNER_PIPE:+x}" ] || {
				# \ls -alh "/tmp/$kiss_root_user/kiss/logs/build.log"
				# read -r _

				# [ -z "${USE_SAY_PIPE+x}" ] ||
				clear_outer "PID_SAY"
				clear_outer "PID_LOG"
			}

			install_state=1
			# printf '%s\n' "$install_state" > "$KISS_TMPDIR/logs/install_state"

			# One-time useage of an input, don't modify global user_output, please
			# Pseudo code
			# "$user_output" == "/tmp/$kiss_root_user/kiss/logs/build.log"

			// log "$find_tip" "$USER_OUTPUT"
			# // log "$find_tip" "$ROOT_OUTPUT"

			// log_shift "$cache_dir/logs/$pkg_name/build.log" "$USER_OUTPUT"
			# // log_shift "$cache_dir/logs/$pkg_name/build.log" "$ROOT_OUTPUT"

			# kill 0 ||
			# // kill_subtree "$KISS_PID"
			// die "$pkg_name" "quit current install process"
			interrupt
			# // war \$SESSION_PID "'$SESSION_PID' was gona being killed. \
			#   ${newline}You have to reload kiss"
			# ! pid_alive $SESSION_PID || { kill -KILL $SESSION_PID; }
		} # | tee -a "$USER_OUTPUT"

	# [ "$install_state" -eq "0" ] && {
	#   // cue '$pkg_name' "'$pkg_name' $action succeeded"
	#   // log '$index' "$index"
	#   // log '$repo_urn' "$repo_urn"
	#   // log 'test' "test_-2"
	#   : $((index += 1))
	#   // log 'test' "test_-1"
	# }
	done
	// log 'test' "test_-0"

	# Pipe here will erase variables inside this scope
	# It means that you have to use files to transfer inside status out or via other means
	# } | tee -a "$USER_OUTPUT"

	// log 'test' "test_00"
	# One-time useage of an input, don't modify global user_output, please
	# Pseudo code
	# "$user_output" == "/tmp/$kiss_root_user/kiss/logs/build.log"

	# \ls -alh "/tmp/$kiss_root_user/kiss/logs/build.log"
	# read -r _

	# Self clean when quit subshell
	# clear_outer "PID_SAY"
	# clear_outer "PID_LOG"

	# install_state="$(cat "$KISS_TMPDIR/logs/install_state")"
	[ "$install_state" -eq "0" ] && {
		// log 'test' "test_01"
		// log '$index' "$index"

		[ "$index" -eq "1" ] ||
		// cue '$action' "'$index' packages $action succeeded"

		# equ "$LOGNAME" "$kiss_root_user" || // log_shift "$USER_OUTPUT" "$ROOT_OUTPUT"

		// log 'test' "test_02"
		// trap_on "$action" "$@"
		// log 'test' "test_03"
	} || {
		// war '$install_state' "$install_state"
		// war '$SESSION_PID' "$SESSION_PID"
		# kill_name "$CROSS_ACTION" "$pkg_name"
		# Will kill the main process
		# kill_tree "$SESSION_PID" true
		interrupt    # kill_tree "$SESSION_PID"
		# return "$install_state"
	}
}

args() {
	_level_2
	# type is_writable
	// war '$TTY' "$TTY"
	// pipe_report "PID_SAY" "$TTY"
	pipe_state "PID_SAY" "$TTY" && SAY_STATE="" && export SAY_STATE
	[ -t 0 ] || { // war 'fd 0' "recovered"; exec </dev/tty; }
	# [ -t 1 ] || { // war 'fd 1' "recovered"; exec &>/dev/tty; }
	# [ -t 2 ] || { // war 'fd 2' "recovered"; exec &>/dev/tty; }

	# type is_writable
	# /usr/bin/ash: set: line 6291: illegal option -s
	# options_filter
	SHELL_OPTIONS="$(// delegate -- options_filter)"
	export SHELL_OPTIONS

	set "-e$SHELL_OPTIONS"
	// log '$SHELL_OPTIONS' "$SHELL_OPTIONS"
	// log '$-' "$-"

	SESSION_PID="$$"
	// log '$SESSION_PID' "$SESSION_PID"
	# The assignment will stop current process? becuse SESSION_PPID is read only
	# { SESSION_PPID="$PPID"; }
	# // log '$SESSION_PPID' "$SESSION_PPID"

	# Parse script arguments manually. This is rather easy to do in our case
	# since the first argument is always an "action" and the arguments that
	# follow are all package names.
	# kiss_commanda are instructed by CROSS_ACTION
	action="${1-}"
	# [ ! -z "${CROSS_ACTION:+x}" ] && action="$CROSS_ACTION" || {
		shift "$(($# != 0))"
	# }

	// cue '$action' "$action"

	! is_pick "$action" || { select_index="${2-}"; set -- "${1-"${PWD##*/}"}"; }

	[ "$#" -eq "0" ] &&
	{
		[ -z "${action:+x}" ] || [ "$action" = "h" ] ||
			// die 'no' "target"
	} || // war '$@' "$(esceval "$@")"
	# pkg_order() needs the following variables to be declared here
	local deps= makedeps= explicit=
	# Ensure that arguments do not contain invalid characters. Wildcards can
	# not be used here as they would conflict with kiss extensions.
	# shellcheck disable=SC1035
	case "$action" in
		"a"|"alternatives")
			case "$1" in *"\*"*|*"\!"*|*"\["*|*"\ "*|*"\]"*|*"/"*|*"$newline"*)
				// die 'Invalid argument' "'!*[ ]/\\n' ($1)"
			esac
		;;

		# b|build|c|checksum|d|download|i|install|l|list|m|manifest|r|remove|u|update)
		b|build|c|checksum|d|download|i|install|l|list|m|manifest|u|update)
			for _arg do case "${action%%"${action#?}"}-$_arg" in
				"i-"*"\!"*|"i-"*"\*"*|"i-"*"\["*|"i-"*"\ "*|"i-"*"\]"*|"i-"*"$newline"*)
					// die 'Invalid argument' "'!*[ ]\\n' ('$_arg')"
					;;

				[!i]-*"\!"*|[!i]-*"\*"*|[!i]-*"\["*|[!i]-*"\ "*|[!i]-*"\]"*|[!i]-*"$newline"*)
				# [!i]-*\]*|[!i]-*/*|[!i]-*"$newline"*)
					// die "Might be wrong usage of argument \
					'!*[ ]/\\n' ('$_arg')." "Use a package name, please."
					;;
			esac done

			# Modified KISS_PATH to readonly
			# # When no arguments are given on the command-line, use the basename
			# # of the current directory as the package name and add the parent
			# # directory to the running process' KISS_PATH.
			# case ${action%%"${action#?}"}-$# in [!l]-0)
			#     export KISS_PATH=${PWD%/*}:$KISS_PATH
			#     set -- "${PWD##*/}"
			# esac

			# Modified KISS_PATH to readonly
			# # Search the installed database first when removing packages. Dependency
			# # files may differ when repositories change. Removal is not dependent on
			# # the state of the repository.
			# case $action in r|remove)
			#     export KISS_PATH=$sys_db:$KISS_PATH
			# esac

			# !!

			local order= redro=
			# Order the argument list based on dependence.
			/ "IFS=$(printf '%b' "$FS") read -r order redro deps makedeps \
				<< $(// here_doc -- pkg_order "$deps" "$makedeps" "$@")"
			2> /dev/null || // die 'pkg_order' "failed"

			for repo_urn in $order; do
				// pkg_dirs "$action" "${repo_urn##*/}"
			done

			# ^^

			# Intentional, globbing disabled.
			# shellcheck disable=2046,2086
			# Don't quote it
			set -- $order
	esac


	// log '$deps' "$deps"
	// log '$makedeps' "$makedeps"
	// log '$explicit' "$explicit"

	# Rerun the script as root with a fixed environment if needed. We sadly
	# can't run singular functions as root so this is needed.
	#
	# Intended behavior.
	# shellcheck disable=2030,2031
	[ -z "${KISS_FORCE+x}" ] || // log '$KISS_FORCE' "$KISS_FORCE"

	# _KISS_LVL will increment inside each subshell
	# case $action in a|alternatives|i|install|r|remove)
	#   # null "$action" ||
	#   # equ "$LOGNAME" "$(// delegate -- owner "$KISS_ROOT/")" || {
	#   equ "$LOGNAME" "root" || {
	#       // cue 'subshell' "$action"
	#       case $action in
	#           r|remove)
	#               local redro=
	#               for parameter in "$@"; do
	#                   for item in $(kiss-revdepends "$parameter" |
	#                       awk -F / '{print $1}' 2> /dev/null)
	#                   do
	#                       redro="${redro} $item"
	#                   done
	#               done
	#               set -- $redro "$@"
	#               // subshell_all "$action" "$@" ;;
	#           *)
	#               // subshell_all "$action" "$@"
	#       esac
	#       return 0
	#   }
	# esac

	# Need to increment _KISS_LVL here to ensure we don't wipe the cache
	# early by non-asroot invocations.
	# : $((_KISS_LVL += 1))
	# export _KISS_LVL
	# // log '$_KISS_LVL' "$_KISS_LVL [in args \"$action\"]"

	# Clear temporary files

	# This will cancell the process on busybox 1.35.0-2
	# when the variables have definition and set -e
	# [ -z "$KISS_DEBUG" ] || // log '$KISS_DEBUG' "$KISS_DEBUG"
	# null "$KISS_DEBUG" || // log '$KISS_DEBUG' "$KISS_DEBUG"
	# This will recover the process
	# [ -z "$KISS_DEBUG" ] || {
	# :
	# // log '$KISS_DEBUG' "$KISS_DEBUG"
	# }

	[ "$#" -eq "0" ] &&
	{ [ -z "${action:+x}" ] || [ "$action" = "h" ] ||
	// die 'no' "target"; } || { // cue '$action' "$action"; // war '$@' "$(esceval "$@")"; }
	[ -z "${KISS_DEBUG+x}" ] || // log '$KISS_DEBUG' "$KISS_DEBUG"

	# Actions can be abbreviated to their first letter. This saves keystrokes
	# once you memorize the commands.
	case "$action" in
		a|alternatives) # // pkg_alternatives "$@" ;;
			// alter "alternatives" "$@" 2>&1 || : ;;
		b|build)        // build_all "$deps" "$makedeps" $redro ;;
		c|checksum)     for pkg_name do // pkg_checksum "$pkg_name"; done ;;
		d|download)
			for pkg_name do
				local pkg_name_string="$(echo "$pkg_name" | sed 's/-/_/g')"
				[ -n "$(/ echo \${synchronized_${pkg_name_string}-})" ] ||
				// pkg_download "$pkg_name"; done ;;
		h|help-ext)     // pkg_help_ext "$@" ;;
		i|install)
			# for repo_urn do // pkg_install "$repo_urn"; done ;;
			// alter "install" "$@" 2>&1 || :
			;;
		l|list)         for repo_urn do // list_version "$repo_urn"; done ;;
		m|manifest)
			for repo_urn do
				// list_version "$repo_urn"
				[ ! -f "$KISS_ROOT/$db/${repo_urn##*/}/manifest" ] ||
				cat "$KISS_ROOT/$db/${repo_urn##*/}/manifest" 2>/dev/null || :
			done ;;
		p|pick)         // pick_up "$1" "$select_index" ;;
		r|remove)
			local redro=
			for parameter in "$@"; do
				for item in $(kiss-revdepends "$parameter" |
					awk -F / '{print $1}' 2> /dev/null)
				do
					redro="${redro} $item"
				done
			done
			set -- $redro "$@"

			# for repo_urn in "$@"; do // pkg_remove "$repo_urn"; done ;;
			// alter "remove" "$@" 2>&1 || : ;;
		s|search)
			for repo_urn; do
				for item in $(// delegate -- repo_trace "$repo_urn" all -d); do
					// log "$repo_urn" "$item"
				done; done ;;
		u|update)       // pkg_update "$deps" "$makedeps" $redro ;;
		U|upgrade)      // pkg_upgrade "$deps" "$makedeps" ;;
		v|version)      // version_installed "${1-}" ;;
		'')
			# // log 'kiss [a|b|c|d|i|l|m|r|s|u|U|v]' '[pkg]...'
			// log '[a|b|c|d|h|i|l|m|o|p|r|s|u|U|v] [pkg]...'
			// log 'a|alternatives' 'List and swap alternatives'
			// log 'b|build'        'Build packages'
			// log 'c|checksum'     'Generate checksums'
			// log 'd|download'     'Download sources'
			// log 'h|help'         "See all actions"
			// log 'i|install'      'Install packages'
			// log 'l|list'         'List installed packages'
			// log 'm|manifest'     'Package manifest'
			// log 'o|owns'         'Package ownership reverse search'
			// log 'p|pick'         'Query and pick up a package'
			// log 'r|remove'       'Remove packages'
			// log 's|search'       'Search for packages'
			// log 'u|update'       'Update the system and repositories'
			// log 'U|upgrade'      'Update the system'
			// log 'v|version'      'Package version'

			# // log '\nRun "kiss [H|help-ext]" to see all actions\n'
			;;

		*)
			# _KISS_LVL is readonly.The package manager should aware the level value
			# corresponding to the host instance (level 0).
			// debug '$#' "$#"
			[ -z "${2:+x}" ] || // debug '$2-$#' "$2-$#"

			local kiss_command="$( \
				// delegate -- repo_trace "kiss-$action*" "" -x "$PATH")"
			ok "$kiss_command" ||
			{ // war "kiss-$action*" "does not exist"; return 0; }
			// cue '$kiss_command' "$kiss_command"

			// debug '$sys_db' "$sys_db"
			// debug '$kiss_command' "$kiss_command"

			# Don't shut off the log function here
			# // kill_pipe 'PID_LOG' "$PID_LOG"
			# // kill_pipe 'PID_SAY' "$PID_SAY"

				# PID_SAY="$PID_SAY" \

			# Like this
			# /usr/bin/kiss-manifest $@
			# _KISS_LVL=1 "$kiss_command" "$@"
			# SHELL_OPTIONS="e$(printf '%s' "$-")" \
			set +f
			SHELL_OPTIONS="$(// delegate -- options_filter)"
			export SHELL_OPTIONS
			# env \
			#   SHELL_OPTIONS="$SHELL_OPTIONS" \
			#   _KISS_LVL="$_KISS_LVL" \
			#   CROSS_ACTION="$CROSS_ACTION" \
			#   SESSION_PPID="$SESSION_PPID" \
			#   SESSION_PID="$SESSION_PID" \
			#   "$kiss_command" "$@" || :

				# PID_LOG="$PID_LOG" \

				# _KISS_LVL=\"$_KISS_LVL\" \
				# SESSION_PPID=\"$SESSION_PPID\" \
				# SESSION_PID=\"$SESSION_PID\" \
			local env_variables=" SHELL_OPTIONS=\"$SHELL_OPTIONS\" CROSS_ACTION=\"$CROSS_ACTION\" "

			[ -z "${KISS_AS_LIBRARY:+x}" ] ||
				env_variables="$env_variables KISS_AS_LIBRARY=\"$KISS_AS_LIBRARY\" "

			/ "$env_variables . \"$kiss_command\" \"$@\" 2>&1" || :
			# pid_external="$!"
	esac

	[ "$PWD" = "$ppwd" ] || {
		// log 'test' "test_06"
		// log '$ppwd' "$ppwd"
		// log '$PWD' "$PWD"
		cd "$ppwd"
	}

	// cue 'usage' "action repo_urn_00 pkg_name_01 ..."

}

# Need a nicer way of detecting architecture
determine_arch() {
	_level_2
	local _arch="$($cmd_elf -a -W "$1" | grep 'Machine:')"
	local _endian="$($cmd_elf -a -W "$1" | grep 'Data:')"

	case "$_arch $_endian" in
		*AArch64*little*)   arch="aarch64-linux-musl";;
		*AArch64*big*)      arch="aarch64_be-linux-musl";;
		*ARM*)              arch="armv7-linux-musleabihf";;
		*Intel*80386*)      arch="i686-linux-musl";;
		*PowerPC64*little*) arch="powerpc64le-linux-musl";;
		*PowerPC64*big*)    arch="powerpc64-linux-musl";;
		*PowerPC*little*)   arch="powerpcle-linux-musl";;
		*PowerPC*big*)      arch="powerpc-linux-musl";;
		*X86-64*)           arch="x86_64-linux-musl";;
		*RISC-V*)           arch="riscv64-linux-musl";;
		*)
			// die 'Unknown architecture' "$_arch / $_endian"
			;;
	esac

	printf '\n%s' $arch
}

cross_flags() {
	_level_2

	# KISS_XBUILD_TRIPLE="$(clang -print-target-triple | sed 's/-unknown//')" ||
	# KISS_XBUILD_TRIPLE="$(cc -dumpmachine | sed 's/-unknown//')" ||
	# [ -n "${KISS_XBUILD_TRIPLE:+x}" ] ||
	KISS_XBUILD_TRIPLE="${KISS_XHOST_TRIPLE:-"$(// delegate -- determine_arch "/usr/bin/bzip2")"}"
	export KISS_XBUILD_TRIPLE
	KISS_XHOST_TRIPLE="${KISS_XHOST_TRIPLE:-"$(// delegate -- determine_arch "$KISS_ROOT/usr/bin/bzip2")"}"
	export KISS_XHOST_TRIPLE

	# set -f

	local ifs="$IFS"
	local IFS=$'-'

	set +f
	set -f -- $KISS_XBUILD_TRIPLE
	export KISS_XBUILD_ARCH="$1"
	export KISS_XBUILD_SYS="$2"
	export KISS_XBUILD_ABI="$3"

	set +f
	set -f -- $KISS_XHOST_TRIPLE
	export KISS_XHOST_ARCH="$1"
	export KISS_XHOST_SYS="$2"
	export KISS_XHOST_ABI="$3"

	IFS="$ifs"
	# Default is set -f ?
	# set +f

	# Flags used for pkg-config
	export PKG_CONFIG_PATH=
	export PKG_CONFIG_LIBDIR="${KISS_ROOT}"/usr/lib/pkgconfig:"${KISS_ROOT}"/usr/share/pkgconfig
	export PKG_CONFIG_SYSROOT_DIR="${KISS_ROOT}"

	# Don't carry over flags if this is a cross build
	[ -z ${KISS_ROOT:+x} ] || {
		unset CFLAGS
		unset CXXFLAGS
		unset LDFLAGS
	}

	# Allow setting of chroot-specific cflags
	flagfile="$KISS_ROOT/etc/os-buildflags"
	[ ! -f "$flagfile" ] || . "$flagfile"
	local cc="$(which cc)"
	local cxx="$(which c++)"
	: "${cc:="/usr/lib/ccache/bin/cc"}"   && export cc
	: "${cxx:="/usr/lib/ccache/bin/c++"}" && export cxx
	# Set the compiler target architecture
	if [ -z "${KISS_ROOT:+x}" ]; then
		# Local build. Allow user-set CFLAGS as per normal KISS, or override them in /etc/os-buildflags
		export  CC="${CC:-"$cc"}"
		export CXX="${CXX:-"$cxx"}"
	else
		# Cross build. CFLAGS will always come from $KISS_ROOT/etc/os-buildflags
		flags="--target=$KISS_XHOST_TRIPLE --sysroot=${KISS_ROOT} -fPIC"
		export   CFLAGS="$flags ${CFLAGS-}"
		export CXXFLAGS="$flags ${CXXFLAGS-}"
		export  LDFLAGS="--sysroot=$KISS_ROOT ${LDFLAGS-}"
		# llvm won't accept $CC with flages
		# export       CC="$cc $CFLAGS"
		export       CC="$cc"
		# llvm won't accept $CXX with flages
		# export      CXX="$cxx $CXXFLAGS"
		export      CXX="$cxx"
	fi
}

repo_setup() {
	_level_2
	# Set variables which help with cross building
	if [ -z "${KISS_BINREPO:+x}" ]; then
		// cross_flags

		# Bin repo will be "local" for normal builds, for chroot builds
		# it will be the last part of $KISS_ROOT appended with md5sum of
		# the full $KISS_ROOT path. This keeps packages built for different
		# root directories in separate directories.
		local lastbit="${KISS_ROOT##*/}"
		if null "$lastbit"; then
			binrepo="local"
		else
			binrepo="${lastbit}_$(echo "$KISS_ROOT" | md5sum | cut -c1-32)"
		fi
	else
		binrepo="$KISS_BINREPO"
	fi
}

pre_args() {
	_level_2

	[ -t 0 ] || // die 'fd 0' "does not work"

	// init_info

	# http://mywiki.wooledge.org/BashFAQ/105
	# Globally disable globbing and enable exit-on-error.

	# Moved to kiss-share
	# https://unix.stackexchange.com/questions/151771/getting-wrong-lineno-for-a-trapped-function

	// log '$-' "$-"
	# [ -n "${SHELL_OPTIONS:+x}" ] ||
	SHELL_OPTIONS="$(// delegate -- options_filter)"
	export SHELL_OPTIONS

	// log '$SHELL_OPTIONS' "$SHELL_OPTIONS"
	set "-e$SHELL_OPTIONS"

	// log '$-' "$-"

	# printf '%s %s\n' '$-' "$- [kiss]"
	# printf '%s %s\n' 'set -o' "[kiss]"
	# set -o
	# read -r

	type_include "is_writable" "function" ||
	// die 'function' "'is_writable' is not defined"

	# Store the original working directory to ensure that relative paths
	# passed by the user on the command-line properly resolve to locations
	# in the filesystem.
	ppwd="$PWD"

	# Store the date and time of script invocation to be used as the name of
	# the log files the package manager creates during builds.
	time="$(date +%Y-%m-%d-%H:%M)"

	# Moved to kiss-share
	# Never know when you're gonna need one of these.
#     newline="
# "
	# Defaults for environment variables.
	: "${KISS_COMPRESS:="gz"}" && export KISS_COMPRESS
	# : "${SESSION_PPID:="$(pid_parent "${PPID}")"}"
	# : "${KISS_PID:=$$}"
	: "${_KISS_LVL:="0"}"
	: "${CROSS_ACTION:=""}"

	: "${REPO_MAIN:?"KISS requires REPO_MAIN be set"}"
	: "${REPO_BASE:="$REPO_MAIN/base"}"
	REPO_URL="$(as_own "$REPO_MAIN" git -C "$REPO_MAIN" remote -v | grep "fetch" | awk '{print $2}')"
	export REPO_URL
	export SESSION_PPID

	# Moved to kiss-share
# : "${IFS=" $(printf '%s' "t" | tr 't' "\\t")
# "}"

	readonly IFS_ORIGIN
	readonly KISS_PATH
	readonly KISS_STRIP
	readonly KISS_CHOICE
	readonly SESSION_PPID
	readonly _KISS_LVL
	# readonly KISS_FORCE
	# readonly KISS_DEBUG

	[ -z "${KISS_FORCE+x}" ] || export KISS_FORCE
	[ -z "${KISS_CHOICE+x}" ] || export KISS_CHOICE
	[ -z "${KISS_COLOR+x}" ] || export KISS_COLOR

	# Only after thie line, logs might work
	# Moved to kiss-share
	// user_log

	[ -t 0 ] || // die 'fd 0' "does not work"
	// log '$@' "$(esceval "$@")"
	// debug '$COLOR_PARENT' "$COLOR_PARENT"
	// debug '$COLOR_CHILD' "$COLOR_CHILD"
	// debug '$COLOR_END' "$COLOR_END"

	# local content="$(// delegate -- prompt "Test prompt in kiss")"
	# ! expr "$content" : '[n|N]\+' > /dev/null || return 0
	# // war '$content' "$content"

	# Figure out which sha256 utility is available.
	cmd_sha=${KISS_CHK:-"$( \
		command -v /usr/bin/openssl   ||
		command -v /usr/bin/sha256sum ||
		command -v /usr/bin/sha256    ||
		command -v /usr/bin/shasum    ||
		command -v /usr/bin/digest
	)"} || // die 'sha256' "utility not found"

	# Figure out which download utility is available.
	cmd_get=${KISS_GET:-"$( \
		command -v /usr/bin/aria2c ||
		command -v /usr/bin/axel   ||
		command -v /usr/bin/curl   ||
		command -v /usr/bin/wget   ||
		command -v /usr/bin/wget2
	)"} || // die 'download utility' "not found (aria2c, axel, curl, wget, wget2)"

	[ -t 0 ] || // die 'fd 0' "does not work"

	// init_dirs "$ppwd"

	// repo_setup

	# Catch errors and ensure that build files and directories are cleaned
	# up before we die. This occurs on 'Ctrl+C' as well as success and error.
	# trap clean_all EXIT INT
	[ -z "${IS_KISS+x}" ] || {
		trap_print "trap_status" "INT|TERM|QUIT|PIPE|EXIT"
		[ -n "$trap_status" ] || {
			# printf '%s %s\n' 'trap' "definitions at $LINENO"
			// war 'trap' "definitions $(delegate -- format "before") trap_on"
			trap
		}
	}
	// trap_on "$@"
	[ -z "${IS_KISS+x}" ] || {
		trap_print "trap_status" "INT|TERM|QUIT|PIPE|EXIT"
		[ -n "$trap_status" ] || {
			# printf '%s %s\n' 'trap' "definitions at $LINENO"
			// war 'trap' "definitions $(delegate -- format "after") trap_on"
			trap
		}
	}
}

main() {
	____

	[ -z "${KISS_DEBUG:+x}" ] || local pid_list=

	// pre_args

	// args "$@"

	// log 'test' "test_07"
	# Logs have been written/shifted in "real time" (on subshell_all)
	# [ -n "${LOG_PERMANENT_ALL_DONE:+x}" ] || // log_shift_all "$user_output" "$@"

	# This line will be terminated by kill_subtree and log_shift_all will be blocked
	# // as_own "$log_dir" rm -f -- "$user_output"
	sync

	// log 'test' "test_08"
	# Do it in trap
	# // as_own "$log_dir" rm -f -- "$pipe_log"
	# // as_own "$log_dir" rm -f -- "$pipe_say"
	# [ ! -p "$pipe_log" ] || // die '$pipe_log' "$pipe_log"
	# [ ! -p "$pipe_say" ] || // die '$pipe_say' "$pipe_say"

	[ -z "${KISS_DEBUG:+x}" ] || {
		local item
		for item in $pid_list; do
			// debug_filter -- printf "%s %s\n" '$pid_list item' "$item"
			# kill -s SIGTERM "$item";
		done
		# "help jobs"
		// debug_filter -- printf '%s\n' "$(jobs -l)"
	}

	# trap 'kill -USR1 "\$SESSION_PID"; exit' INT TERM QUIT PIPE

	#         for trap_name in INT TERM  QUIT PIPE EXIT; do
	#             trap " \
	# printf '%s %s\n' \"trap\" \"at line $LINENO\"; \
	# // war '$trap_name' \"triggered in \\\"$FUNCNAME\\\"\"; \
	# // kill_all \"{kiss}\" \"${0##*/}\"; \
	# ! pid_alive \"$SESSION_PID\" || kill -USR1 \"$SESSION_PID\"; \
	# " $trap_name
	#         done

	# Mute the "Terminated" message? Mainly thinking about what went wrong with the desing, I think
	# trap "exit" 1
	# trap 'exit' 9

	// log '$SESSION_PID' "$SESSION_PID"
	// log '$PPID' "$PPID"
	// log '$SESSION_PPID' "$SESSION_PPID"
	# // log '$KISS_PID' "$KISS_PID"
	[ -z "${KISS_INNER_PIPE:+x}" ] || {
		# [ -z "${USE_SAY_PIPE+x}" ] ||
		[ -z "${PID_SAY:+x}" ] || // log '$PID_SAY' "${PID_SAY-}"
		[ -z "${PID_LOG:+x}" ] || // log '$PID_LOG' "${PID_LOG-}"
	}
	# [ "$SESSION_PPID" -ne "$PPID" ] ||
	# [ "$_KISS_LVL" -ne "0" ] || {
		# // log 'clean_all' "$(esceval "$@")"
		# clean_all needs to write log or debug message to user_output
		# // clean_all "$@"

		# Shut off the log/cue function
		# // log '$PID_SAY' "$PID_SAY will be killed"
		# // log '$(pstree -p "$KISS_PID")' "$(pstree -p "$KISS_PID")"

		# Considering no kill on normal processes
		# // kill_pipe 'PID_SAY' "$PID_SAY"

		# ! pid_alive "$PID_SAY" || kill -TERM "$PID_SAY"
		# (sleep 1 && ! pid_alive "$PID_SAY" || // war '$PID_SAY' "'$PID_SAY' killing failed") &

		# // log '$(pstree -p "$KISS_PID")' "$(pstree -p "$KISS_PID")"
		# // log '$PID_LOG' "$PID_LOG will be killed"
		# // log '$(pstree -p "$KISS_PID")' "$(pstree -p "$KISS_PID")"

		# // kill_pipe 'PID_LOG' "$PID_LOG"

		# ! pid_alive "$PID_LOG" || kill -TERM "$PID_LOG"
		# (sleep 1 && ! pid_alive "$PID_LOG" || // war '$PID_LOG' "'$PID_LOG' killing failed") &

		# // log '$(pstree -p "$KISS_PID")' "$(pstree -p "$KISS_PID")"

		# trap "kill 0" EXIT
		# trap "kill $(jobs -p)" EXIT
		# kill 0/$KISS_PID in this way (as root user) will reboot the system
		# trap 'as "root" kill $KISS_PID' EXIT
		# set -E; trap \'trace_line "$LINENO" "$lineno_scope" "$func_name" "$scope"\' ERR;
		# trap 'printf "%s\n" "ERROR on EXIT"; kill 0 || // kill_subtree "$KISS_PID"' EXIT
		# trap 'trace_line "$LINENO" "${lineno_scope:-"$LINENO"}" "$func_name" "${scope:-"kiss"}"' EXIT
		# trap 'kill 0 || // kill_subtree "$KISS_PID"' EXIT

		# trap 'pkill -P "$PPID" || // kill_subtree "$KISS_PID"' EXIT

		# kill 0 ||
		# // kill_tree "$KISS_PID" > /dev/null 2>&1
		# // kill $(pstree -p "$KISS_PID" | sed 's/(/\n(/g' | grep '(' | sed 's/(\(.*\)).*/\1/' | tr "\n" " ")
		# pkill -P "$PPID" || // kill_subtree "$KISS_PID"

	[ -z "${KISS_INNER_PIPE:+x}" ] || {
		# trap ' \
		# // kill_pipe "PID_SAY" "$PID_SAY"; \
		# // kill_pipe "PID_LOG" "$PID_LOG"' INT EXIT TERM
		# trap " \
		# kill -TERM \"$PID_SAY\"; \
		# kill -TERM \"$PID_LOG\"" INT EXIT TERM

		# trap ' \
		# // pipe_cancel "PID_SAY"; \
		# // pipe_cancel "PID_LOG"; exit' EXIT
		# trap "// kill_all $*" EXIT
		[ -z "${IS_KISS+x}" ] || {
			trap_print "trap_status" "INT|TERM|QUIT|PIPE|EXIT"
			[ -n "$trap_status" ] || {
				# printf '%s %s\n' 'trap' "definitions at $LINENO"
				// war 'trap' "definitions"
				trap
			}
		}
		# trap '// kill_subtree "$PPID"' INT EXIT TERM

		# [ "$SESSION_PPID" -ne "$KISS_PID" ] || kill 0 || // kill_subtree "$KISS_PID"
		# [ "$SESSION_PPID" -eq "$PPID" ] || kill 0 || // kill_subtree "$PPID"
		# [ "$SESSION_PPID" -ne "$PPID" ] || // kill_tree "$KISS_PID" > /dev/null 2>&1
		# [ "$SESSION_PPID" -eq "$PPID" ] || // kill_tree "$KISS_PID" > /dev/null 2>&1
	}
	# }

	[ -z "${KISS_DEBUG:+x}" ] || {
		// debug_filter -- printf '%s\n' "pstree at _KISS_LVL $_KISS_LVL at $KISS_PID"
		for pid in $(pstree -p "$KISS_PID" | sed 's/(/\n(/g' | grep '(' | sed 's/(\(.*\)).*/\1/'); do
			// debug_filter -- printf '%s %s\n' "_KISS_LVL $_KISS_LVL" "$pid"
		done
	}

	[ -z "${pid_external:+x}" ] ||
	! pid_alive "$pid_external" || {    # // kill_subtree "$pid_external"
		# [ -z "${KISS_DEBUG:+x}" ] ||
		// debug_filter -- printf '%s \n' "pid list of \$pid_external == $pid_external"
		for pid in $(pstree -p "$pid_external" | sed 's/(/\n(/g' | grep '(' | sed 's/(\(.*\)).*/\1/' | tr "\n" " "); do
			// debug_filter -- printf '%s \n' "\$pid_external child $pid"
			# kill_tree "$pid" true > /dev/null 2>&1
		done
		# // kill $(pstree -p "$pid_external" | sed 's/(/\n(/g' | grep '(' | sed 's/(\(.*\)).*/\1/' | tr "\n" " ")
	}

	[ -z "${KISS_INNER_PIPE:+x}" ] || {
		# [ -z "${USE_SAY_PIPE+x}" ] ||
		// debug_filter -- printf '%s %s\n' '$PID_SAY' "${PID_SAY-}"
		// debug_filter -- printf '%s %s\n' '$PID_LOG' "${PID_LOG-}"
	}
	// log 'test' "test_09"
	# // log '$0' "$0"
	// log '$$ : $0' "$(delegate -- format "$$") : $0"
	// log '$_KISS_LVL' "$_KISS_LVL"
	// log '$LOGNAME' "$LOGNAME"
	# shift 1
	# stty susp 'kill-name "$@"'
	# trap 'kill-name "$@"' TSTP

	# trap ' \
	# // kill_pipe "PID_SAY" "$PID_SAY"; \
	# // kill_pipe "PID_LOG" "$PID_LOG"' TSTP

	[ "$SESSION_PPID" -ne "$PPID" ] ||
		[ "$_KISS_LVL" -ne "0" ] || {
		[ -z "${KISS_INNER_PIPE:+x}" ] || {
			// debug_filter -- printf '%s %s\n' '$PID_SAY' "${PID_SAY-}"
			// debug_filter -- printf '%s %s\n' '$PID_LOG' "${PID_LOG-}"
		}
		# // pipe_cancel "PID_SAY"
		# // pipe_cancel "PID_LOG"
	}
	# ! pid_alive "$PID_SAY" || kill -TERM "$PID_SAY"
	# ! pid_alive "$PID_LOG" || kill -TERM "$PID_LOG"

	// log 'test' "test_10"
	[ -n "${KISS_AS_LIBRARY+x}" ] || // trap_off
	// log 'test' "test_11"
	return 0
}

# How to change user:
# doas login $USER
# The following methond won't work
# su - $USER

# kiss is the biggest repeatly reloading component
# These functions should not override other functions defined previously
function_define() {
	{ is_alias "$1" || is_function "$1"; } &&
	// war "$1" "already has a definition" ||
	/ "$1() ( // pre_args; // args \"$2\" \"\$@\"; )"
	# / "alias $1='( // args \"$2\" \"\$@\"; )'"
}

alter() {
	action="$1"; shift 1;
	[ "$(whoami)" = "root" ] &&
		// pre_args && subshell_all "$action" "$@" 2>&1 ||
		// as_own "$KISS_ROOT/" /usr/bin/kiss "$action" "$@";
}
a() { alter "alternatives" "$@"; }
r() { alter "remove" "$@"; }
i() { alter "install" "$@"; }

# // function_define "alternatives" "a"
# // function_define "i"            "i"
# // function_define "remove"       "r"

// function_define "b"            "b"
// function_define "checksum"     "c"
// function_define "download"     "d"
// function_define "f"            "find"
// function_define "help"         "h"
// function_define "k"            "kill"
// function_define "list"         "l"
// function_define "manifest"     "m"
// function_define "pick"         "p"
// function_define "search"       "s"
// function_define "update"       "u"
// function_define "upgrade"      "U"
// function_define "v"            "v"
// function_define "o"            "owns"
// function_define "link"         "link"
// function_define "bup"          "bup"
// function_define "chroot"       "chroot"
// function_define "cconf"        "cmake-config"
// function_define "dep"          "depends"
// function_define "fork"         "fork"
// function_define "genpkg"       "genpkg"
// function_define "maintainer"   "maintainer"
// function_define "mconf"        "meson-config"
// function_define "new"          "new"
// function_define "orphans"      "orphans"
// function_define "preferred"    "preferred"
// function_define "revdepends"   "revdepends"
// function_define "rst"          "reset"
// function_define "sz"           "size"

alias_define() {
	{ is_alias "$1" || is_function "$1"; } &&
	// war "$1" "already has a definition" || / "alias $1='$2'"
}

# // alias_define "a"    "alternatives"
# // alias_define "r"    "remove"

// alias_define "c"    "checksum"
// alias_define "d"    "download"
// alias_define "h"    "help"
// alias_define "l"    "list"
// alias_define "m"    "manifest"
// alias_define "p"    "pick"
// alias_define "s"    "search"
// alias_define "u"    "update"
// alias_define "U"    "upgrade"
// alias_define "orph" "orphans"
// alias_define "pref" "preferred"
// alias_define "rdep" "revdepends"

# If you still wanna /usr/bin/kiss, use it like this:
# unset KISS_AS_LIBRARY; KISS_FORCE= sh /usr/bin/kiss p runit

# We have to overwrite kiss() in ${SHARE_PREFIX:-/mnt}/init/env
# Usage: kiss l acl
# Output will print to original screen where kiss initialized
# kiss() { // args "$@"; }

# type is_writable

! is_alias "kiss" || unalias kiss
kiss() ( // pre_args; // args "$@"; )

# FATAL: ENV values in the shell environment wil ruin cmake, etc.
[ -z "${ENV:+x}" ] || unset ENV

: "${lineno="$((LINENO + 4))"}"
: "${lineno_scope="$lineno"}"
[ -z "${KISS_AS_LIBRARY+x}" ] && {
	# alias kiss=' // args "$@" '
	main "$@" || :
} || {
	# alias kiss=' KISS_AS_LIBRARY= SHELL_OPTIONS=$SHELL_OPTIONS // args "$@" '
	( // pre_args; // args "$@"; )
}

# Redirecting the errors output. But it will break subshell messages like:
# // as "root" env PATH="$PATH" ... '/usr/bin/kiss'
# trap won't be inherited by sub processes
exec 2>"$ERR_OUTPUT"

# vi:   set filetype=sh syntax=sh :
# vim:  set filetype=sh syntax=sh :
# nvim: set filetype=sh syntax=sh :





