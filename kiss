#!/bin/sh -eEf
# shellcheck source=/dev/null
#
# Simple package manager written in POSIX shell for https://kisslinux.org
#
# The MIT License (MIT)
#
# Copyright (c) 2019-2021 Dylan Araps
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Semantics
# XXX_DIR     : parent address for a package    (like dirname command)
# XXX_ROOT    : parent/root address for packages
# XXX_PATH    : full address of a package      (like realpath command)
# XXX_FOLDER  : parent dir name for a package   (has no path)

# xxx_dir     : parent address for a package (locally / does not export)

alias /='eval'
alias //='lineno="$LINENO"'
alias __='local mute=1'
alias ^^='local mute='

LINES="$(wc -l /usr/bin/kiss | cut -f 1 -d ' ')"

[ -n "${NL:+x}" ] || export NL='
'
[ -n "${TABSTOP:+x}" ]         || export TABSTOP=4
[ -n "${WIDTH_LINES:+x}" ]     || export WIDTH_LINES="${#LINES}"
[ -n "${WIDTH_SCOPE:+x}" ]     || export WIDTH_SCOPE=13
[ -n "${WIDTH_FUNC_NAME:+x}" ] || export WIDTH_FUNC_NAME=13
[ -n "${WIDTH_KEY:+x}" ]       || export WIDTH_KEY=17
[ -n "${DELIMITER:+x}" ]       || export DELIMITER="$NL"
[ -n "${USE_TAG:+x}" ]         || export USE_TAG=1

[ -n "${LENGTH_VER:+x}" ]   || LENGTH_VER="$((WIDTH_FUNC_NAME - TABSTOP - 2))"
[ -n "${MARGIN_ROUTE:+x}" ] || MARGIN_ROUTE="$((WIDTH_KEY - 3 * TABSTOP - 2))"
# [ -n "${MARGIN_ROUTE:+x}" ] || MARGIN_ROUTE="$((WIDTH_KEY - 2 * TABSTOP - 1))"

# Refering to FUNCNAME each time is annoying
# Without this inserted into a function, you will get parent "func_name" for logs and bug reports
# Otherwise you will get local reports
# LINENO does nost have luck as FUNCNAME. You need to evaluate it before you want to get the current line number
alias _env=$'set -eE; trap \'trace_line "$LINENO"\' ERR; local scope="$func_name" func_name="$FUNCNAME" lineno_scope="$lineno" lineno="$LINENO"; [ "$scope" != "$func_name" ] || // die "$scope" "recursived"; // debug \'$@\' "$(esceval "$@")" '

# $1 string
# $2 sub_str
contains() {
    # Check if a "string list" contains a word.
    case " $1 " in *" $2 "*) return 0; esac; return 1
}

equ() {
    # Check if a string is equal to enother.
    # This replaces '[ "$var" = str ]' and '[ "$var" != str ]'.
    case "$1" in "$2") return 0 ;; *) return 1; esac
}

ok() {
    # Check if a string is non-null.
    # This replaces '[ "$var" ]', '[ -n "$var" ]'.
    case "$1" in '') return 1 ;; *) return 0; esac
}

null() {
    # Check if a string is null.
    # This replaces '[ -z "$var" ]'.
    case "$1" in '') return 0 ;; *) return 1; esac
}

# Error trace
trace_line() {
    local lineno="$1"
    # die "$lineno" 'trap'
    set -E
    [ -z "${scope##*ERROR*}" ] || local func_name="${func_name} ERROR"
    local c1='\033[1;41m'
    local c2='\033[1;32m'
    local c3='\033[m'
    local result="$(see "$lineno_scope" "$lineno" "trace error" "process halted")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"
    # bog "$lineno" "$log_output" "trace error" "process halted"
    # bog "$lineno" "$log_output" "find log at" "$log_output"
    # read -r _
    kill 0
}

# "set -e" did this
# trap 'trace_line "$(readlink -f "$0")" "$LINENO"' ERR

# https://stackoverflow.com/questions/70675246/replacing-newlines-with-the-string-n-with-posix-tools
magic() { { cat -u; printf '\n'; } | awk -v ORS= '{print sep $0; sep="\\n"}'; }

# https://stackoverflow.com/questions/12162010/posix-sh-equivalent-for-bash-s-printf-q
esceval() {
    local level="-1"
    [ "$level" -eq "-1" ] || { _env; }
    local result=
    case $# in 0) return 0; esac
    local index=0
    while :
    do
        if null "$result"; then
            result="'"
        else
            result="$result'${DELIMITER}'"
        fi
        : $((index += 1))
        # // debug "$scope \$@ \$$index" "$1"
        case "$1" in
            '') result="$result$(printf '%s' "")" ;;
            *)  result="$result$(printf '%s' "$1" | sed "s/'/'\\\\''/g")"
        esac
        shift
        case $# in 0) break; esac
    done
    result="$result'"
    printf '%s' "$result"
}

run() {
    _env
    # Print the command, then run it.
    // log "$scope" "$*"
    "$@"
}

# Some maintainers might print debug information to stdout in a function's definition,
# but which function has a return value.
# This delegation makes it sure of only getting the printf content after the last \n,
# which content comes from a
# function_name() { printf "\n%s" "$return_value"; }
# local var="$(delegate -- function_name "$@")"
delegate() {

    // debug '$@' "$(esceval "$@")"

    ! equ "$1" "--" || shift 1
    printf '%s\n' "$("$@" | awk 'BEGIN{ RS = ""; FS = "\n" }{print $NF}')"
}

# Should be subshell function
occurrences() {
    _env
    { [ -n "$1" ] && [ -n "$2" ]; } || // die 'Wrong parameters' "for function"
    local s="$1"
    local sub_str="$2"
    count=0
    until
        t=${s#*"$sub_str"}
        [ "$t" = "$s" ]
    do
        count=$((count + 1))
        s=$t
    done
    printf "%s" "$count"
}

# Should be subshell function
standardize() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    local path="$1"

    ok "$path" || { printf "%s" ""; return 0; }

    [ "${path:0:2}" != '//' ] || path="${path#/}"

    [ "${path:$((${#path} - 1))}" != '/' ] || path="${path%/}"

    [ "${path:$((${#path} - 1))}" != '*' ] || path="${path%\*}"

    [ "${path##*/}" != "." ] || path="${path%/*}"

    ok "$path" || { printf "%s" ""; return 0; }

    [ "$path" == "$1" ] || path="$(standardize "$path")"

    printf "%s" "$path"
}

spaces() {
    _env
    local header_width=$1
    local length_header=$2
    local index=1
    local white_spaces=
    while [ "$index" -le "$((header_width - length_header))" ]; do
        white_spaces=" ${white_spaces}"
        let "index = index + 1"
    done
    printf "%s" "${white_spaces}"
}

# $1 output
# $2 input : length of final target
length_trim() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    local target_name="$1"
    local length_final="$2"
    / "local v=\"\$$target_name\""

    // debug "\$${target_name}" "$v before trimmed"

    [ "${#v}" -le "$length_final" ] || / "${target_name}=\"${v:${#v}-$length_final}\""

    // debug '\$${target_name}' "\$${target_name} after trimmed"
}

# 0=$(tabstop_remainder -16)
# 3=$(tabstop_remainder -17)
tabstop_remainder() {
    local length=$1
    local length_with_tabstop=$((length > 0 ? ((length / TABSTOP + 1)) * TABSTOP \
                - length : length - ((length / TABSTOP - 1)) * TABSTOP))
    [ "$length_with_tabstop" -ne "4" ] || length_with_tabstop=0
    printf '%s' "$length_with_tabstop"
}

[ -n "${LENGTH_HEADER:+x}" ] || export LENGTH_HEADER="$((WIDTH_SCOPE + (WIDTH_LINES + 1) + WIDTH_FUNC_NAME + (WIDTH_LINES + 1) + WIDTH_KEY))"

# [ -n "${OUTPUT_VERSION:+x}" ] || export OUTPUT_VERSION=5

see() {

    # local key="$1"
    # local contents="$(printf "%b" "$(printf '%s' "$2" | magic)" | tr "\n" " ")"
    # [ -z "${contents##*"'"*"'"*}" ] || contents="'$contents'"
    # # Line number might come from _env or bog itself
    # [ -z "$3" ] || local lineno="$3"

    # local length_scope=$((${#scope} + 1))
    # [ "$c1" != "$KISS_C1" ] || [ "$length_scope" -le "$WIDTH_SCOPE" ] || scope="${scope:$length_scope - $WIDTH_SCOPE}"
    # length_scope=$((${#scope} + 1))
    # local margin_scope=$((WIDTH_SCOPE - length_scope))
    # [ $margin_scope -ge 0 ] || margin_scope=$(tabstop_remainder $length_scope)
    # local length_func_name=$((${#func_name} + 1))
    # [ "$c1" != "$KISS_C1" ] || [ "$length_func_name" -le "$WIDTH_FUNC_NAME" ] || func_name="${func_name:$length_func_name - $WIDTH_FUNC_NAME}"
    # length_func_name=$((${#func_name} + 1))
    # local margin_func_name=$((WIDTH_FUNC_NAME - length_func_name))
    # [ $margin_func_name -ge 0 ] || margin_func_name=$(tabstop_remainder $length_func_name)

    # # local length_contents=$((${#contents} + 1))
    # # margin_contents=$(tabstop_remainder $length_contents)

    # # printf "%b%-$((${WIDTH_SCOPE} - 1))s%b %b%-$((${WIDTH_FUNC_NAME} - 1))s%b %b%-$((${WIDTH_KEY} - 1))s%b %s %-${margin_contents}s \
    # # printf "%b%-${margin_scope}s%s%b %b%-${margin_func_name}s%s%b %b%-$((${WIDTH_KEY} - 1))s%b close to line %s %-${margin_contents}s %s" \
    # printf "%b%-${margin_scope}s%s %b%b%-${margin_func_name}s%s %b%b%-$((${WIDTH_KEY} - 1))s %b'close to line %s' %s" \
    #     "$c1" "" "$scope" "$c3" "$c1" "" "$func_name" "$c3" "$c2" "$key" "$c3" "$lineno" "$contents"

    local lineno_scope="$1"
    local lineno="$2"
    shift 2
    local key="$1"
    local contents
    local result=

    # Problematical design
    if null "$2"; then
        # $2 is not set at all
        # printf "-z \$2: %s %s %s\n" "$FUNCNAME" '$key' "$key" > /dev/stderr
        case "$key" in
            *'$'*)
                # // debug '$1' "$1"
                contents="$(/ echo "$key")"
                ;;
            *)
                contents="$key"
                key=""
        esac
    else
      # $2 is empty or something else
      # printf "non -z \$2: %s %s %s\n" "$FUNCNAME" '$key' "$key"
      contents="$2"
    fi

    # semantic          demo                definition
    # RESERVED LENGTH   WIDTH_LINES + 1     LENGTH_HEADER
    # real length + 1   WIDTH_LINES + 1     wrapped_key
    # printf spaces     0                   wrapped_key

    local length_scope=$((${#scope} + 1))
    [ "$c1" != "$KISS_C1" ] || [ "$length_scope" -le "$WIDTH_SCOPE" ] || scope="${scope:$length_scope - $WIDTH_SCOPE}"
    # local length_scope=$((WIDTH_SCOPE > length_scope ? WIDTH_SCOPE : length_scope))
    length_scope=$((${#scope} + 1))
    local margin_scope=$((WIDTH_SCOPE - length_scope))
    [ $margin_scope -ge 0 ] || margin_scope=$(tabstop_remainder $length_scope)

    local length_func_name=$((${#func_name} + 1))
    [ "$c1" != "$KISS_C1" ] || [ "$length_func_name" -le "$WIDTH_FUNC_NAME" ] || func_name="${func_name:$length_func_name - $WIDTH_FUNC_NAME}"
    length_func_name=$((${#func_name} + 1))
    local margin_func_name=$((WIDTH_FUNC_NAME - length_func_name))
    [ $margin_func_name -ge 0 ] || margin_func_name=$(tabstop_remainder $length_func_name)

    local length_key=$((${#key} + 1))
    # local margin_key=$((WIDTH_KEY - length_key))
    # [ $margin_key -ge 0 ] || margin_key=$(tabstop_remainder $margin_key)
    local margin_header=
    null "$contents" || {
        # Using "$scope $key" as a combined header
        margin_header=$((WIDTH_SCOPE + WIDTH_FUNC_NAME + WIDTH_KEY - length_scope - margin_scope - length_func_name - margin_func_name - length_key))
        [ $margin_header -ge 0 ] || margin_header=$(tabstop_remainder $((length_scope + margin_scope + length_func_name + margin_func_name + length_key)))
    }

    local wrapped_scope="$(printf "%b%${margin_scope}.0s%s %b" "$c1" "" "$scope" "$c3")"
    local wrapped_func_name="$(printf "%b%-${WIDTH_LINES}s %b%b%${margin_func_name}.0s%s %b" "$c4" "$lineno_scope" "$c3" "$c1" "" "$func_name" "$c3")"
    local wrapped_key="$(printf "%b%-${WIDTH_LINES}s %b%b%s%${margin_header}.0s %b" "$c4" "$lineno" "$c3" "${key:+$c2}" "$key" "" "$c3")"
    local wrapped_header="$wrapped_scope$wrapped_func_name$wrapped_key"

    local length_header=$((margin_scope + length_scope + (WIDTH_LINES + 1) + margin_func_name + length_func_name + (WIDTH_LINES + 1) + length_key + margin_header))

    # local length_applied=0
    local length_spaces=""
    result="$wrapped_header"

    [ "$length_header" -le "$LENGTH_HEADER" ] ||
    null "$contents" ||
    result="$result\\${newline}$(printf "%${LENGTH_HEADER}.0s" "")"

    null "$contents" ||
    case "$contents" in
        *$newline*|*$cr*)
            # contents="$(printf "%b" "$(printf "%s" "$contents" | magic)" | tr "\n" " ")"
            [ -n "${contents##*"\n"*}" ] ||
            # contents="$(printf "%b" "$(printf "%s" "$contents" | magic)" | tr "$cr" "${newline}")"
            contents="$(printf "%b" "$(printf "%s" "$contents")" | tr "$cr" "${newline}")"
            local index=0
            IFS_ORIGIN=$IFS
            IFS=$newline
            local item_previous=
            for item in $contents; do
                ok "$item" || continue
                [ -z "${item##*"'"*"'"*}" ] || item="'$item'"
                [ "$index" -eq "0" ] || {
                    # length_applied=$length_header
                    # length_applied="$LENGTH_HEADER"
                    # length_spaces="$(// spaces "${LENGTH_HEADER}")"
                    # pipe_read will eat up your spaces after $newline if no "IFS=" before "read -r"
                    result="$result$(printf "%$(tabstop_remainder $((LENGTH_HEADER + ${#item_previous}))).0s" "")\\${newline}$(printf "%-${LENGTH_HEADER}s" "")"
                }
                # printf "%-${WIDTH_SCOPE}s%-${WIDTH_KEY}s%s %s\n" "$scope/$func_name" '$length_applied' "$length_applied" "$item"
                result="$result$item"
                item_previous="$item"
                : $((index += 1))
            done
            IFS=$IFS_ORIGIN
            ;;
        *)
            [ -z "${contents##*"'"*"'"*}" ] || contents="'$contents'"
            result="$result$(printf "%s" "$contents")"
    esac

    # For log method 0~4
    printf '%s\n' "$result"

}

# Print key-value parameter pair with consistent format
# Local variables/contents have to be passed by parameter 3
# $1 scope  : function name
# S2 key    : variable name
# $3 value  : contents
out() {
    null "$mute" || return 0
    # For log method 5 and after
    # local log_dir_user="$1"
    local screen_pipe="$1"
    local log_pipe="$2"
    shift 2

    local result="$(see "$1" "$2" "$3" "$4")"
    # / 'local result="$(see "$1" "$2" "$3" "$4")"'
    # printf '%s\n' "local result=\"$(see "$1" "$2" "$3" "$4")\"" > /dev/null
    # / $'local result="$(printf \'%s\n\' "$(see "$1" "$2" "$3" "$4")")"'

    # For log method 5 and after

    # local as_log_dir_user="$(// delegate -- as_user "$log_dir_user")"

    # [ "$log_dir_user" == "$(whoami)" ] || // die '$(whoami) != $log_dir_user'
    # set --
    # [ "$log_dir_user" == "$(whoami)" ] ||
    # set -- $(// delegate -- as_user "$log_dir_user")

    # [ "$(stat -c '%U' "$log_pipe")" == "$log_dir_user" ] || // die '$log_pipe' "wrong user of $log_pipe"
    # ! / '$@ flock -x "$pipe_lock_screen" -c "$(printf "%s\n" "$result" > "$screen_pipe")"' ||

    # / $' ! $@ flock -x "$pipe_lock_screen" -c "$($@ printf \'%s\n\' "$result" > "$screen_pipe")" || \
    # $@ flock -x "$pipe_lock_log" -c "$($@ printf \'%s\n\' "$result" | sed \'s,\x1b\\[[0-9;]*[a-zA-Z],,g\' 2>&1 > "$log_pipe")"' & \
    #     pig_list="${pig_list:+"${pig_list} "}$!"
    / $' ! flock -x "$pipe_lock_screen" -c "$(printf \'%s\n\' "$result" > "$screen_pipe")" || \
        flock -x "$pipe_lock_log" -c "$(printf \'%s\n\' "$result" | sed \'s,\x1b\\[[0-9;]*[a-zA-Z],,g\' 2>&1 > "$log_pipe")"' & \
        pig_list="${pig_list:+"${pig_list} "}$!"

}

log() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }

    set -E
    [ "$#" -lt "3" ] || {
        local lineno="$1"
        shift 1
    }

    # Method 0
    # [ "$OUTPUT_VERSION" -ne "0" ] || {
    #     local result="$(out "$1" "$2")"
    #     # printf '%s\n' "$result" > /dev/stderr &
    #     printf '%s\n' "$result" > /dev/stderr
    #     # printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output" &
    #     printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output" &
    # }

    # https://stackoverflow.com/questions/692000/how-do-i-write-standard-error-to-a-file-while-using-tee-with-a-pipe
    # https://stackoverflow.com/questions/13804965/how-to-tee-to-stderr
    # printf '%s\n' "$result" > /dev/stderr | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 | tee -a "$log_output"
    # printf '%s\n' "$result" 3>&2 1>"$log_output" 2> >(tee -a "$log_output" >&3)

    # Method 1
    # local result="$(out "$1" "$2")"
    # printf '%s\n' "$result" | tee -a "$log_output"
    # sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_output"

    # Method 2
    # local result="$(out "$1" "$2")"
    # printf '%s\n' "$result" | tee "$log_pipe" && \
    # sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_pipe" & cat "$log_pipe" >> "$log_output" &

    # Method 3
    # local result="$(out "$1" "$2")"
    # printf '%s\n' "$result" > "$log_pipe" && cat "$log_pipe" > /dev/stderr &
    # sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_pipe" && cat "$log_pipe" >> "$log_output" &

    # Method 4
    # printf '%s\n' "$(out "$1" "$2")" > "$log_pipe" && cat "$log_pipe" > /dev/stderr
    # sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_pipe" && cat "$log_pipe" >> "$log_output" &

    # Method 5
    # local key="$1"
    # local value="$2"
    # out "$screen_pipe" "$log_pipe" "$key" "$value" &&
    # out "$log_dir_user" "$screen_pipe" "$log_pipe" "$1" "$2" &&

    # printf '%s\n' "local lineno=\"\$LINENO\""
    # printf '%s\n' "\$lineno = $lineno" > /dev/stderr
    # out "$log_dir_user" "$screen_pipe" "$log_pipe" "$1" "$2"

    # / 'out "$screen_pipe" "$log_pipe" "$1" "$2" "$3"'

    # The way to get line number transfered
    out "$screen_pipe" "$log_pipe" "$lineno_scope" "$lineno" "$1" "$2"

    # printf '%s\n' "/ $(out "$screen_pipe" "$log_pipe" "$lineno" "$1" "$2")"
    # printf '%s\n' $'out "$screen_pipe" "$log_pipe" "$lineno" "$1" "$2"'
    # out "$screen_pipe" "$log_pipe" "$lineno" "$1" "$2"

    # local as_log_dir_user="$(// delegate -- as_owner "$log_dir")"
    # set -- "$(// delegate -- as_owner "$log_dir")"
    # $@ flock -x $log_dir/.err -c "$($@ sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_pipe")" &

    # https://stackoverflow.com/questions/23665780/flock1-is-failing-to-release-lock
}

war() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    set -E
    local c1_origin="$c1"
    local c1='\033[1;43m'
    local func_name_origin="$func_name"
    local func_name="${func_name} WARNING"

    # # printf '%s\n' "log \"\$lineno\" \"$2\" \"$3\""
    # out "$screen_pipe" "$log_pipe" "$lineno_scope" "$lineno" "$1" "$2"

    local key="$1"
    local value="$2"
    # Display line number
    local result="$(see "$lineno_scope" "$lineno" "$key" "$value")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"

    local c1="$c1_origin"
    local func_name="$func_name_origin"
}

hint() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    set -E
    local c1_origin="$c1"
    local c1='\033[1;45m'
    local c2_origin="$c2"
    # local c2_origin="$c2"
    local c2='\033[1;07m'
    # local c2='\033[1;07m'
    local func_name_origin="$func_name"
    local func_name="${func_name} INITIATE"

    # / $'printf \'%s\n\' "local lineno=\"\$LINENO\""';
    # printf '%s\n' "\$lineno = $lineno" > /dev/stderr
    # printf '%s\n' "log \"\$lineno\" '$1' \"$2\""
    out "$screen_pipe" "$log_pipe" "$lineno_scope" "$lineno" "$1" "$2"

    # 7>$log_dir/.err 2>&1 |
    # 7>&- $@ flock -n $log_dir/.err -c "$($@ sed -i $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' "$log_pipe" && $@ cat "$log_pipe" >> "$log_output" &)" ||
    # { printf '%s\n' "what?"; exit 1; }

    local c2="$c2_origin"
    # local c2="$c2_origin"
    local c1="$c1_origin"
    local func_name="$func_name_origin"
}

# How to use
# // bog "$LINENO" "$log_output" '$key' "$value"
# // bog "$log_output" '$key' "$value"
bog() {
    set -E
    [ "$#" -lt "4" ] || {
        local lineno="$1"
        shift 1
    }
    [ -z "$1" ] || local log_output="$1"
    [ -f "$log_output" ] || {
        local scope="ERROR $scope"
        local c1='\033[1;41m'
        # local c2='\033[1;32m'
        # local c3='\033[m'
        # Line number comes from _env
        printf '%s\n' "$(see "$lineno_scope" "$lineno" "$log_output" "$log_output")" > /dev/stderr
        kill 0
    }
    shift 1

    local key="$1"
    local value="$2"
    # Display line number
    local result="$(see "$lineno_scope" "$lineno" "$key" "$value")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"
}

# How to use
# // die '$key' "$value"
die() {
    set -E
    local func_name_origin="$func_name"
    local func_name="${func_name} ERROR"
    local c1_origin="$c1"
    local c1='\033[1;41m'
    local c2_origin="$c2"
    local c2='\033[1;32m'
    # printf '%s\n' "local c3='\033[m'"

    local key="$1"
    local value="$2"
    local result="$(see "$lineno_scope" "$lineno" "$key" "$value")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"
    local result="$(see "$lineno_scope" "$lineno" "find log at" "$log_output")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"

    # Won't work as expected
    # printf '%s\n' "bog \"$log_output\" '$1' '$2'"
    # printf '%s\n' $'bog "$log_output" "$key" "$value"'
    # printf '%s\n' $'bog "$log_output" "find log at" "$log_output"'

    # Pause
    # read -r _
    # Without complicated "out/see"
    # printf "%b%-$((${WIDTH_SCOPE} - 1))s%b %b%-$((${WIDTH_FUNC_NAME} - 1))s%b %b%-$((${WIDTH_KEY} - 1))s%b '%s'\n" \
    #     "$c1" "$scope" "$c3" "$c1" "$func_name" "$c3" "$c2" "find log at" "$c3" "$log_output"

    # # Through pipes. The pipe_read will shut down the process at the first screen_pipe shown time
    # printf '%s\n' "out \"$screen_pipe\" \"$log_pipe\" \"\$lineno\" '$1' \"$2\""
    # # This following line will never run if the shutting down was triggered by pipe_read
    # printf '%s\n' "out \"$screen_pipe\" \"$log_pipe\" \"\$lineno\" 'find log at' \"$log_output\""

    local c2="$c2_origin"
    local c1="$c1_origin"
    local func_name="$func_name_origin"

    # Without this, printf content will not submit. "kill 0" will not do the job
    # Either use pipe_read or this following line to achive stopping the process
    # exit 1  # printf '%s\n' 'exit 1'
    # If use eval inside this function, kill 0 make function does not return, so information will not display
    kill 0    # printf '%s\n' 'kill 0'
}

# How to debug kiss
# export KISS_DEBUG=1
# env KISS_DEBUG=1 kiss p acl
# set -exf /usr/bin/kiss p acl
# https://bugzilla.redhat.com/show_bug.cgi?id=1596312
# strace -f -eexecve /usr/bin/kiss p acl 1
# sh -x /usr/bin/ldd /bin/sh
# How to use
# // debug '$key' "$value"
debug() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    # # https://www.shellscript.sh/exitcodes.html
    # # local check_debug=$(set | grep '^KISS_DEBUG=')
    # local check_debug="$(/ echo '$KISS_DEBUG')"
    # [ "$?" -eq "0" ] || {
    #     echo "Sorry, cannot find KISS_DEBUG in set"
    #     return 0
    # }

    # https://stackoverflow.com/questions/3601515/how-to-check-if-a-variable-is-set-in-bash
    # [ "${KISS_DEBUG+set}" != set ] || return 0
    [ -n "${KISS_DEBUG+x}" ] || return 0

    # Will hang up the shell on busybox 1.35.0-2
    # ( [ -n "$KISS_DEBUG" ] && printf "%s\n" "$(see "$lineno_scope" "$lineno" "$1" "$2")" 2>&1 >> "$log_output" )

    # local contents="$(printf "%b" "$(printf '%s' "$2" | magic)" | tr "\n" " ")"
    # printf "%-$((${WIDTH_SCOPE} - 1))s %-$((${WIDTH_KEY} - 1))s %s\n" "$scope" "$1" "$contents" > /dev/stderr

    set -E
    local key="$1"
    local value="$2"
    local result="$(see "$lineno_scope" "$lineno" "$key" "$value")"
    printf '%s\n' "$result" > /dev/stderr
    printf '%s\n' "$result" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"

}

# Aquire an empty file in temporary directory for writing into
# it step by step in the future
# $1 scope        : function name
# $2 src_address  : source file full path or file name
slot_aquire() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    local src_address="$(standardize "$2")"
    local src_name="${src_address##*/}"
    src_name="${src_name%\?*}"

    [ "${src_address:0:1}" != '/' ] || src_address="${src_address#/}"

    # Create a uniquely named temporary file and store its absolute path
    # in a variable (_stack_topend).
    #
    # To prevent subshell usage and to handle cases where multiple files
    # are needed, this saves the last two temporary files to variables
    # for access by the caller (allowing 3 files at once).
    # _stack_bottom="$_stack_second"
    # _stack_second="$_stack_topend"
    local _stack_topend="$tmp_dir/$pkg_name/$src_address"
    for item in $(\ls -1 "$tmp_dir/$pkg_name"); do
        [ "$item" != "$_stack_topend" ] || {
            _stack_topend=""
            break
            // die "$tmp_dir/$pkg_name/$src_address" "failed to create -- already exists"
        }
    done

    # { [ -n "$_stack_bottom" ] && [ -n "$_stack_second" ]; } \
    #     && { [ "$_stack_bottom" = "$_stack_second" ] \
    #         || [ "$_stack_bottom" = "$_stack_topend" ] \
    #         || [ "$_stack_topend" = "$_stack_second" ]; } \
    #     && {
    #     // log '$_stack_bottom' "$_stack_bottom"
    #     // log '$_stack_second' "$_stack_second"
    #     // log '$_stack_topend' "$_stack_topend"
    #     // die "$src_address" "Failed to aquire temporary file"
    # }

    null "$_stack_topend" || {
        local dir_topend="${_stack_topend%/*}"
        [ -d "$dir_topend" ] || // as_own "$tmp_dir/$pkg_name" mkdir -p "$dir_topend"

        # // as_own "$tmp_dir/$pkg_name" : > "$_stack_topend" ||
        # // die "$src_address" "failed to create the temporary file under $tmp_dir/$pkg_name"
        // as_own "$tmp_dir/$pkg_name" touch "$_stack_topend" ||
        // die "$src_address" "failed to create the temporary file under $tmp_dir/$pkg_name"
    }
    printf "\n%s" "$_stack_topend"
}

# Copy an extarnal file to temporary directory in one time
# Won't create empty file
# $1 scope        : function name
# $2 src_address  : source file full path
slot_push() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    local src_address="$2"
    local src_name="${src_address##*/}"
    src_name="${src_name%\?*}"

    # Create a uniquely named temporary file and make a duplicate of
    # the file in '$1' if it exists.
    [ ! -f "$src_address" ] || {
        // log '$src_address' "$src_address"
        local top="$(// delegate -- "slot_aquire" "$pkg_name" "$src_address")"
        null "$top" || // as_own "$top" cp -f "$src_address" "$top"
    }
    // log '$top' "$top"
    printf "\n%s" "$top"
}

prompt() {
    _env
    null "$1" || // log '$1' "$1"

    // log "Continue?" "Press Enter to continue or Ctrl+C to abort"

    # korn-shell does not exit on interrupt of read.
    equ "$KISS_PROMPT" 0 || read -r _ || // die 'error' 'read input'
}

mkcd() {
    _env

    ok "$1" || // die "Trying to create an empty directory"

    local target="$1"
    for item in "$@"; do
        item="$(standardize "$item")"
        // debug '$item' "$item"
        local parent_dir="${item%/*}"
        // debug '$parent_dir' "$parent_dir"
        local index=0
        [ -z "${parent_dir:+x}" ] ||
        # Have not been created yet
        while [ ! -d "$parent_dir" ] && [ "$index" -lt "10" ]; do [ -z "${parent_dir:+x}" ] || parent_dir="${parent_dir%/*}"; : $((index += 1)); done
        [ -n "${parent_dir:+x}" ] ||
            // die 'mkdir -p $item' 'Trying to modify system root /'
        [ "$parent_dir" != "$KISS_ROOT" ] ||
            // die 'mkdir -p $item' 'Trying to modify $KISS_ROOT/'
        // debug '$parent_dir' "$parent_dir"
        // debug '$item' "$item"
        // as_own "$parent_dir" mkdir -p "$item" || // die 'mkdir' "$item"
    done
    cd "$target"
    // log '$PWD' "$PWD"
}

# decode right to left
# $1 src_string : body
# $2 substitute : output
# $3 sub_string : input
# replace "$repo_source" "REPO_MAIN" "$REPO_MAIN" "REPO_ROOT" "$REPO_ROOT"
#                ^             ^        |             ^        |
#                |             |________|             |________|
#                |_________________|______________________|
replace() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    // debug '$@' "$(esceval "$@")"
    [ "$#" -ge "3" ] || // die '$#' "$#"

    # Replace all occurrences of substrings with substrings. This
    # function takes pairs of arguments iterating two at a time
    # until everything has been replaced.
    local result_value="$1"
    // debug '$result_value' "$result_value [input]"
    shift 1

    while :; do case $result_value-$# in
        *"$2"*)
            result_value=${result_value%"$2"*}${1}${result_value##*"$2"}
            // debug '$result_value' "$result_value"
            ;;
        *-2) break ;;
        *)
            shift 2
            // debug '$#' "$#"
            // debug '$sub_string' "$2 [input]"
            // debug '$substitute' "$1 [output]"
    esac done
    // debug '$result_value' "$result_value [output]"
    printf "\n%s" "$result_value"
}

# encode right to left
# encode "$repo_source" "REPO_MAIN" "$REPO_MAIN" "REPO_ROOT" "$REPO_ROOT"
#               ^             ^        |             ^        |
#               |             |________|             |________|
#               |_________________|______________________|
encode() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    // debug '$@' "$(esceval "$@")"
    [ "$#" -ge "3" ] || // die '$#' "$#"
    local str="$1"
    shift 1

    local key=
    local value=
    local args=

    for index in $(seq 1 2 $#); do
        local key="$(/ "printf '%s' \"\${$index}\"")"
        [ -n "$key" ] || key=\"\"
        local value="$(/ "printf '%s' \"\${$((index + 1))}\"")"
        [ -n "$value" ] || value=\"\"
        args="$args \x03 $key $key $value \\$key \x03"
        # If you have an array, and step in 2 elements at a time
        # set -f -- "$@" "\ " "$key" "$key" "$value" "\\$key" "\ "
    done
    // debug '$args' "$args"
    printf "\n%s" "$(delegate -- replace "$str" $args)"
}

# Surround each replacement with substitutions to handled escaped markers.
# First substitution turns '\MARKER' into ' ' (can't appear in sources as
# they're already split on whitespace),
# second replaces 'MARKER' with its value
# and the third, turns ' ' into 'MARKER' (dropping \\).
# decode "${src_url%"${src_url##*[!/]}"}" \
#         "\ " "\\PACKAGE" "$pkg_name" "PACKAGE" "PACKAGE" "\ "

# decode right to left
# decode "$repo_source" "$REPO_MAIN" "REPO_MAIN" "$REPO_ROOT" "REPO_ROOT"
#               ^             ^        |             ^        |
#               |             |________|             |________|
#               |_________________|______________________|
decode() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    // debug '$@' "$(esceval "$@")"
    [ "$#" -ge "3" ] || // die '$#' "$#"
    local str="$1"
    shift 1

    local value=
    local key=
    local args=

    # will be treated as $1+0
    # // debug '$10' "$10"
    # // debug '${10}' "${10}"
    for index in $(seq 1 2 $#); do
        # // log '$index' "$index"
        local value="$(/ "printf '%s' \"\${$index}\"")"
        [ -n "$value" ] || value=\"\"
        // debug '$value' "$value"
        # // log "\$$((index+1))" "$(// echo \${$((index+1))})"
        local key="$(/ "printf '%s' \"\${$((index + 1))}\"")"
        [ -n "$key" ] || key=\"\"
        // debug '$key' "$key"
        args="$args \x03 \\$key $value $key $key \x03"
        # If you have an array, and step in 2 elements at a time
        # set -f -- "$@" "\ " "\\$key" "$value" "$key" "$key" "\ "
    done
    // debug '$args' "$args"
    printf "\n%s" "$(delegate -- replace "$str" $args)"
}

# $1 path
am_owner() {
    _env
    local path="$1"
    # local user_key=$2
    # local group_key=$3

    // debug "$FUNCNAME in" "$scope"

    # Figure out if we need to change users to operate on
    # a given file or directory.

    local real_path="$(readlink -f "$path")" || // die 'readlink abnormal' "$real_path"
    [ -d "${real_path}" ] || // die "does not exist" "$real_path"
    // debug '$real_path' "$real_path"

    # local inf="$(\ls -ld "$real_path")" ||
    #     // die 'Failed to file information for'"'$1'"

    # // debug '$inf' "$inf"
    # # Split the ls output into fields.
    # read -r _ _ user _ < <(printf "$inf\n") > /dev/null ||
    #     // die 'printf $inf' "failed"

    local user=$(stat -c '%U' "${real_path}")
    // debug '$user' "$user"

    # [ -z "$user_key" ] || / "$user_key=$user"
    # // log '$user_key' "$user_key"
    # // log '$(/ echo \$$user_key)' "$(/ echo \$$user_key)"

    local group=$(stat -c '%G' "${real_path}")
    // debug '$group' "$group"

    # [ -z "$group_key" ] || / "$group_key=$group"
    # // log '$group_key' "$group_key"
    # // log '$(/ echo \$$group_key)' "$(/ echo \$$group_key)"

    # loginame="$(whoami)"
    # equ "$loginame/$user" "$user/$loginame"

    printf '%s\3%s\n' "$user" "$group"
}

# For directly putting into command
as() {
    _env

    // debug "$FUNCNAME in" "$scope"

    ! equ "$1" "--" || shift 1
    local user_name="$1"
    [ "$#" -ge "1" ] || // die '$user_name' "$user_name"
    shift 1

    // debug "using '${cmd_su##*/}'" "to become $user_name"

    case ${cmd_su##*/} in
        su) $cmd_su -c $* <&3 $user_name 3<&0 </dev/tty ;;
         *) $cmd_su -u $user_name -- $@
    esac
}

# For directly putting into command
as_own() {
    _env

    // debug "$FUNCNAME in" "$scope"

    ! equ "$1" "--" || shift 1
    local path="$1"
    [ "$#" -ge "1" ] || // die '$user_name' "$user_name"
    shift 1

    local real_path="$(readlink -f "$path")" || // die "readlink abnormal" "$real_path"
    [ -d "${real_path}" ] || [ -f "${real_path}" ] || // die "does not exist" "$real_path"

    local user_name="$(stat -c '%U' "$real_path")"

    // debug "using '${cmd_su##*/}'" "to become $user_name"

    case ${cmd_su##*/} in
        su) $cmd_su -c $* <&3 $user_name 3<&0 </dev/tty ;;
         *) $cmd_su -u $user_name -- $@
    esac
}

# For repeatedly positional arguments using
# $1 user_name
as_user() {
    _env

    // debug "$FUNCNAME in" "$scope"

    ! equ "$1" "--" || shift 1
    local user_name="$1"
    [ "$#" -ge "1" ] || // die '$#' "$#"
    [ -n "$user_name" ] || // die '$user_name' "$user_name"
    shift 1

    // debug "using '${cmd_su##*/}'" "to become $user_name"

    case ${cmd_su##*/} in
        su) # / "$as_user_name=\"$cmd_su -c $* <&3 $user_name 3<&0 </dev/tty\"" ;;
            printf '\n%s' "$cmd_su -c $* <&3 $user_name 3<&0 </dev/tty" ;;
        *)  # / "$as_user_name=\"$cmd_su -u $user_name -- $@\""
            printf '\n%s' "$cmd_su -u $user_name -- $@"
    esac
}

# For repeatedly positional arguments using
as_owner() {
    _env

    // debug "$FUNCNAME in" "$scope"

    ! equ "$1" "--" || shift 1

    local path="$1"
    [ "$#" -ge "1" ] || // die '$user_name' "$user_name"
    shift 1

    local real_path="$(readlink -f "$path")" || // die "readlink abnormal" "$real_path"
    [ -d "${real_path}" ] || [ -f "${real_path}" ] || // die "does not exist" "$real_path"

    local user_name="$(stat -c '%U' "$real_path")"

    // debug "using '${cmd_su##*/}'" "to become $user_name"

    case ${cmd_su##*/} in
        su) # / "$as_user_name=\"$cmd_su -c $* <&3 $user_name 3<&0 </dev/tty\"" ;;
            printf '%s' "$cmd_su -c $* <&3 $user_name 3<&0 </dev/tty" ;;
        *)  # / "$as_user_name=\"$cmd_su -u $user_name -- $@\""
            printf '%s' "$cmd_su -u $user_name -- $@"
    esac
}

# $1 parameter
# $2 library
# $3 manifest list
pkg_owner() {
    _env

    // debug "$FUNCNAME in" "$scope"

    ok "$2" || { set +f; set -f -- "$1" "$sys_db"/*/manifest; }

    _owns=$(grep -lxF "$@")
    _owns=${_owns%/*}
    _owns=${_owns##*/}

    ok "$_owns"
}

resolve_path() {
    _env
    _rpath=$KISS_ROOT/${1#/}
    local _parent
    # Attempt to resolve symlinks by using 'cd'.
    # If this fails, fallback to the file's parent
    # directory.
    if cd -P "${_rpath%/*}" 2>/dev/null; then
        _parent=$PWD
        cd "$OLDPWD"
    else
        _parent=${_rpath%/*}
    fi

    _rpath=${_parent#"$KISS_ROOT"}/${_rpath##*/}
}

run_hook() {
    _env
    local command="$1"
    # Run all hooks in KISS_HOOK (a colon separated
    # list of absolute file paths).
    IFS_ORIGIN=$IFS
    IFS=:

    for hook in ${KISS_HOOK:-}; do case $hook in *?*)
        "$hook" "$@" || // die "$command" "hook failed: '$hook'"
    esac done

    IFS=$IFS_ORIGIN
}

# $1 command
# $2 pkg_name
run_hook_pkg() {
    _env
    local command="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    local repo_target="$sys_db/$pkg_name"
    # Run a hook from the package's database files.
    if [ -x "$repo_target/$command" ]; then
        // log "$pkg_name" "running $command hook"
        "$repo_target/$command"

    elif [ -f "$repo_target/$command" ]; then
        // war "$pkg_name" "skipping $command hook: not executable"
    fi
}

# $1 tar_file : tar file
decompress() {
    _env
    local tar_file="$1"

    if ok "$tar_file"; then
        // log '$tar_file' "$tar_file [local]"
    else
        // die '$tar_file' "${tar_file:+"${tar_file} "}has not yet built [local]"
    fi

    case $tar_file in
        *.tbz|*.bz2) bzip2 -d ;;
        *.lzma)      lzma -dc ;;
        *.lz)        lzip -dc ;;
        *.tar)       cat      ;;
        *.tgz|*.gz)  gzip -d  ;;
        *.xz|*.txz)  xz -dcT0 ;;
        *.zst)       zstd -dc ;;
    esac < "$tar_file"
}

sh256() {
    _env
    # Higher level sh256 function which filters out non-existent
    # files (and also directories).
    for f do shift
        [ -d "$f" ] || [ ! -e "$f" ] || set -- "$@" "$f"
    done

    local hash="$(// _sh256 $@)" || // die '_sh256' "$hash"
    printf '\n%s' "$hash"
}

_sh256() {
    _env

    # There's no standard utility to generate sha256 checksums.
    # This is a simple wrapper around sha256sum, sha256, shasum,
    # openssl, digest, ... which will use whatever is available.
    #
    # All utilities must match 'sha256sum' output.
    #
    # Example: '<checksum>  <file>'
    local hash

    # Skip generation if no arguments.
    ! equ "$#" 0 || return 0

    # Set the arguments based on found sha256 utility.
    case ${cmd_sha##*/} in
        openssl) set -- dgst -sha256 -r "$@" ;;
         sha256) set -- -r "$@" ;;
         shasum) set -- -a 256 "$@" ;;
         digest) set -- -a sha256 "$@" ;;
    esac

    IFS_ORIGIN=$IFS
    IFS=$newline

    # Generate checksums for all input files. This is a single
    # call to the utility rather than one per file.
    local sha_list="$("$cmd_sha" "$@")" || // die "Failed to generate checksums"

    # Strip the filename from each element.
    # '<checksum> ?<file>' -> '<checksum>'
    for sum in $sha_list; do
        hash=$hash${hash:+"${IFS}"}${sum%% *}
    done

    printf '\n%s' "$hash"
    IFS=$IFS_ORIGIN
}

# Package version of selected $KISS_PATH
# $1 pkg_name
# $2
# $3 -d / -x
# $4 $KISS_PATH / $sys_db / $PATH
pkg_version() {
    _env
    local repo_url="$1"
    local pkg_name
    local list="$2"
    local shell_flag="$3"
    local search_dir="$4"
    ok "$search_dir" || search_dir="$KISS_PATH"

    IFS=$'\x03' read -r pkg_name _ repo_path \
        < <(// repo_resolve "$repo_url" "$search_dir") > /dev/null || // die 'repo_resolve' "failed"
    // debug '$pkg_name' "$pkg_name"
    // debug '$repo_path' "$repo_path"

    [ -d "$repo_path" ] || // die '$repo_path' "No such package ($repo_path)"

    IFS=$' ' read -r repo_ver repo_rel 2>/dev/null < "$repo_path/version" ||
        // die "$pkg_name" "failed to read $repo_path/version"

    # local format="$(// delegate -- pkg_format "$repo_path")"
    null "${repo_path##*"${sys_db}"*}" ||
    ! is_in_main "$repo_path" || {
        ok "${repo_ver##*"v"*}" &&
        ok "${repo_ver##*"-"*}" &&
        # Just enter for history reason. So don't need to consider real git repos
        # [ "git" != "$format" ] &&
        [ "git" != "$repo_ver" ] || {
            is_in_main "$repo_path" || // die 'is_in_main' "did wrong thing"
            IFS=$'\x03' read -r repo_ver repo_rel < <(// delegate -- latest_tag "$repo_path") 2>/dev/null ||
            // die 'latest_tag' "failed"
            ok "$repo_ver" && ok "$repo_rel" ||
            IFS=$'\x03' read -r repo_ver repo_rel < <(// delegate -- latest_tag "$repo_path") 2>/dev/null ||
            // die 'latest_tag' "failed"
            local as_version_ower=
            [ "$(whoami)" == "$(stat -c '%U' "$repo_path/version")" ] || as_version_ower="$(// delegate -- as_owner "$repo_path/version")"
            // log '$as_version_ower' "$as_version_ower"
            $as_version_ower sh -c "/usr/bin/printf '%s %s\n' \"$repo_ver\" \"$repo_rel\" > \"$repo_path/version\"" ||
            // die 'permission denied' "on writting version to file $repo_path/version"
            IFS=$' ' read -r ver rel 2>/dev/null < "$repo_path/version" ||
            // die "$pkg_name" "failed to read $repo_path/version"
            [ "$repo_ver" == "$ver" ] && [ "$repo_rel" == "$rel" ] || die 'version update' "failed"
            // density_output "$pkg_name" "$repo_path" "$repo_path" "0"
        }
    }

    ok "$repo_rel" ||
        // die "$pkg_name" "uelease field not found in version file"


    # This belongs somewhere else, for now it can live here.
    [ -x "$repo_path/build" ] ||
        // die "$pkg_name" "build file not found or not executable"

    // debug '$repo_ver' "$repo_ver"
    // debug '$repo_rel' "$repo_rel"

    printf '\n%s\3%s\3%s' \
        "$repo_path" "$repo_ver" "$repo_rel"

}

# Package version of $sys_db
version_installed() {
    _env
    local repo_url
    if ok "$1"; then repo_url="$1"; else repo_url="kiss"; fi
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ \
        < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"

    IFS=$'\3' read -r _ ver rel \
        < <(// delegate -- pkg_version "$pkg_name" "" "" "$sys_db") > /dev/null ||
        // die 'pkg_version' "failed"
    // log '$ver-$rel' "$ver-$rel"
}

# Package version details of selected $KISS_PATH
# $1 repo_url : package repo url/uri
# $2
# $3 -d / -x
# $4 $KISS_PATH / $sys_db / $PATH
version_split() {
    _env
    local repo_url="$1"
    local pkg_name
    local list="$2"
    local shell_flag="$3"
    local search_dir="$4"
    ok "$search_dir" || search_dir="$KISS_PATH"

    IFS=$'\x03' read -r pkg_name _ repo_path \
        < <(// repo_resolve "$repo_url" "$search_dir") > /dev/null || // die 'repo_resolve' "failed"
    // debug '$pkg_name' "$pkg_name"

    # https://stackoverflow.com/questions/2488715/idioms-for-returning-multiple-values-in-shell-scripting
    IFS=$'\3' read -r _ repo_ver repo_rel \
        < <(// delegate -- pkg_version "$pkg_name" "$list" "$shell_flag" "$search_dir") > /dev/null ||
        // die 'pkg_version' "failed"
    ok "$repo_ver" || // die '$repo_ver' "$repo_ver"
    ok "$repo_rel" || // die '$repo_rel' "$repo_rel"
    // debug '$repo_ver' "$repo_ver"

    # Split the version on '.+-_' to obtain individual components.
    IFS=.+-_ read -r repo_major repo_minor repo_patch repo_ident \
        < <(printf "$repo_ver\n") > /dev/null || // die "printf '$repo_ver'" "failed"

    // debug '$repo_path' "$repo_path"
    // debug '$repo_major' "$repo_major"
    // debug '$repo_minor' "$repo_minor"
    // debug '$repo_patch' "$repo_patch"
    # [ -n ${repo_ident} ] || repo_ident="0"
    // debug '$repo_ident' "$repo_ident"

    printf '%s\3%s\3%s\3%s\3%s\3%s\3%s\n' \
        "$repo_path" "$repo_ver" "$repo_rel" "$repo_major" "$repo_minor" "$repo_patch" "$repo_ident"

}

density_output() {
    _env
    [ "$#" -ge "4" ] || // die '$#' "wrong parameters gave $#"
    local pkg_name="$1"
    local repo_path="$2"
    local repo_source="$3"
    local repo_ver
    local repo_rel
    local index="$4"
    local format="$(// delegate -- pkg_format "$repo_path")"

    IFS=$' ' read -r repo_ver repo_rel 2>/dev/null < "$repo_path/version" ||
        // die "$pkg_name" "failed to read $repo_path/version"

    local scope_origin="$scope"
    local func_name_origin="$func_name"
    length_trim "repo_ver" "$((2 * TABSTOP))"
    length_trim "repo_rel" "$TABSTOP"
    local route=
    local c1_origin="$c1"
    local c2_origin="$c2"
    c2="$c1"
    [ -n "${repo_path##*$sys_db*}" ] || { route="<x>"; c1='\033[1;45m'; c2='\033[1;07m'; }
    [ "$repo_source" != "$repo_path" ] || { route=">o<"; c1='\033[1;45m'; c2='\033[1;07m'; }
    scope="$pkg_name"
    local length_index=$((${#index} + 1))
    local margin_index=$((TABSTOP - length_index))
    [ "$margin_index" -ge "0" ] || margin_index=$(tabstop_remainder $length_index)
    // debug '$margin_index' "$margin_index"
    # func_name="$(printf "%-${LENGTH_VER}s %-${TABSTOP}d" "$pkg_name" "$index")"
    func_name="$(printf "%-${TABSTOP}s %-${margin_index}s%s" "$format" "" "$index")"
    // log "$(printf "%-$((2 * TABSTOP))s %-${MARGIN_ROUTE}s%-${TABSTOP}s" "$repo_ver" "" "$repo_rel")" "${route:+"${route} "}$repo_path"
    c2="$c2_origin"
    c1="$c1_origin"
    func_name="$func_name_origin"
    scope="$scope_origin"
}

valid_tail() {
    local target_file="$1"
    local tail_deep
    [ ! -s "$target_file" ] || {
        tail_deep=1
        local lines="$(wc -l "$target_file" | cut -f 1 -d ' ')"
        while [ -z "$(tail -n $tail_deep "$target_file")" ] && [ "$tail_deep" -le "$lines" ]; do
            : $((tail_deep += 1))
        done
    }
    printf '\n%s' "$tail_deep"
}

# Query package from $REPO_ROOT without being limited by $KISS_PATH
# and install it from the query index (optional)
# $1 repo_url : package repo url/uri
# $2 index: selected one
pick_up() {
    _env
    action_of_session="pick"
    local index=0

    local repo_url
    local pkg_name
    local repo_list
    local index_pick_up=

    if ok "$1"; then
        repo_url="${1}"
        IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        // log '$pkg_name' "$pkg_name"
        repo_list="$(as_own "$REPO_ROOT" find "$REPO_ROOT" \( -type d -o -type l \) -name "${pkg_name}")"
        null "$2" || index_pick_up="${2}"
    else
        repo_url="${PWD##*/}"
        IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        repo_list="${PWD}"
        index_pick_up="$index"
    fi

    local repo_selected=
    local repo_source
    local repo_target="$sys_db/$pkg_name"

    local tail_deep="$(// delegate -- valid_tail "$repo_target/keys")"
    [ -z "${tail_deep:+x}" ] || {
        IFS=$' ' read -r _ _ repo_source < <(tail -n $tail_deep "$repo_target/keys") \
            > /dev/null || // die "tail -n $tail_deep \"$repo_target/keys\"" "failed"
        repo_source="$(delegate -- decode "$repo_source" "$REPO_MAIN" "REPO_MAIN")"
    }
    // log '$repo_source' "$repo_source"

    local route
    local c2_origin="$c2"
    // debug '$LENGTH_VER' "$LENGTH_VER"
    // debug '$MARGIN_ROUTE' "$MARGIN_ROUTE"

    [ -n "${repo_list:+x}" ] || {
        c2="$c1"
        // log "$pkg_name" "NONE"
        c2="$c2_origin"
        return 0
    }

    for repo in $repo_list
    do
        [ -d "$repo" ] && [ -f "$repo/version" ] || continue

        // density_output "$pkg_name" "$repo" "$repo_source" "$index"

        null "$index_pick_up" || [ "$index" != "$index_pick_up" ] ||
            repo_selected="$repo"

        : $((index += 1))
    done

    ok "$repo_selected" || return 0

    [ -n "${kiss_root_user:+x}" ] ||
    IFS=$'\3' read -r  kiss_root_user _ \
        < <(// am_owner "$KISS_ROOT/") > /dev/null || // die 'am_owner' "failed"
    // log "Perfroming selection"

    // density_output "$pkg_name" "$repo_selected" "$repo_source" "$index_pick_up"

    # local repo_dir="${repo_selected%/*}"
    local pkg_selected="${repo_selected##*/}"

    # // log '$repo_dir' "$repo_dir"
    // log '$pkg_selected' "$pkg_selected"

    // pkg_dirs "$action_of_session" "$pkg_selected"

    # export REPO_DIR=$repo_dir

    { // hint 'checksum' "$repo_selected"
        action="checksum"; ! // checksum  "$repo_selected" 2>&1 > /dev/stderr; } ||
    { // hint 'build_all' "$repo_selected"
        action="build"; ! // build_all "$repo_selected" 2>&1 > /dev/stderr; } || {
        // hint 'pkg_install' "$repo_selected"
        if ! equ "$(whoami)" "$kiss_root_user"; then
            // log '$repo_selected' "$repo_selected"
            // subshell_all "install" "$repo_selected"
        else
            // log '$repo_selected' "$repo_selected"
            action="install"; // pkg_install "$repo_selected" 2>&1 > /dev/stderr
        fi
    }
}

# Figure out which repository a package belongs to (repo_path)
# or print applications in $PATH (app_path)
# $1 repo_url
# $2 list option: "all" for repositories, "pure" for no $sys_db, and "" for the 1st repository
# $3 shell flag: -d / -x
# $4 $KISS_PATH / $sys_db / $PATH. Don't have pkg_name
pkg_find() {
    _env
    // debug '$repo_url' "$repo_url [global]"
    // debug '$4' "$4"
    # Figure out which repository a package belongs to by searching for
    # directories matching the package name in $KISS_PATH/*.
    set -- "$1" "$2" "$3" "${4:-"$KISS_PATH"}"

    local repo_url="$1"
    local list="$2"
    ok "$list" || repo_url="$(standardize "$repo_url")" # repo_url=${repo_url%%\*}
    // debug '$repo_url' "$repo_url [local]"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    // debug '$pkg_name' "$pkg_name [local]"
    local test_key="$3"
    local search_paths="$4"
    [ "pure" == "$list" ] || search_paths="${search_paths:+"${search_paths}:"}$sys_db"
    local repo_path=

    // debug '$#' "$#"

    // debug '$sys_db' "$sys_db"

    IFS_ORIGIN=$LFS
    IFS=$':'
    # Iterate over KISS_PATH, grabbing all directories which match the query.
    # Intentional.
    # shellcheck disable=2086
    // debug '$search_paths' "$search_paths"
    for _found_path in $search_paths; do
        // debug '$repo_url' "$repo_url"
        // debug '$pkg_name' "$pkg_name"
        null "$_found_path" || {
            _found_path="$(standardize "$_found_path")"
            // debug '$_found_path' "$_found_path"
        }
        # Expansion will mistake folder name for an implied package name
        set +f
        if null "$list"; then
            // debug '$list' "$list"
            local _found_pkg="$_found_path/$pkg_name"
            // debug '$_found_pkg' "$_found_pkg"
            // debug '$#' "$#"
            // debug '${test_key:--d}' "${test_key:--d}"
            ! test "${test_key:--d}" "$_found_pkg" || {
                set -f -- "$@" "$_found_pkg"
                break
            }
            // debug '$#' "$#"
        else    # ok "$list"
            // debug '$list' "$list"
            IFS=$newline
            for _found_pkg in $(\ls -1 "$_found_path" 2>/dev/null | grep "$(standardize "$pkg_name")"); do
                // debug '$_found_path' "$_found_path"
                // debug '$_found_pkg' "$_found_pkg"
                _found_pkg="$_found_path/$_found_pkg"
                _found_pkg="$(standardize "$_found_pkg")"
                ! test "${test_key:--x}" "$_found_pkg" || {
                    set -f -- "$@" "$_found_pkg"
                }
            done
            IFS=$':'
        fi
    done
    IFS=$IFS_ORIGIN

    // debug 'search done'
    // debug '$list-$#' "$list-$#"

    # Figure out which repository a package belongs to by searching for
    # Show all search results if called from 'kiss search', else store the
    # values in variables. If there are 4 arguments, no package has been found.
    case $list-$# in
        *-4) ;;
        -*) # null "$list"
            repo_path="$(standardize "$5")"
            // debug '$repo_path' "$repo_path"
            ;;
        *)  # ok "$list"
            shift 4;
            for item in "$@"; do
                repo_path="${repo_path:+"${repo_path} "}$item"
            done
            // debug '$applications' "$repo_path"
    esac

    // debug '$repo_path' "$repo_path"

    printf '\n%s' "$repo_path"
}

list_version() {
    _env
    // log '$#' "$#"
    local repo_url="${1:-"${PWD##*/}"}"
    // log '$repo_url' "$repo_url"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path \
        < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    // log '$pkg_name' "$pkg_name"
    # List installed packages. As the format is files and directories, this
    # just involves a simple for loop and file read.

    // log '$sys_db' "$sys_db"

    # Optional arguments can be passed to check for specific packages. If no
    # arguments are passed, list all.
    if null "$repo_url"; then
        set +f; set -f -- "$sys_db"/*
    else
        set -- "$pkg_name"
    fi
    # Loop over each package and print its name and version.
    for pkg_name do
        // log '$pkg_name' "$pkg_name"
        # // debug '${pkg_name##*/}' "${pkg_name##*/}"
        IFS=$'\3' read -r _ repo_ver repo_rel \
            < <(// delegate -- pkg_version "${pkg_name}" "" "" "$sys_db") \
            > /dev/null || // die 'pkg_version' "failed"
        // log "${pkg_name}" "$repo_ver-$repo_rel"
    done
}

# Should be subshell function
# How to use:
# local tar_file="$(delegate -- pkg_cache "$pkg_name")"
# $1 repo_url : package repo url/uri
pkg_cache() {
    _env
    local arguments="$@"
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    null "$2" || // debug '$2' "$2"
    // log '$bin_dir' "$bin_dir"

    # Find the tarball of a package using a glob. Use the user's set compression
    # method if found or first match of the below glob.

    IFS=$'\3' read -r _ repo_ver repo_rel \
        < <(// delegate -- pkg_version "$pkg_name") > /dev/null || // die 'pkg_version' "failed"

    // log '$repo_ver' "$repo_ver"
    // log '$repo_rel' "$repo_rel"
    set -- $arguments
    set +f -- "${bin_dir}/${pkg_name}/${1}@${repo_ver}-${repo_rel}.tar."
    set -f -- "${1}$KISS_COMPRESS" "${1}"*

    local tar_file=""

    // log '$1' "$1"
    // log '$2' "$2"

    # If the first match does not exist, use the second. If neither exist,
    # this function returns 1 and the caller handles the error.
    if [ -f "$1" ]; then
        tar_file="$1"
    elif [ -f "$2" ]; then
        tar_file="$2"
    else
        // war '$tar_file' "for $pkg_name needs build"
    fi

    // debug '$1' "$1"
    // debug '$2' "$2"
    // debug '$tar_file' "$tar_file"

    printf "\n%s" "$tar_file"
}

# Given a line of input from the sources file with parameters (src_url)
# and designated target folder name (dest), translate parameters and return
# an absolute path to the source (_des_dir) if it already exists, error if not.
# Input
# $1 repo_url  : package repo url/uri
# $2 src_url   : source link (in sources file)
# $3 dest      : destination / source folder name (in sources file)
# $4 action
# How to use
# IFS=$'\3' read -r _res _des_dir \
#     < <(// source_route "$pkg_name" "$src_url" "$dest" "$action") > /dev/null ||
#         // die 'source_route' "failed"
# Output
# _res      : source url
# _des_dir  : target file location, directory destination
source_route() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
    local src_url="$2"
    local dest="$3"
    local action="$4"
    local _res _des_dir real_url

    ok "${2%%\#*}" || {
        printf "%s\3%s\n" "" ""
        return 0
    }

    # IFS=$'\3' read -r repo_path repo_ver repo_rel \
    #     < <(// delegate -- pkg_version "$pkg_name") > /dev/null || // die 'pkg_version' "failed"
    # IFS=$'\3' read -r _ repo_ver repo_rel \
    #     repo_major repo_minor repo_patch repo_ident \
    #     < <(// version_split "$pkg_name") > /dev/null || // die 'version_split' "failed"
    # ok "$repo_path" || // die '$repo_path' "$repo_path"

    # // debug '$repo_major' "$repo_major"
    # // debug '$repo_minor' "$repo_minor"
    # // debug '$repo_patch' "$repo_patch"
    # // debug '$repo_ident' "$repo_ident"
    # // debug '$pkg_name' "$pkg_name"

    : "${ARCH:="${KISS_XHOST_ARCH}"}"
    # [ -n "${ARCH:+x}" ] || // die '$ARCH' "${ARCH:+"${ARCH} "}must be defined"
    // log '$ARCH' "$ARCH"

    local real_url="$(delegate -- decode \
        "${src_url%"${src_url##*[!/]}"}" \
        "$REPO_MAIN"  "REPO_MAIN" \
        "$ARCH"       "ARCH"      \
        "$repo_ver"   "VERSION"   \
        "$repo_rel"   "RELEASE"   \
        "$repo_major" "MAJOR"     \
        "$repo_minor" "MINOR"     \
        "$repo_patch" "PATCH"     \
        "$repo_ident" "IDENT"     \
        "$pkg_name"   "PACKAGE")"

    // log '$real_url/uri' "$real_url"

    set -- "$pkg_name" "$real_url" "${3%"${3##*[!/]}"}" "$4"

    pkg_name="$1"
    src_url="$2"
    dest="$3"
    action="$4"

    local src_name="${src_url##*/}"
    src_name="${src_name%\?*}"

    # local src_current="${src_name%%-"$repo_ver"*}"
    # src_current="${src_current%%"$repo_ver"*}"
    # src_current="${src_current%%[@\#]*}"
    # [ -n "$src_current" ] || {
    #     src_current="$pkg_name"
    # }
    # local _des_name=$src_current
    # case $src_url in
    #     git+*)
    #         ;;

    #     *.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z)
    #         // log '$dest' "$dest"
    #         # // mkcd "$make_dir/$pkg_name/${_des_dir##*/}"
    #         local head=${src_name%.t??*}
    #         local tail=${src_name##$head}
    #         src_current=$src_current-$repo_ver$tail
    #         ;;

    #     *?*)
    #         ;;
    # esac
    # // log '$src_current' "$src_current"

    # Git repository.
    if null "${src_url##git+*}"; then
        _res=$src_url
        # _des_dir=$src_dir/$pkg_name/${dest:-"$src_name"}
        # _des_dir=${_des_dir%[@#]*}/.
        _des_dir=$src_dir/$pkg_name/${dest:+"$dest/"}.

    # How to judge the content under src's subfolder is valid?
    # # Remote source dir (cached).
    # elif [ -d "$src_dir/$pkg_name/${dest:+"$dest/"}$src_current" ]; then
    #     _res=$src_dir/$pkg_name/${dest:+"$dest/"}$src_current
    #     _des_dir=$src_dir/$pkg_name/${dest:+"$dest/"}$src_current

    # Remote source files (cached).
    elif [ -f "$archive_path/$pkg_name/${dest:+"$dest/"}$src_name" ]; then
        _res=$archive_path/$pkg_name/${dest:+"$dest/"}$src_name
        _des_dir=$src_dir/$pkg_name/${dest:+"$dest/"}.

    # Remote source archive/files.
    elif null "${src_url##*://*}"; then
        _res=url+$src_url
        _des_dir=$archive_path/$pkg_name/${dest:+"$dest/"}.

    # Local relative dir.
    elif [ -d "$repo_path/$src_url" ]; then
        _res=$repo_path/$src_url/.
        _des_dir=$_res

    # Local absolute dir.
    elif [ -d "/${src_url##/}" ]; then
        _res=/${src_url##/}/.
        _des_dir=$_res

    # Local relative file (/repo_path/files/filename).
    elif [ -f "$repo_path/$src_url" ]; then
        _res=$repo_path/$src_url
        _des_dir="${_res%/*}/."

    # Local absolute file (/files/filename).
    elif [ -f "/${src_url##/}" ]; then
        _res=/${src_url##/}
        _des_dir="${_res%/*}/."

    else
        // die "$pkg_name" "No local file '$src_url'"
    fi

    ok "$action" || // log '$_res' "$_res"

    // log '$_des_dir' "$_des_dir"
    // log '$action' "$action"

    printf "%s\3%s\3%s\n" "$_res" "$_des_dir" "$real_url"
}

# Download any remote package sources. The existence of local files is
# also checked.
# $1 repo_url  : package repo url/uri
# $2 action    : action name
pkg_download() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local action="$2"

    // log '$pkg_name' "$pkg_name"
    // log '$action' "$action"

    # IFS=$'\3' read -r repo_path repo_ver repo_rel repo_major repo_minor repo_patch repo_ident \
    #     < <(// version_split "$pkg_name") > /dev/null || // die 'version_split' "failed"

    # // debug '$repo_path' "$repo_path"
    # // debug '$repo_major' "$repo_major"
    # // debug '$repo_minor' "$repo_minor"
    # // debug '$repo_patch' "$repo_patch"
    # // debug '$repo_ident' "$repo_ident"

    # Support packages without sources. Simply do nothing.
    [ -f "$repo_path/sources" ] || return 0

    // log "$pkg_name" "reading sources"

    while read -r src_url dest || ok "${src_url%%\#*}"; do
        ok "${src_url%%\#*}" || continue
        // log '$src_url' "$src_url"
        // log '$dest' "$dest"
        IFS=$'\3' read -r _res _des_dir real_url \
            < <(// source_route "$pkg_name" "$src_url" "$dest" "$action") > /dev/null ||
            // die "source_route" "failed"
        // log '$_res' "$_res"
        // log '$_des_dir' "$_des_dir"

        # arg1: pre-source
        # arg2: package name
        # arg3: verbatim source
        # arg4: resolved source
        // run_hook pre-source "$pkg_name" "$src_url" "$real_url"

        # '$2' is set when this function is called from 'kiss c' and it is used
        # here to skip calling the Git code.
        local _res_purified="${_res##"${_res%%+*}+"}"
        // log '$_res_purified' "$_res_purified"
        // log '${_res%%+*}' "${_res%%+*}"

        { [ -n "${KISS_FORCE:+x}" ] && [ "git" == "${_res%%+*}" ]; } ||
        case ${action}$_res in "${action}url+"*|"git+"*)
            // log "download_${_res%%+*}" "beginning"
            # For download_url and download_git
            / // "download_${_res%%+*}" "$pkg_name" "$_des_dir" "$_res_purified"
        esac

        # arg1: post-source
        # arg2: package name
        # arg3: verbatim source
        # arg4: resolved source
        // run_hook post-source "$pkg_name" "$src_url" "${_des_dir:-"$_res"}"
    done < "$repo_path/sources"
}

download_url() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    shift 1
    local _des_dir="$1"
    local _res_purified="$2"
    local src_name="${_res_purified##*/}"
    src_name="${src_name%\?*}"

    [ "${_des_dir##*/}" != "." ] || _des_dir="${_des_dir%/*}"
    // log '$_des_dir' "$_des_dir"
    // mkcd "$_des_dir"

    // log "$pkg_name" "$_res_purified"
    // log '${cmd_get##*/}' "${cmd_get##*/}"
    # Set the arguments based on found download utility.
    case ${cmd_get##*/} in
        aria2c|axel) set -- -o   "$_des_dir/$src_name" "$_res_purified" ;;
               curl) set -- -fLo "$_des_dir/$src_name" "$_res_purified" ;;
         wget|wget2) set -- -O   "$_des_dir/$src_name" "$_res_purified" ;;
    esac

    # Opening output file $_des_dir/$src_name
    # Error opening local file
    # /usr/bin/kiss: line 1198: -o: not found
    local as_archive_user=
    IFS=$'\3' read -r archive_dir_user _  \
        < <(// am_owner "$archive_path/$pkg_name") > /dev/null ||
        // die 'am_owner' "failed"
    equ "$(whoami)" "$archive_dir_user" ||
    // as_archive_user="$(delegate -- as_user "$archive_dir_user")"

    // log '$LOGNAME' "$LOGNAME"
    // log '$as_archive_user' "$as_archive_user"

    $as_archive_user "$cmd_get" "$@" || {
        $as_archive_user rm -f "$_des_dir/$src_name"
        // die "$pkg_name" "Failed to download $_res_purified"
    }
}

latest_tag() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    // log '$pkg_name' "$pkg_name"
    // log '$repo_path' "$repo_path"
    shift 1
    local force_fetch
    if [ "$#" -ge "1" ]; then
        force_fetch="$1"
        shift 1
    else
        force_fetch=
    fi
    local _des_dir
    local _res_purified
    if [ "$#" -ge "2" ]; then
        local _des_dir="$1"
        local _res_purified="$2"
    else
        while read -r src_url dest || ok "${src_url%%\#*}"; do
            ok "${src_url%%\#*}" || continue

            null "${src_url##*"${pkg_name%%-*}"*}" || continue

            // log '$src_url' "$src_url"
            // log '$dest' "$dest"

            IFS=$'\3' read -r _res _des_dir real_url \
                < <(// source_route "$pkg_name" "$src_url" "$dest" "$action") > /dev/null ||
            // die "source_route" "failed"

            // log '$_res' "$_res"
            // log '$_des_dir' "$_des_dir"

            # '$2' is set when this function is called from 'kiss c' and it is used
            # here to skip calling the Git code.
            _res_purified="${_res##"${_res%%+*}+"}"
            // log '$_res_purified' "$_res_purified"
            break
        done < "$repo_path/sources"
    fi

    ok "$_des_dir" || // die '$_des_dir' "can not figure out \$_des_dir of \"$pkg_name\""

    // log '$src_dir' "$src_dir"
    // log '$src_user' "$src_user"

    set --
    equ "$(whoami)" "$src_user" ||
    set -- "$(// delegate -- as_user "$src_user")"

    // log '$_des_dir' "$_des_dir"
    # "$src_dir/$pkg_name/${dest:+"$dest/"}."

    # Remove "/."
    [ "${_des_dir##*/}" != "." ] || _des_dir="${_des_dir%/*}"
    // log '$_des_dir' "$_des_dir"

    // mkcd "$_des_dir"


    url="${_res_purified%[\#@]*}"
    # url="${url%.git}.git"

    // log '$url' "${url}"
    // log '$PWD' "$PWD"

    local target=

    # [ "$($@ git -C "$_des_dir" rev-parse --is-inside-work-tree 2>/dev/null)" = "true" ] || {
    #     $@ find "$_des_dir" -mindepth 1 -delete
    #     $@ git clone --recursive --depth 1 "${url}" "$_des_dir" ||
    #     $@ git clone --branch $target "${url}" "$_des_dir" 2>/dev/null ||
    #     // die "git clone --recursive --depth 1 \"${url}\" \"$_des_dir\"" "failed"
    # }
    # null "$force_fetch" || $@ git fetch --tags --prune

    # target="$($@ git describe --tags $($@ git rev-list --tags --max-count=1))"

    IFS=$'\x03' read -r upstream_type target \
        < <(// delegate -- determine_type "$upstream_name" "$_des_dir" "$url" "$force_fetch") \
        > /dev/null || // die 'determine_type' "failed"

    local rel=1

    local ver="$(// delegate -- synchronize "$upstream_name" "$_des_dir" "$url" "$upstream_type" "$target")"

    // log '$ver' "$ver"

    ok "${ver##*"v"*}" || ver="${ver##*"v"}"
    ok "${ver##*"-"*}" || {
        ver="${ver%%-*}"
        rel="${ver##*-}"
    }
    // log '$ver' "$ver"
    // log '$rel' "$rel"
    printf "\n%s\3%s" "$ver" "$rel"
}

determine_type() {
    _env
    local upstream_name="$1"
    local _des_dir="$2"
    local url="$3"
    shift 3
    local force_fetch
    if [ "$#" -ge "1" ]; then
        force_fetch="$1"
        shift 1
    else
        force_fetch=
    fi
    local upstream_type=
    local target=

    set --
    equ "$(whoami)" "$src_user" ||
        set -- "$(// delegate -- as_user "$src_user")"

    [ "$PWD" == "$_des_dir" ] || // cd "$_des_dir"

    [ -z "${USE_TAG:+X}" ] || upstream_type="tag"
    [ -z "${upstream_name:+x}" ] ||
    for item in $($@ git ls-remote ${url} --tags origin "refs/tags/*${upstream_name}*" | awk '{print $2}'); do
        [ -z "${item##*"${upstream_name}"*}" ] || continue
        target="${item##"refs/tags/"}"
        break
    done
    [ -n "$target" ] || {

        [ "$($@ git -C "$_des_dir" rev-parse --is-inside-work-tree 2>/dev/null)" == "true" ] || {
            $@ find "$_des_dir" -mindepth 1 -delete
            $@ git clone --recursive --depth 1 "${url}" "$_des_dir" ||
            $@ git clone --branch $target "${url}" "$_des_dir" 2>/dev/null ||
            // die "git clone --recursive --depth 1 \"${url}\" \"$_des_dir\"" "failed"
        }
        # Time consuming operation
        # $@ git fetch --all --tags --prune
        null "$force_fetch" || $@ git fetch --tags --prune
        # https://stackoverflow.com/questions/21439488/find-latest-git-tag-from-the-remote-git-repository
        # Leaving ^0 at the end of tags
        # target="$($@ git rev-list --tags --timestamp --no-walk | sort -nr | head -n1 | cut -f 2 -d ' ' | xargs $@ git describe --contains)"
        # https://stackoverflow.com/questions/1404796/how-can-i-get-the-latest-tag-name-in-current-branch-in-git
        null "$($@ git tag)" ||
        target="$($@ git describe --tags $($@ git rev-list --tags --max-count=1))" ||
        war 'woops' "not a tag type repo"
    }

    [ -n "$target" ] ||
    # // die "branch/tag '$upstream_name' doesn't exist" "Specify a valid branch/tag name, please"
    for item in $($@ git ls-remote ${url} --heads origin "refs/heads/*" | awk '{print $2}'); do
        { [ -n "${upstream_name:+x}" ] && [ -z "${item##*"${upstream_name}"*}" ]; } ||
        [ -z "${item##*"master"*}" ] || [ -z "${item##*"main"*}" ] ||
        continue
        target="${item##"refs/heads/"}"
        break
    done

    [ -z "$target" ] || upstream_type="branch"
    [ -n "$target" ] ||
    // die "branch/tag '$upstream_name' doesn't exist" "Specify a valid branch/tag name, please"
    printf '\n%s\3%s' "$upstream_type" "$target"
}

synchronize() {
    _env
    local _des_dir="$1"
    local url="$2"
    local upstream_name="$3"
    local upstream_type="$4"
    local target="$5"
    shift 5
    local force_fetch
    if [ "$#" -ge "1" ]; then
        force_fetch="$1"
        shift 1
    else
        force_fetch=
    fi
    local ver_data

    set --
    equ "$(whoami)" "$src_user" ||
        set -- "$(// delegate -- as_user "$src_user")"

    [ "$PWD" == "$_des_dir" ] || // cd "$_des_dir"

    if [ "$upstream_type" == "branch" ]; then
        null "$force_fetch" || {
            # [ -z "$target" ] ||
            $@ git remote set-branches origin $target ||
            // die "git remote set-branches origin $target" "failed"

            // log 'fetch' "${url}"
            $@ git fetch --depth 1 "${url}" $target 2>/dev/null ||
            $@ git fetch "${url}" $target ||
            // die "git fetch --depth 1 \"${url}\" $target" "failed"
            # generate branch "$terget" in .git/config
            $@ git fetch --depth 1 origin $target

            local target_ref=$($@ git branch | grep -v remotes | grep \* | awk '{print $2}')
            # fatal: a branch named 'master' already exists when "$target" = "$target_ref"
            [ "$target" == "$target_ref" ] || {
                [ "$($@ git branch | grep -v remotes | grep "$target" | awk '{print $1}')" == "$target" ] ||
                # fatal: a branch named 'master' already exists
                $@ git branch $target FETCH_HEAD 2>/dev/null ||
                # fatal: 'origin/aster' is not a commit and a branch 'master' cannot be created from it
                $@ git checkout -b $target --track origin/$target 2>/dev/null ||
                // die "git checkout -b $target --track origin/$target" "failed"

                $@ git switch $target 2>/dev/null || $@ git switch -c $target ||    # Already on 'master'
                // die "git switch $target" "failed"

                target_ref=$($@ git branch | grep -v remotes | grep \* | awk '{print $2}')
                [ "$target_ref" = "$target" ] || // die " \"$target_ref\" = \"$target\" " "failed"
            }

            // log '$target_ref' "$target_ref"

            $@ git branch --set-upstream-to=origin/$target $target
            # fatal: the requested upstream branch 'origin/master' does not exist
            $@ git reset --hard origin/$target > /dev/null ||
            // die "git reset --hard origin/$target" "failed"
        } > /dev/stderr
        ver_data="$(printf "%s\n" "$($@ git rev-parse --short 'HEAD@{upstream}' 2>/dev/null)")"

    else
        null "$force_fetch" || {
            local targets=$($@ git tag)
            contains "$targets" "$target" ||
            # $@ git fetch --all --tags
            $@ git fetch --depth 1 "${url}" tag $target --no-tags 2>/dev/null ||
            $@ git fetch --depth 1 "${url}" refs/tags/$target:refs/tags/$target 2>/dev/null ||
            $@ git fetch "${url}" tag $target --no-tags ||
            // die "git fetch \"${url}\" tag $target --no-tags" "failed"

            local target_ref=$($@ git branch | grep -v remotes | grep \* | awk '{print $2}')
            [ -z "${target_ref##*${target}*}" ] || {
                [ "$($@ git branch | grep -v remotes | grep "$target" | awk '{print $1}')" == "$target" ] ||
                $@ git checkout tags/$target -b $target --force ||
                // die "git checkout tags/$target -b $target" "failed"

                $@ git switch $target 2>/dev/null || $@ git switch -c $target ||    # Already on 'master'
                // die "git switch $target" "failed"

                target_ref=$($@ git branch | grep -v remotes | grep \* | awk '{print $2}')
                [ "$target_ref" == "$target" ] || // die " \"$target_ref\" = \"$target\" " "failed"
            }

            // log '$target_ref' "$target_ref"

            $@ git reset --hard tags/$target > /dev/null || // die "git reset --hard tags/$target" "failed"
        } > /dev/stderr
        ver_data="$target"
    fi
    ok "$ver_data" || // die '$ver_data' "${ver_data:+"${ver_data} "}got wrong value"
    // log '$ver_data' "$ver_data"
    printf "\n%s" "$ver_data"
}

download_git() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    shift 1
    local _des_dir="$1"
    local _res_purified="$2"

    // log '$src_dir' "$src_dir"
    // log '$src_user' "$src_user"

    set --
    equ "$(whoami)" "$src_user" ||
        set -- "$(// delegate -- as_user "$src_user")"

    // log '$_des_dir' "$_des_dir"
    # "$src_dir/$pkg_name/${dest:+"$dest/"}."

    # Remove "/."
    [ "${_des_dir##*/}" != "." ] || _des_dir="${_des_dir%/*}"
    // log '$_des_dir' "$_des_dir"

    // mkcd "$_des_dir"

    # Might be empty
    local upstream_name=
    [ -n "${_res_purified##*[@\#]*}" ] || upstream_name="${_res_purified##*[@\#]}"

    local url="${_res_purified%[\#@]*}"
    url="$(standardize "$url")"
    null "${url##*".git"*}" || url="${url}.git" # url="${url%.git}.git"

    // log '$upstream_name' "$upstream_name"
    // log '$url' "${url}"
    // log '$PWD' "$PWD"

    local upstream_type=
    local target=

    IFS=$'\x03' read -r upstream_type target \
        < <(// delegate -- determine_type "$upstream_name" "$_des_dir" "$url" "$force_fetch") \
        > /dev/null || // die 'determine_type' "failed"

    // log '$target' "$target"
    // log '$upstream_type' "$upstream_type"
    local ver
    local ver rel=1

    if [ "$($@ git -C "$_des_dir" rev-parse --is-inside-work-tree 2>/dev/null)" = "true" ]; then

        local remote_url=$($@ git -C "$_des_dir" remote -v | grep fetch | grep origin | awk '{print $2}')
        # [ "$remote_url" == "$url" ] || {
        #     $@ git remote remove origin
        #     $@ git remote add origin "${url}"
        # }

        [ "$remote_url" == "$url" ] ||
        $@ git remote set-url origin "${url}" 2>/dev/null ||
        $@ git remote add origin "${url}" ||
        // die "git remote set-url origin \"${url}\"" "failed"

        ver="$(// delegate -- synchronize "$upstream_name" "$_des_dir" "$url" "$upstream_type" "$target" "1")"

        $@ git rev-parse --short HEAD || // war 'git rev-parse --short HEAD' "failed"
        $@ git describe --always || // war 'git describe --always' "failed"

        $@ git submodule deinit --all -f
        $@ git submodule init
        $@ git submodule sync
        $@ git submodule update --init --remote --recursive --force
    else
        $@ find "$_des_dir" -mindepth 1 -delete
        # https://github.blog/2020-12-21-get-up-to-speed-with-partial-clone-and-shallow-clone/
        $@ git clone --recursive --depth 1 --single-branch --branch $target "${url}" "$_des_dir" 2>/dev/null ||
        # $@ git clone --recursive --depth 1 --single-branch --branch $target "${url}" "$_des_dir" 2>/dev/null ||
        # $@ git clone --recursive --filter=tree:0 --branch $target "${url}" "$_des_dir" 2>/dev/null ||
        # $@ git clone --recursive --filter=blob:none --branch $target "${url}" "$_des_dir" 2>/dev/null ||
        $@ git clone --branch $target "${url}" "$_des_dir" 2>/dev/null ||
            // die "git clone --recursive --depth 1 --branch $target \"${url}\" \"$_des_dir\"" "failed"

        if [ "$upstream_type" == "branch" ]; then
            # ver="$(delegate -- $@ git rev-parse --short 'HEAD@{upstream}' 2>/dev/null)"
            ver="$(printf "%s\n" "$($@ git rev-parse --short 'HEAD@{upstream}' 2>/dev/null)")"
        else
            ver="$target"
        fi
    fi
    ok "$ver" || // die '$ver' "${ver:+"${ver} "}got wrong value"
    // log '$ver' "$ver"

    ok "${ver##*"v"*}" || ver="${ver##*"v"}"
    ok "${ver##*"-"*}" || {
        ver="${ver%%-*}"
        rel="${ver##*-}"
    }

    ok "${repo_path##*"${sys_db}"*}" &&
    ! is_in_main "$repo_path" || {
        local as_version_ower=
        [ "$(whoami)" == "$(stat -c '%U' "$repo_path/version")" ] || as_version_ower="$(// delegate -- as_owner "$repo_path/version")"
        // log '$as_version_ower' "$as_version_ower"
        $as_version_ower sh -c "/usr/bin/printf '%s %s\n' \"$ver\" \"$rel\" > \"$repo_path/version\"" ||
        // die 'permission denied' "on writting version to file $repo_path/version"
        IFS=$' ' read -r repo_ver repo_rel 2>/dev/null < "$repo_path/version" ||
        // die "$pkg_name" "failed to read $repo_path/version"
        [ "$repo_ver" == "$ver" ] && [ "$repo_rel" == "$rel" ] || die 'version update' "failed"
        // density_output "$pkg_name" "$repo_path" "$repo_path" "0"
    }
}

# $1 repo_url : package repo url/uri
# $2 $_des_dir
# $3 $_res
# working under "${_des_dir%/*}"
extract_tar() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    shift 1
    local _des_dir="$1"
    local _res="$2"

    [ -n "${_des_dir:+x}" ] || // die '$_des_dir' "$_des_dir"

    [ "${_des_dir##*/}" != "." ] || _des_dir="${_des_dir%/*}"
    // mkcd "$_des_dir"

    // log '$0' "$0"
    // log '$_res' "$_res"
    // log '$pkg_name' "$pkg_name"

    # This is a portable shell implementation of GNU tar's
    # '--strip-components 1'. Use of this function denotes a
    # performance penalty.
    local tarball="$(// delegate -- "slot_aquire" "$pkg_name" "$_des_dir/tarball")"
    // log '$tarball' "$tarball"
    local tarball_manifest="$(// delegate -- "slot_aquire" "$pkg_name" "$_des_dir/tarball-manifest")"
    // log '$tarball_manifest' "$tarball_manifest"

    // decompress "$_res" > "$tarball" || {
        \rm -f "$_res"
        // die "$pkg_name" "Failed to decompress $_res and deleted."
    }

    tar xf "$tarball" ||
        // die "$pkg_name" "Failed to extract $_res"

    # The sort command filters out all duplicate top-level
    # directories from the tarball's manifest. This is an optimization
    # as we avoid looping (4000 times for Python(!)).
    tar tf "$tarball" | sort -ut / -k1,1 > "$tarball_manifest" ||
        // die "$pkg_name" "Failed to extract manifest"

    # Iterate over all directories in the first level of the
    # tarball's manifest. Each directory is moved up a level.
    while IFS=/ read -r dir _; do case ${dir#.} in *?*)
        # Skip entries which aren't directories.
        [ -d "$dir" ] || continue

        # Move the parent directory to prevent naming conflicts
        # with the to-be-moved children.
        mv -f "$dir" "$KISS_PID-$dir"

        # Move all children up a directory level. If the mv command
        # fails, fallback to copying the remainder of the files.
        #
        # We can't use '-exec {} +' with any arguments between
        # the '{}' and '+' as this is not POSIX. We must also
        # use '$0' and '$@' to reference all arguments.
        find "$KISS_PID-$dir/." ! -name . -prune \
            -exec sh -c 'mv -f "$0" "$@" .' {} + 2>/dev/null ||

        find "$KISS_PID-$dir/." ! -name . -prune \
            -exec sh -c 'cp -fRp "$0" "$@" .' {} +

        # Remove the directory now that all files have been
        # transferred out of it. This can't be a simple 'rmdir'
        # as we may leave files in here if any were copied.
        rm -rf "$KISS_PID-$dir"
    esac done < "$tarball_manifest"

    # Remove the tarball now that we are done with it.
    rm -f "$tarball"
}

# $1 repo_url : package repo url/uri
dump_to_make() {
    _env
    local repo_path="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # Extract all source archives to the build directory and copy over any
    # local repository files.
    #
    # NOTE: repo_path comes from caller.
    // log "$pkg_name" "extracting sources"

    # arg1: pre-extract
    # arg2: package name
    # arg3: path to DESTDIR
    // run_hook pre-extract "$pkg_name" "$pkg_dir/$pkg_name"

    while read -r src_url dest || ok "${src_url%%\#*}"; do
        IFS=$'\3' read -r _res _des_dir _ \
            < <(// source_route "$pkg_name" "$src_url" "$dest") > /dev/null ||
            // die "source_route" "failed"

        [ "${_des_dir##*/}" != "." ] || _des_dir="${_des_dir%/*}"

        # Create the source's directories if not null.
        ok "$_res" || continue
        local destination="$make_dir/$pkg_name/$dest"
        // log '$_res [extract]' "$_res"

        case $_res in
            git+*)
                // mkcd "$destination"
                { ls -1LA "$_des_dir" 2>/dev/null | grep -q .; } ||
                // die '$_des_dir' "empty directory $_des_dir"
                rsync -aqz "$_des_dir/." .
                sync
                // log '$_des_dir [git]' "$_des_dir"
            ;;

            *.tar|*.tar.??|*.tar.???|*.tar.????|*.t?z)
                // extract_tar "$pkg_name" "$_des_dir" "$_res"
                // mkcd "$destination"
                { ls -1LA "$_des_dir" 2>/dev/null | grep -q .; } ||
                // die '$_des_dir' "empty directory $_des_dir"
                rsync -aqz "$_des_dir/." .
                sync
                // log '$_des_dir [extract]' "$_des_dir"
            ;;

            *?*)
                // mkcd "$destination"
                { ls -1LA "$_res" 2>/dev/null | grep -q .; } ||
                // die '$_res' "empty directory $_res"
                cp -LRf "$_res" .
                // log '$_des_dir [copy]' "$_des_dir"
            ;;
        esac
        sync
        { ls -1LA "$destination" 2>/dev/null | grep -q .; } ||
        // die '$destination' "empty directory $destination"
    done < "$repo_path/sources" || // die "$pkg_name" "Failed to extract $_res"
}

# $1 repo_url   : package repo url/uri
# $2 policy     : raw/expl | policies
# $3 filter     : filter switch
# $4 appended   : dependencies appended
# $5 dep_stage  : dependent type/stage [build time / runtime]
pkg_depends() {
    _env
    local makedeps="$1"
    shift 1
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local policy="$2"
    local filter="$3"
    local appended="$4"
    local dep_stage="$5"

    // log '$pkg_name' "$pkg_name"
    // log '$policy' "$policy"
    // log '$filter' "$filter"
    // log '$appended' "$appended"
    // log '$dep_stage' "$dep_stage"

    // log '$deps' "$deps"
    // log '$explicit' "$explicit"
    local repo_target="$sys_db/$pkg_name"
    // log '$repo_target' "$repo_target"

    # Resolve all dependencies and generate an ordered list. The deepest
    # dependencies are listed first and then the parents in reverse order.
    ! contains "$deps" "$pkg_name" || return 0

    # Filter out non-explicit, already installed packages.
    null "$filter" || ok "$policy" || contains "$explicit" "$pkg_name" ||
        [ ! -d "$repo_target" ] || return 0

    # Detect circular dependencies and bail out.
    # Looks for multiple repeating patterns of (dep dep_parent) (5 is max).
    case " $appended " in
*" ${appended##* } "*" ${pkg_name} "\
*" ${appended##* } "*" ${pkg_name} "\
*" ${appended##* } "*" ${pkg_name} "\
*" ${appended##* } "*" ${pkg_name} "\
*" ${appended##* } "*" ${pkg_name} "*)
        // die "$pkg_name <> ${4##* }" "circular dependency detected"
    esac

    local repo_path="$repo_target"
    [ -d "$repo_target" ] ||
        // repo_path="$(delegate -- "pkg_find" "$pkg_name")"

    ok "$repo_path" || // die "$pkg_name" 'is not yet installed'

    // log '$repo_path' "$repo_path"
    // log '$KISS_ROOT' "$KISS_ROOT"
    // log '$4' "$4"
    // log '$appended' "$appended"

    # Packages which exist and have depends.
    // null "$(delegate -- "pkg_find" "$pkg_name")" ||
    [ ! -e "$repo_path/depends" ] ||
    # Recurse through the dependencies of the child packages.
    while read -r dep dep_type || ok "$dep"; do
        // log '$dep' "$dep"
        // log '$dep_type' "$dep_type"

        null ${dep##*/*} ||
        contains "$appended" "$pkg_name" || {
            null "${dep##\#*}" || [ -n ${KISS_ROOT:+x} ] ||
                // pkg_depends "makedeps" "$dep" '' "$filter" "$4 $pkg_name" "$dep_type"
            [ -z ${KISS_ROOT:+x} ] || ok "$dep_type" ||
                // pkg_depends "makedeps" "$dep" '' "$filter" "$4 $pkg_name" "$dep_type"
            [ -z ${KISS_ROOT:+x} ] || null "$dep_type" ||
                // make_depends "makedeps" "$dep" '' "$filter" "$4 $pkg_name" "$dep_type"
        }
    done < "$repo_path/depends" || :

    # Add parent to dependencies list.
    // equ "$policy" expl && { ! equ "$dep_stage" make || ok "$(delegate -- "pkg_cache" "$pkg_name")"; } ||
        deps="${deps:+"${deps} "}$pkg_name"

    for item in $deps; do
        // log '$deps' "$item"
    done
}

make_depends() {
    _env
    local makedeps_name="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    / "local makedeps_value=\$$makedeps_name"
    # Only add to list once
    ! contains "$makedeps_value" "$pkg_name" || return 0

    # Filter already installed packages on build machine.
    [ ! -d "$REPO_ROOT/installed/$pkg_name" ] || return 0

    # Add to the list
    makedeps_value="${makedeps_value:+"${makedeps_value} "}$pkg_name"
    / "$makedeps_name=$makedeps_value"
}

# "$@" : all packages
pkg_order() {
    _env
    # Order a list of packages based on dependence and take into account
    # pre-built tarballs if this is to be called from 'kiss i'.
    local order redro deps

    for pkg_name do case $pkg_name in
      /*@*.tar.*) deps="$deps $pkg_name" ;;
       *@*.tar.*) deps="$deps $ppwd/$pkg_name" ;;
             */*)
                 // die 'Not a package' "$pkg_name"
                 ;;
               *) // pkg_depends "makedeps" "$pkg_name" raw
    esac done

    for item in $deps; do
        // debug '$deps' "$item"
    done

    local order=
    local redro=
    # Filter the list, only keeping explicit packages. The purpose of these
    # two loops is to order the argument list based on dependence.
    for pkg_name in $deps; do case " $* " in *" $pkg_name "*|*" ${pkg_name##"$ppwd/"} "*)
        order="${order:+"${order} "}$pkg_name"
        redro="$pkg_name${redro:+" ${redro}"}"
    esac done

    // log '$order' "'$order'"
    // log '$redro' "'$redro'"

    unset deps

    printf "%s\3%s\n" "$order" "$redro"
}

pkg_strip() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # Strip package binaries and libraries. This saves space on the system as
    # well as on the tarballs we ship for installation.
    [ -f "$make_dir/$pkg_name/nostrip" ] || equ "$KISS_STRIP" 0 && return

    // log "$1" "Stripping binaries and libraries"

    # Strip only files matching the below ELF types. This uses 'od' to print
    # the first 18 bytes of the file. This is the location of the ELF header
    # (up to the ELF type) and contains the type information we need.
    #
    # Static libraries (.a) are in reality AR archives which contain ELF
    # objects. We simply read from the same 18 bytes and assume that the AR
    # header equates to an archive containing objects (.o).
    #
    # Example ELF output ('003' is ELF type):
    # 0000000 177   E   L   F 002 001 001  \0  \0  \0  \0  \0  \0  \0  \0  \0
    # 0000020 003  \0
    # 0000022
    #
    # Example AR output (.a):
    # 0000000   !   <   a   r   c   h   >  \n   /
    # 0000020
    # 0000022
    while read -r file; do [ -h "$pkg_dir/$pkg_name$file" ] || case $file in
        # Look only in these locations for files of interest (libraries,
        # programs, etc). This includes all subdirectories. Old behavior
        # would run od on all files (upwards of 4000 for Python).
        */sbin/?*[!/]|*/bin/?*[!/]|*/lib/?*[!/]|\
        */lib??/?*[!/]|*/lib???/?*[!/]|*/lib????/?*[!/])

        case $(od -A o -t c -N 18 "$pkg_dir/$pkg_name$file") in
            # REL (object files (.o), static libraries (.a)).
            *177*E*L*F*0000020\ 001\ *|*\!*\<*a*r*c*h*\>*)
                // run strip -g -R .comment -R .note "$pkg_dir/$pkg_name$file"
            ;;

            # EXEC (binaries), DYN (shared libraries).
            # Shared libraries keep global symbols in a separate ELF section
            # called '.dynsym'. '--strip-all/-s' does not touch the dynamic
            # symbol entries which makes this safe to do.
            *177*E*L*F*0000020\ 00[23]\ *)
                // run strip -s -R .comment -R .note "$pkg_dir/$pkg_name$file"
            ;;
        esac
    esac done < "$pkg_dir/$pkg_name/$db/$1/manifest" || :
}

# could be subshell function before local version
# $1 repo_url : package repo url/uri
pkg_fix_deps() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # Dynamically look for missing runtime dependencies by checking each
    # binary and library with 'ldd'. This catches any extra libraries and or
    # dependencies pulled in by the package's build suite.
    // log "$pkg_name" "looking for dependencies (using ${cmd_elf##*/})"

    // log '$PWD' "$PWD"
    # "$pkg_dir/$pkg_name/$db/$pkg_name"
    // log '$sys_db' "$sys_db"
    // log '$pkg_name' "$pkg_name"

    set +f
    set -f -- "$sys_db/"*/manifest

    unset _fdep_seen

    # False positive (not a write).
    # shellcheck disable=2094
    while read -r _file; do [ -h "$_file" ] || case $_file in
        # Look only in these locations for files of interest (libraries,
        # programs, etc). This includes all subdirectories. Old behavior
        # would run ldd on all files (upwards of 4000 for Python).
        */sbin/?*[!/]|*/bin/?*[!/]|*/lib/?*[!/]|\
        */lib??/?*[!/]|*/lib???/?*[!/]|*/lib????/?*[!/])

        // debug '$_file' "$_file"
        # [ "${_file:0:1}" == '/' ] || _file="${_file:1}"

        # The readelf mode requires ldd's output to resolve the library
        # path for a given file. If ldd fails, silently skip the file.
        local ldd="$(ldd -- "$pkg_dir/$pkg_name$_file" 2>/dev/null)" || continue

        # Attempt to get information from readelf. If this fails (or we
        # are in ldd mode), do full ldd mode (which has the downside of
        # listing dependencies of dependencies (and so on)).
        local elf="$("$cmd_elf" -d "$pkg_dir/$pkg_name$_file" 2>/dev/null)" || elf=$ldd

        # Iterate over the output of readelf or ldd, extract file names,
        # resolve their paths and finally, figure out their owner.
        while read -r lib; do case $lib in *NEEDED*\[*\]|*'=>'*)
            # readelf: 0x0000 (NEEDED) Shared library: [libjson-c.so.5]
            lib=${lib##*\[}
            lib=${lib%%\]*}

            # Resolve library path.
            # ldd: libjson-c.so.5 => /lib/libjson-c.so.5 ...
            case $cmd_elf in
                *readelf) lib=${ldd#*"	$lib => "} ;;
                *)        lib=${lib##*=> } ;;
            esac
            lib=${lib%% *}

            # Skip files owned by libc, libc++ and POSIX.
            case ${lib##*/} in
                ld-*           |\
                lib[cm].so*    |\
                libc++.so*     |\
                libc++abi.so*  |\
                libcrypt.so*   |\
                libdl.so*      |\
                libgcc_s.so*   |\
                libmvec.so*    |\
                libpthread.so* |\
                libresolv.so*  |\
                librt.so*      |\
                libstdc++.so*  |\
                libtrace.so*   |\
                libunwind.so*  |\
                libutil.so*    |\
                libxnet.so*    |\
                ldd)
                    continue
            esac

            # Skip files we have seen before.
            case " $_fdep_seen " in
                *" $lib "*) continue ;;
                *) _fdep_seen="$_fdep_seen $lib"
            esac

            // resolve_path "$lib"

            # Skip file if owned by current package
            ! // pkg_owner -e "$_rpath" manifest || continue

            ! // pkg_owner -e "$_rpath" "$@" || // log '$_owns' "$_owns"

        esac done < <([ "$?" -eq 0 ] || :; printf "%s\n" "$elf") > /dev/null ||
        // die 'printf "%s\n" "$elf"' "failed"
    esac done < manifest |

    [ ! -s "depends" ] || {
        local depends_list="$(cat depends)"
        for item in $depends_list; do
            // log "to fix" "$item"
        done
        local depends_clone="$(// delegate -- "slot_push" "$pkg_name" "depends")"
        // log '$depends pushed' "$depends"

        local depends_fixed="$(// delegate -- "slot_aquire" "$pkg_name" "depends-fixed")"
        // log '$depends_fixed' "$depends_fixed [pushed]"

        # Sort the depends file (including the existing depends file) and
        # remove any duplicate entries. This can't take into account comments
        # so they remain rather than being replaced.
        sort -u -k 1,1 "$depends_clone" /dev/stdout > "$depends_fixed"

        # If the depends file was modified, show a diff and replace it.
        [ ! -s "$depends_fixed" ] || {
            diff -U 3 "$depends_clone" "$depends_fixed" 2>/dev/null || :

            // log 'to be $depends_fixed' "$depends_fixed"
            # Replace the existing depends file if one exists, otherwise this
            # just moves the file to its final resting place.
            \mv -f "$depends_fixed" depends
            local depends_list="$(cat depends)"
            for item in $depends_list; do
                // log 'Fixed $item' "$item"
            done
            # Generate a new manifest as we may be the creator of the depends
            # file. This could otherwise be implemented by inserting a line
            # at the correct place in the existing manifest.
            // pkg_manifest "${PWD##*/}" "$pkg_dir/$pkg_name"
        }
    }
}

# could be subshell function before local version
# $1 repo_url                               : package repo url/uri
# $2 pkg_dir/$pkg_name / tar_dir/$pkg_name  : package directory / extracting directory
pkg_manifest() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local dir_operating="$2"
    # Generate the package's manifest file. This is a list of each file
    # and directory inside the package. The file is used when uninstalling
    # packages, checking for package conflicts and for general debugging.
    // log "$pkg_name" "generating manifest"
    // log '$dir_operating' "$dir_operating"
    // log '$db' "$db"

    local manifest="$(// delegate -- "slot_aquire" "$pkg_name" "manifest")"

    # Create a list of all files and directories. Append '/' to the end of
    # directories so they can be easily filtered out later. Also filter out
    # all libtool .la files and charset.alias.
    {
        printf '%s\n' "$dir_operating/$db/$pkg_name/manifest"

        ! [ -d "$dir_operating/etc" ] ||
        printf '%s\n' "$dir_operating/$db/$pkg_name/etcsums"

        find "$dir_operating" ! -path "$dir_operating" -type d -exec printf '%s/\n' {} + \
            -o \( ! -type d -a ! -name \*.la -a ! -name charset.alias \) -print

        # Sort the output in reverse. Directories appear after their contents.
    } | sort -ur > "$manifest"

    // / as "$src_user" /usr/bin/touch "$dir_operating/$db/$pkg_name/manifest"
    # Remove the prefix from each line.
    while read -r file; do
        printf '%s\n' "${file#"$dir_operating"}"
    done < "$manifest" > "$dir_operating/$db/$pkg_name/manifest"
}

# $1 $pkg_name
manifest_validate() {
    _env
    # NOTE: pkg_name comes from caller.
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    // log "$pkg_name" "checking if manifest valid"

    // log '$tar_dir/$pkg_name' "$tar_dir/$pkg_name"
    // log 'manifest file' "$db/$pkg_name/manifest"

    shift 1

    local tar_man="$tar_dir/$pkg_name/$db/$pkg_name/manifest"
    while read -r line; do
        [ -e "$tar_dir/$pkg_name$line" ] || [ -h "$tar_dir/$pkg_name$line" ] || {
            // log '$line' "$line"
            set -- "$@" "$line"
        }
    done < "$tar_man"

    for f do
        // log '$f' "$f"
        // die "$pkg_name" "manifest contains $# non-existent files"
    done
}

manifest_replace() {
    _env
    # Replace the matching line in the manifest with the desired replacement.
    # This used to be a 'sed' call which turned out to be a little
    # error-prone in some cases. This new method is a tad slower but ensures
    # we never wipe the file due to a command error.
    local manifest_replace_buffer="$(// delegate -- "slot_aquire" "$pkg_name" "manifest-replace-${2##*/}")"

    while read -r line; do
        ! equ "$line" "$2" || line=$3

        printf '%s\n' "$line"
    done < "$sys_db/$1/manifest" | sort -r > "$manifest_replace_buffer"

    mv -f "$manifest_replace_buffer" "$sys_db/$1/manifest"
}

# $@ :
pkg_etcsums() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # Generate checksums for each configuration file in the package's /etc/
    # directory for use in "smart" handling of these files.
    // log "$pkg_name" "generating etcsums"
    shift 3

    # Minor optimization - skip packages without /etc/.
    [ -d "$pkg_dir/$pkg_name/etc" ] || return 0

    # Create a list of all files in etc but do it in reverse.
    while read -r etc; do case $etc in /etc/*[!/])
        set -- "$pkg_dir/$pkg_name/$etc" "$@"
    esac done < "$pkg_dir/$pkg_name/$db/$pkg_name/manifest"

    local hash="$(// delegate -- "sh256" "$@")"
    // / as "$src_user" sh -c 'printf "%s\n" "$hash" > "$pkg_dir/$pkg_name/$db/$pkg_name/etcsums"'
}

# $1 repo_url : package repo url/uri
pkg_tar() {
    _env
    // log '$pkg_name' "$pkg_name [global]"
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    // log '$pkg_name' "$pkg_name [local]"

    # Create a tarball from the built package's files. This tarball also
    # contains the package's database entry.
    #
    # NOTE: repo_ comes from caller.
    // log "$pkg_name" "tarball creating"
    # tree "$pkg_dir"

    IFS=$'\3' read -r repo_path repo_ver repo_rel \
        < <(// delegate -- pkg_version "$pkg_name") > /dev/null || // die 'pkg_version' "failed"
    ok "$repo_path" || // die '$repo_path' "$repo_path"
    ok "$repo_ver" || // die '$repo_ver' "$repo_ver"
    local tar_file=$bin_dir/$pkg_name/$pkg_name@$repo_ver-$repo_rel.tar.$KISS_COMPRESS
    local repofile="repo.index"

    # Use 'cd' to avoid needing tar's '-C' flag which may not be portable
    # across implementations.
    cd "$pkg_dir/$pkg_name"

    # Create a tarball from the contents of the built package.
    // / as "$src_user" /usr/bin/tar cf - . | case $KISS_COMPRESS in
        bz2)  bzip2 -z ;;
        gz)   gzip -6  ;;
        lzma) lzma -zf  ;;
        lz)   lzip -z  ;;
        xz)   xz -zT0f  ;;
        zst)  zstd -z  ;;
    esac > "$tar_file"

    # Remove any instances of this package in the index
    # This will leave only the latest version
    // / as "$src_user" touch $bin_dir/$pkg_name/$repofile
    sed -i "/$pkg_name@/d" $bin_dir/$pkg_name/$repofile

    # Write the checksum to the repo file
    local cs="$(// delegate -- "_sh256" "$tar_file")"
    echo "$cs  $_tar_fn" >> "$bin_dir/$pkg_name/$repofile"
    // log "$pkg_name" "repo index updated"

    cd "$OLDPWD"

    // log "$pkg_name" "tarball created successfully"
    // log '$tar_file' "$tar_file"

    # arg1: post-package
    # arg2: package name
    # arg3: path to tarball
    // run_hook post-package "$pkg_name" "$tar_file"
}

# $@ packages name
build_all() {
    _env

    local action="build"

    # Build packages and turn them into packaged tarballs.
    # Order the argument list and filter out duplicates.

    # Mark packages passed on the command-line explicit.
    # Also resolve dependencies for all explicit packages.
    for repo_url do
        IFS=$'\x03' read -r pkg_name _ _ \
            < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        // pkg_dirs "$action" "$pkg_name"
        // pkg_depends "makedeps" "$pkg_name" expl filter
        explicit="$explicit $pkg_name "
    done

    # If this is an update, don't always build explicitly passsed packages
    # and instead install pre-built binaries if they exist.
    ok "$prefer_cache" || explicit_build=$explicit

    # If cross building, make sure the build machine has the correct deps
    set -- $makedeps
    [ "$#" -le 0 ] || // die "You need the following packages on your build machine" "$*"

    set --

    # If an explicit package is a dependency of another explicit package,
    # remove it from the explicit list.
    for repo_url in $explicit; do
        IFS=$'\x03' read -r pkg_name _ _ \
            < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        contains "$deps" "$pkg_name" || set -- "$@" "$pkg_name"
    done
    explicit_cnt=$#
    explicit=$*

    // log "Building: explicit" "$*${deps:+, implicit: ${deps## }}"

    # Intentional, globbing disabled.
    # shellcheck disable=2046,2086
    set -- $deps "$@"

    # Ask for confirmation if extra packages need to be built.
    equ "$#" "$explicit_cnt" || // prompt

    // log "checking for pre-built dependencies"

    # Install any pre-built dependencies if they exist in the binary
    # directory and are up to date.
    for repo_url in "$@"; do
        IFS=$'\x03' read -r pkg_name _ _ \
            < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        local tar_file="$(// delegate -- "pkg_cache" "$repo_url")"
        if ! contains "$explicit_build" "$pkg_name" && ok "$tar_file"; then
            // log "$pkg_name" "Found pre-built binary"

            # Intended behavior.
            # shellcheck disable=2030,2031
            (export KISS_FORCE=1; // args i "$tar_file")
        else
            set -- "$@" "$pkg_name"
        fi
        shift
    done

    for repo_url do
        // pkg_download "$repo_url"
        local repo_path
        IFS=$'\x03' read -r pkg_name _ repo_path \
            < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        local format="$(// delegate -- pkg_format "$repo_path")"
        [ ! -f "$repo_path/sources" ] ||
        [ "$format" == "git" ] ||
        // checksums_verify "$repo_path"
    done

    [ -z ${KISS_ROOT:+x} ]          || // log '$KISS_ROOT' "$KISS_ROOT"
    # Building on host (cross build)
    [ -z ${KISS_XBUILD_TRIPLE:+x} ] || // log '$KISS_XBUILD_TRIPLE' "$KISS_XBUILD_TRIPLE"
    # Building for target (cross host)
    [ -z ${KISS_XHOST_TRIPLE:+x} ]  || // log '$KISS_XHOST_TRIPLE' "$KISS_XHOST_TRIPLE"
    // log '$bin_dir' "$bin_dir"
    [ -z ${CC:+x} ]      || // log '$CC'       "$CC"
    [ -z ${CXX:+x} ]     || // log '$CXX'      "$CXX"
    [ -z ${CFLAGS+x} ]   || // log '$CFLAGS'   "$CFLAGS"
    [ -z ${CXXFLAGS+x} ] || // log '$CXXFLAGS' "$CXXFLAGS"
    [ -z ${LDFLAGS+x} ]  || // log '$LDFLAGS'  "$LDFLAGS"

    # Finally build and create tarballs for all passed packages and
    # dependencies.
    local _build_cur
    for repo_url do
        // log "$repo_url" "Building package ($((_build_cur+=1))/$#)"

        # IFS=$'\3' read -r repo_path repo_ver repo_rel repo_major repo_minor repo_patch repo_ident \
        #     < <(// version_split "$repo_url") > /dev/null ||
        #     // die 'version_split' "failed"
        IFS=$'\x03' read -r pkg_name _ repo_path \
            < <(// repo_resolve "$repo_url") > /dev/null || // die 'repo_resolve' "failed"
        ok "$repo_path" || // die '$repo_path' "$repo_path"

        # arg1: queue-status
        # arg2: package name
        # arg3: number in queue
        # arg4: total in queue
        // run_hook queue "$pkg_name" "$_build_cur" "$#"

        // log '$repo_path' "$repo_path [local]"
        [ -d "$repo_path" ] || // die '$repo_path' "not found ${repo_path:+"${repo_path} "}[local]"
        [ ! -f "$repo_path/sources" ] || // dump_to_make "$repo_path" "$pkg_name"

        // log '$db' "$db"
        // log '$PWD' "$PWD"
        // pkg_build "$pkg_name"
        // pkg_manifest "$pkg_name" "$pkg_dir/$pkg_name"
        // pkg_strip "$pkg_name"

        cd "$pkg_dir/$pkg_name/$db/$pkg_name"
        // pkg_fix_deps "$pkg_name"
        // pkg_etcsums  "$pkg_name"
        // pkg_tar      "$pkg_name"

        if equ "${prefer_cache:=0}" 1 || ! contains "$explicit" "$pkg_name"; then
            // log "$pkg_name" "Needed as a dependency or has an update, installing"

            # Intended behavior.
            # shellcheck disable=2030,2031
            (export KISS_FORCE=1; // args i "$pkg_name")
        fi
    done

    # Intentional, globbing disabled.
    # shellcheck disable=2046,2086
    ! equ "${build_install:=1}" 1 || ! equ "${KISS_PROMPT:=1}" 1 ||
        ! // prompt "Install built packages? [$explicit]" || (// args i $explicit)
}

# could be subshell function before local version
# $1 repo_url : package repo url/uri
pkg_build() {
    _env
    local action="build"
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name repo_dir repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # local repo_path="$(// delegate -- "pkg_find" "$pkg_name")"
    ok "$repo_path" || // die '$repo_path' "$repo_path"
    # Install built packages to a directory under the package name to
    # avoid collisions with other packages.

    // log '$pkg_dir' "$pkg_dir"
    // log '$bin_dir' "$bin_dir"
    // log '$log_dir' "$log_dir"
    // log '$proc_root/$pkg_name' "$proc_root/$pkg_name"
    // log '$make_dir/$pkg_name' "$make_dir/$pkg_name"
    // log '$repo_ver' "$repo_ver"
    // log '$repo_path' "$repo_path [global]"

    // log '$repo_path' "$repo_path [local]"
    // log '$pkg_name' "$pkg_name"
    // log '$db' "$db"
    // log '$LOGNAME' "$LOGNAME"
    // log '$pkg_dir/$pkg_name/$db/$pkg_name' "$pkg_dir/$pkg_name/$db/$pkg_name"

    // mkcd "$make_dir/$pkg_name" "$pkg_dir/$pkg_name/$db/$pkg_name"
    [ -d "$pkg_dir/$pkg_name/$db/$pkg_name" ] ||
    // die "does not exist" "$pkg_dir/$pkg_name/$db/$pkg_name"

    // log "$pkg_name" "Starting build"

    # arg1: pre-build
    # arg2: package name
    # arg3: path to build directory
    // run_hook pre-build "$pkg_name" "$make_dir/$pkg_name"

    # Attempt to create the log file early so any permissions errors are caught
    # before the build starts. 'tee' is run in a pipe and POSIX shell has no
    # pipe-fail causing confusing behavior when tee fails.
    # Log has been created when script booted
    # : > "$log_output"

    [ -z "${USE_GMAKE+x}" ] || {
        // log "GNU make used"
        [ "$(readlink -f "$bin_dir/$pkg_name/gunzip")" == "/usr/bin/pigz"  ] ||
            // / as "$src_user" /usr/bin/ln -sf "/usr/bin/pigz"  "$bin_dir/$pkg_name/gunzip"
        [ "$(readlink -f "$bin_dir/$pkg_name/make")"   == "/usr/bin/gmake" ] ||
            // / as "$src_user" /usr/bin/ln -sf "/usr/bin/gmake" "$bin_dir/$pkg_name/make"
        export PATH="$bin_dir/$pkg_name:$PATH"
    }

    # Call the build script, log the output to the terminal and to a file.
    # There's no PIPEFAIL in POSIX shell so we must resort to tricks like kill.
    {
        // log '$LOGNAME' "$LOGNAME"
        // log '$(whoami)' "$(whoami)"
        // log '$PWD' "$PWD"
        # Give the script a modified environment. Define toolchain program
        # environment variables assuming a generic environment by default.
        #
        # Define DESTDIR and GOPATH to sane defaults as their use is mandatory
        # in anything using autotools, meson, cmake, etc. Define KISS_ROOT as
        # the sanitized value used internally by the package manager. This is
        # safe to join with other paths.
        env \
            AR="${AR:-ar}" \
            CC="${CC:-cc}" \
            CXX="${CXX:-c++}" \
            CFLAGS="${CFLAGS:-" -O3 -pipe -fPIC "}" \
            CXXFLAGS="${CXXFLAGS:-" -O3 -pipe -fPIC "}" \
            NM="${NM:-nm}" \
            RANLIB="${RANLIB:-ranlib}" \
            KISS_SRC_ROOT="$KISS_SRC_ROOT" \
            RUSTFLAGS="--remap-path-prefix=${PWD=.} ${RUSTFLAGS}" \
            GOFLAGS="-trimpath -modcacherw $GOFLAGS" \
            GOPATH="$PWD/go" \
            PATH="$GOPATH/bin:$PATH" \
            KISS_TMPDIR="$KISS_TMPDIR" \
            REPO_MAIN="$REPO_MAIN" \
            KISS_ROOT="$KISS_ROOT" \
            KISS_XHOST_ARCH="$KISS_XHOST_ARCH" \
            KISS_XBUILD_ARCH="$KISS_XHOST_ARCH" \
            CHOST=${KISS_XHOST_TRIPLE} \
            CBUILD=${KISS_XBUILD_TRIPLE} \
            KISS_XHOST_ABI="$KISS_XHOST_ABI" \
            KISS_XBUILD_ABI="$KISS_XBUILD_ABI" \
            KISS_XHOST_TRIPLE="$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI" \
            KISS_XBUILD_TRIPLE="$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI" \
            KISS_PID="$KISS_PID" \
            _KISS_LVL="$_KISS_LVL" \
            SRC_DIR="$src_dir" \
            LOG_DIR="$log_dir" \
            MAKE_DIR="$make_dir" \
            DESTDIR="$pkg_dir/$pkg_name" \
            \
            "$repo_path/build" "$pkg_dir/$pkg_name" "$repo_ver" 2>&1 || {
            // log "$pkg_name" "build failed"
            // log "$pkg_name" "if hardcoded doas/sudo/su/ssu, it is not recommended)"
            # // log "$pkg_name" "Log stored to \"$log_output\""
            // log_permanent_all "$action" "$pkg_name"
            # arg1: build-fail
            # arg2: package name
            # arg3: path to build directory
            (// run_hook build-fail "$pkg_name" "$make_dir/$pkg_name") || :

            # clean_all
            kill 0
        }
    } | tee -a "$log_output"

    # # Delete the log file if the build succeeded to prevent the directory
    # # from filling very quickly with useless logs.
    # equ "$KISS_KEEPLOG" 1 || rm -f "$log_dir/$pkg_name/build.log"

    # Copy the repository files to the package directory.
    // / as "$src_user" /usr/bin/cp -LRf "$repo_path" "$pkg_dir/$pkg_name/$db/"

    // log "$pkg_name" "successfully built"

    # arg1: post-build
    # arg2: package name
    # arg3: path to DESTDIR
    // run_hook post-build "$pkg_name" "$pkg_dir/$pkg_name"
}

checksum() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"

    // pkg_download "$pkg_name" c

    // log '$repo_path' "$repo_path"
    [ -f "$repo_path/sources" ] || return 0

    local hash="$(// delegate -- "checksum_gen" "$pkg_name")"

    if ok "$hash"; then
        local as_kiss_root_usr=
        [ "$(whoami)" == "$kiss_root_user" ] ||
        local as_kiss_root_usr="$(// delegate -- as_user "$kiss_root_user")"
        // log '$as_kiss_root_usr' "$as_kiss_root_usr"
        $as_kiss_root_usr sh -c '/usr/bin/printf "%s\n" "$hash" > "$repo_path/checksums"'
        // log "$pkg_name" "checksums generated"

    else
        // log "$pkg_name" "no sources needing checksums"
    fi
}

# $1 repo_url : package repo url/uri
checksum_gen() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    // log '$repo_path' "$repo_path"
    # Generate checksums for packages.
    #
    # NOTE: repo_ comes from caller.
    while read -r src_url dest || ok "${src_url%%\#*}"; do
        IFS=$'\3' read -r _res _ _ \
            < <(// source_route "$pkg_name" "$src_url" "$dest") > /dev/null ||
            // die "source_route" "failed"

        case ${_res##git+*} in */*[!.])
            set -- "$@" "$_res"
        esac
    done < "$repo_path/sources"

    # sh256 "$hash_name" "$@"
    local hash="$(// delegate -- "sh256" "$@")"
    printf "\n%s" "$hash"
}

# $1 repo_url : package repo url/uri
checksums_verify() {
    _env
    local repo_path="$1"
    local pkg_name="${repo_path##*/}"

    # Verify all package checksums. This is achieved by generating a new set
    # of checksums and then comparing those with the old set.
    #
    # NOTE: repo_path comes from caller.
    // log "$pkg_name" "verifying sources"

    # Generate a new set of checksums to compare against.
    local hash="$(// delegate -- "checksum_gen" "$pkg_name")"
    // log '$hash' "$hash"

    # Intentional, globbing disabled.
    # shellcheck disable=2038,2086
    set -- $hash
    local checksums="$repo_path/checksums"
    [ -z "${KISS_FORCE:+x}" ] ||    # [ -s "$checksums" ] &&
    ! is_in_main "$repo_path" || {
        // log '$hash' "${hash:+"${hash} [updated]"}"
        as_own "$checksums" : > "$checksums"
        for hash_item in "$@"; do
            as_own "$checksums" sh -c $'printf \'%s\n\' "$hash_item" >> "$checksums"' ||
            // die 'permission denied' "on writting version to file $checksums"
        done
    }

    # Check that the first column (separated by whitespace) match in both
    # checksum files. If any part of either file differs, mismatch. Abort.
    null "$1" || while read -r check _ || ok "$1"; do
        # printf '%s\n%s\n' "- ${check:-missing}" "+ ${1:-no source}"
        // log '$check' "${check:-missing}"
        // log '$hash' "${1:-no source}"
        equ "$1-${check:-null}" "$check-$1" ||
        equ "$1-${check:-null}" "$1-SKIP" || {
            [ -n "${KISS_FORCE:+x}" ] || // die "$pkg_name" "checksum mismatch"
        }
        shift "$(($# != 0))"
    done < "$checksums"
}

# $1 repo_url : package repo url/uri
pkg_conflicts() {
    _env
    # Check to see if a package conflicts with another.
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"

    // log "$pkg_name" "checking for package conflicts"

    local manifest_files="$(// delegate -- "slot_aquire" "$pkg_name" "manifest-files")"
    local found_conflicts="$(// delegate -- "slot_aquire" "$pkg_name" "found-conflicts")"
    local tar_man="$tar_dir/$pkg_name/$db/$pkg_name/manifest"
    [ -f "$tar_man" ] ||
    // die "does not exist" "$tar_man"
    # Filter the tarball's manifest and select only files. Resolve all
    # symlinks in file paths as well.
    while read -r file; do case $file in *[!/])
        // resolve_path "$file"

        printf '%s\n' "$_rpath"
    esac done < "$tar_man" > "$manifest_files"

    cd "$tar_dir/$pkg_name"
    set +f
    set -f "$sys_db"/*/manifest

    # Remove the current package from the manifest list.
    local complement="$(delegate -- replace " $* " " " " $sys_db/$pkg_name/manifest ")"

    # Intentional, globbing disabled.
    # shellcheck disable=2046,2086
    set -- $complement

    # Return here if there is nothing to check conflicts against.
    ! equ "$#" 0 || return 0

    # Store the list of found conflicts in a file as we'll be using the
    # information multiple times. Storing things in the cache dir allows
    # us to be lazy as they'll be automatically removed on script end.
    grep -Fxf "$manifest_files" -- "$@" 2>/dev/null > "$found_conflicts" || :

    # Enable alternatives automatically if it is safe to do so.
    # This checks to see that the package that is about to be installed
    # doesn't overwrite anything it shouldn't in '$REPO_ROOT/installed'.
    grep -q ":$REPO_ROOT/installed/" "$found_conflicts" || safe=1

    if ! equ "$KISS_CHOICE" 1 && equ "$safe" 1 && [ -s "$found_conflicts" ]; then
        # This is a novel way of offering an "alternatives" system.
        # It is entirely dynamic and all "choices" are created and
        # destroyed on the fly.
        #
        # When a conflict is found between two packages, the file
        # is moved to a directory called "choices" and its name
        # changed to store its parent package and its intended
        # location.
        #
        # The package's manifest is then updated to reflect this
        # new location.
        #
        # The 'kiss alternatives' command parses this directory and
        # offers you the CHOICE of *swapping* entries in this
        # directory for those on the filesystem.
        #
        # The alternatives command does the same thing we do here,
        # it rewrites manifests and moves files around to make
        # this work.
        #
        # Pretty nifty huh?
        while IFS=: read -r _ con; do
            // log "found conflict $con"

            # Create the "choices" directory inside of the tarball.
            # This directory will store the conflicting file.
            mkdir -p "$PWD/$cho_db"

            # Construct the file name of the "db" entry of the
            # conflicting file. (pkg_name>usr>bin>ls)
            local fake_route="$(delegate -- replace "$con" '>' '/')"

            # Move the conflicting file to the choices directory
            # and name it according to the format above.
            mv -f "$PWD$con" "$PWD/$cho_db/$pkg_name$fake_route" 2>/dev/null || {
                // log "File must be in ${con%/*}" "and not a symlink to it"
                // log "This usually occurs when a binary is installed to" "/sbin"
                // die "instead of" "/usr/bin (example)"
            }
        done < "$found_conflicts"

        // log "$pkg_name" "converted all conflicts to choices (kiss a)"

        # Rewrite the package's manifest to update its location
        # to its new spot (and name) in the choices directory.
        // pkg_manifest "$pkg_name" "$tar_dir/$pkg_name"

    elif [ -s "$found_conflicts" ]; then
        // log "Package '$pkg_name' conflicts with another package" "!>"
        // log "Run 'KISS_CHOICE=1 kiss i $pkg_name' to add conflicts" "!>"
        // die "as alternatives." "!>"
    fi
}

# $@ :
pkg_alternatives() {
    _env
    if equ "$1" -; then
        while read -r pkg_name path; do
            // pkg_swap "$pkg_name" "$path"
        done

    elif ok "$1"; then
        // pkg_swap "$@"

    else
        # Go over each alternative and format the file
        # name for listing. (pkg_name>usr>bin>ls)
        set +f; for pkg_name in "$sys_ch/"*; do
            local real_route="$(delegate -- replace "${pkg_name##*/}" '/' '>')"
            # printf '%s %s\n' "${real_route%%/*}" "/${real_route#*/}"
            // log "${real_route%%/*}" "/${real_route#*/}"
        done
    fi
}

pkg_swap() {
    _env
    # Swap between package alternatives.
    [ -d "$sys_db/$1" ] || // die '$sys_db/$1' "not found $sys_db/$1"

    local fake_route="$(delegate -- replace "$1$2" '>' '/')"

    [ -f "$sys_ch/$fake_route" ] || [ -h "$sys_ch/$fake_route" ] ||
        // die "$sys_ch/$fake_route" "Alternative '$1 ${2:-null}' doesn't exist"

    if [ -f "$KISS_ROOT/${2#/}" ]; then
        // pkg_owner "/${2#/}" ||
            // die '$2' "File '$2' exists on filesystem but isn't owned"

        // log "swapping '$2'" "from '$_owns' to '$1'"

        # Convert the current owner to an alternative and rewrite its manifest
        # file to reflect this.
        cp -Pf "$KISS_ROOT/${2#/}" "$sys_ch/$_owns>${fake_route#*>}"
        // manifest_replace "$_owns" "$2" "/$cho_db/$_owns>${fake_route#*>}"
    fi

    # Convert the desired alternative to a real file and rewrite the manifest
    # file to reflect this. The reverse of above.
    mv -f "$sys_ch/$fake_route" "$KISS_ROOT/${2#/}"
    // manifest_replace "$1" "/$cho_db/$fake_route" "$2"
}

file_rwx() {
    _env
    # Convert the output of 'ls' (rwxrwx---) to octal. This is simply
    # a 1-9 loop with the second digit being the value of the field.
    #
    # NOTE: This drops setgid/setuid permissions and does not include
    # them in the conversion. This is intentional.
    unset oct o

    rwx=$(ls -ld "$1")

    for c in 14 22 31 44 52 61 74 82 91; do
        rwx=${rwx#?}

        case $rwx in
            [rwx]*) o=$((o + ${c#?})) ;;
             [st]*) o=$((o + 1)) ;;
        esac

        case $((${c%?} % 3)) in 0)
            oct=$oct$o
            o=0
        esac
    done
}

pkg_install_files() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    shift 1
    # Copy files and create directories (preserving permissions).
    # The 'test $1' will run with '-z' for overwrite and '-e' for verify.
    while { read -r file && _file=$KISS_ROOT$file; } do case $file in
        */)
            # Skip directories if they already exist in the file system.
            # (Think /usr/bin, /usr/lib, etc).
            [ -d "$_file" ] || {
                // file_rwx "$2/${file#/}"
                mkdir -m "$oct" "$_file"
            }
        ;;

        *)
            # Skip directories and files which exist in verify mode.
            [ -d "$_file" ] || ! test "$1" "$_file" ||
                continue

            case $file in /etc/*[!/])
                # Handle /etc/ files in a special way (via a 3-way checksum) to
                # determine how these files should be installed. Do we overwrite
                # the existing file? Do we install it as $file.new to avoid
                # deleting user configuration? etc.
                #
                # This is more or less similar to Arch Linux's Pacman with the
                # user manually handling the .new files when and if they appear.
                // pkg_etc "$file" "$pkg_name" || continue
            esac

            if [ -h "$_file" ]; then
                # Copy the file to the destination directory overwriting
                # any existing file.
                cp -fP "$2$file" "${_file%/*}/."

            else
                # Construct a temporary filename which is a) unique and
                # b) identifiable as related to the package manager.
                local __tmp=${_file%/*}/__kiss-tmp-$pkg_name-${file##*/}-$KISS_PID

                # Copy the file to the destination directory with the
                # temporary name created above.
                cp -fP "$2$file" "$__tmp" &&

                # Atomically move the temporary file to its final
                # destination. The running processes will either get
                # the old file or the new one.
                mv -f "$__tmp" "$_file"
            fi
    esac || return 1; done
}

pkg_remove_files() {
    _env
    # Remove a file list from the system. This function runs during package
    # installation and package removal. Combining the removals in these two
    # functions allows us to stop duplicating code.
    while read -r file; do
        case $file in /etc/?*[!/])
            local hash="$(// delegate -- "sh256" "$KISS_ROOT/${file#/}")"

            read -r sum_pkg <&3 ||:

            equ "$hash" "$sum_pkg" || {
                // log "skipping" "$file (modified)"
                continue
            }
        esac

        local _file=${KISS_ROOT:+"$KISS_ROOT/"}${file%%/}

        # Queue all directory symlinks for later removal.
        if [ -h "$_file" ] && [ -d "$_file" ]; then
            case $file in /*/*/)
                set -- "$@" "$_file"
            esac

        # Remove empty directories.
        elif [ -d "$_file" ]; then
            rmdir "$_file" 2>/dev/null || :

        # Remove everything else.
        else
            rm -f "$_file"
        fi
    done

    # Remove all broken directory symlinks.
    for sym do
        [ -e "$sym" ] || rm -f "$sym"
    done
}

pkg_etc() {
    _env
    local file="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local hash="$(// delegate -- "sh256" "$tar_dir/$pkg_name/$file" "$KISS_ROOT/${file#/}")"

    local sum_new=${hash%%"$newline"*}
    local sum_sys=${hash#*"$newline"}

    read -r sum_old <&3 2>/dev/null ||:

    # Compare the three checksums to determine what to do.
    case ${sum_old:-null}${sum_sys:-null}${sum_new} in
        # old = Y, sys = X, new = Y
        "${sum_new}${sum_sys}${sum_old}")
            return 1
        ;;

        # old = X, sys = X, new = X
        # old = X, sys = Y, new = Y
        # old = X, sys = X, new = Y
        "${sum_old}${sum_old}${sum_old}"|\
        "${sum_old:-null}${sum_sys}${sum_sys}"|\
        "${sum_sys}${sum_old}"*)

        ;;

        # All other cases.
        *)
            // war "$pkg_name" "saving $file as $file.new"
            _file=$_file.new
        ;;
    esac
}

removable() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    # Check if a package is removable and die if it is not.
    # A package is removable when it has no dependents.
    // log "$pkg_name" "checking if package removable"

    cd "$sys_db"
    set +f
    # ?
    repo_url="$1"
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    // log '$pkg_name' "$pkg_name"

    ! grep -lFx -- "$pkg_name" */depends ||
        // die "$pkg_name" "Not removable, has dependents"

    set -f
    cd "$OLDPWD"
}

# $1 repo_url : package repo url/uri
# could be subshell function before local version
pkg_remove() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local repo_target="$sys_db/$pkg_name"
    # Remove a package and all of its files. The '/etc' directory is handled
    # differently and configuration files are *not* overwritten.
    [ -d "$repo_target" ] || // die '$pkg_name' "not installed $pkg_name"

    # Intended behavior.
    # shellcheck disable=2030,2031
    equ "$KISS_FORCE" 1 || // removable "$pkg_name"

    # Block being able to abort the script with 'Ctrl+C' during removal.
    # Removes all risk of the user aborting a package removal leaving an
    # incomplete package installed.
    trap '' INT

    # arg1: pre-remove
    # arg2: package name
    # arg3: path to installed database
    // run_hook_pkg pre-remove "$pkg_name"
    // run_hook     pre-remove "$pkg_name" "$repo_target"

    // log '$pkg_name' "$pkg_name"
    // log "removing package" "$pkg_name"
    # Make a backup of any etcsums if they exist.
    [ ! -f "$repo_target/manifest" ] || {
        [ ! -s "$repo_target/etcsums" ] &&
        // pkg_remove_files < "$repo_target/manifest" || {
            local etcsums_clone="$(// delegate -- "slot_push" "$pkg_name" "$repo_target/etcsums")"
            // pkg_remove_files < "$repo_target/manifest" 3< "$etcsums_clone"
        }
    }
    rm -rf "$repo_target"
    # Reset 'trap' to its original value. Removal is done so
    # we no longer need to block 'Ctrl+C'.
    trap '// clean_all "r" "$pkg_name"' EXIT INT

    // log "$pkg_name" "removed successfully"
}

# could be subshell function before local version
# $1 repo_url  : package repo url/uri
# $2 depends   : depends file address
# $3 missing   : missing package(s)
installable() {
    _env
    local repo_url="$1"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local depents="$2"
    local missing="$3"
    # Check if a package is removable and die if it is not.
    # A package is removable when all of its dependencies
    # are satisfied.
    // log "$pkg_name" "checking if package installable"

    // log '$PWD' "$PWD"
    // log '$pkg_name' "$pkg_name"
    // log '$depents' "$depents"

    null "$missing" || // log '$missing' "$missing"

    # False positive.
    # shellcheck disable=2094
    ! [ -f "$depents" ] ||

    while read -r dep dep_type || ok "$dep"; do
        // debug '$dep' "$dep"
        // debug '$sys_db' "$sys_db"
        case "$dep $dep_type" in [!\#]?*\ )
            { [ ! -d "$sys_db/$dep" ] &&
                // log '$dep not found' "$dep"
            } || continue

            // debug '$dep' "$dep"
            // war '$dep' "$dep"
            // debug '$dep_type' "$dep_type"
            // war '$dep_type' "$dep_type"
            missing=$(($missing + 1))
            set -- "$pkg_name" "$depents" "$missing"
            # set -- "$1" "$2" "$(($3 + 1))"
        esac
    done < "$depents"
    null "$missing" || // log '$missing' "$missing"
    // debug '$3' "$3"
    // debug '$missing' "$missing"
    case ${missing:-0} in [1-9]*)
        // die "$pkg_name" "not installable, missing $missing package(s)"
    esac
}

# Readonly
# $1 diff source
# $2 diff target
identical() (
    _env
    local a="$1"
    local b="$2"
    [ -d "$a" ] || return 1
    [ -d "$b" ] || return 1
    local result=1
    local differences=
    while IFS=$' ' read -r _ _ _ file _; do
        local base_name="${file##*/}"
        case "$base_name" in
            "version"|"keys"|"manifest"|"etcsums"|"checksums"|"depends") ;;
            *)
                differences="$file${differences:+" ${differences}"}"
                // log "diff [$base_name]" "$file"
        esac
    done < <(diff -qrN "$a" "$b") 2>/dev/null || // die 'diff' "failed"
    ok "$differences" || result=0
    return "$result"
)

# Return recommended repo source
# How to use
# archive "$repo_archive" "$repo_in_main" "$reference"
archive() (
    _env
    local repo_archive="$1"
    local repo_in_main="$2"
    local reference="$3"
    local $index_global="$4"
    local repo_result=

    repo_in_main="$(standardize "$repo_in_main")"

    [ -f "$repo_in_main/build" ] ||
    [ -f "$repo_in_main/sources" ] ||
    [ -f "$repo_in_main/version" ] || {
        // war "$repo_in_main" "was discarded due to lack of integrity"
        \rm -rf "$repo_in_main"
        repo_result="$reference"
        printf '\n%s' "$repo_result"
        return 0
    }

    IFS=$'\x03' read -r pkg_name repo_dir _ \
        < <(// repo_resolve "$repo_in_main") > /dev/null || // die 'repo_resolve' "failed"

    local repo_target="$sys_db/$pkg_name"

    [ -z "${KISS_FORCE:+X}" ] &&
    // identical "$repo_target" "$repo_in_main" || {
        IFS=$'\3' read -r _ ver rel \
            < <(// delegate -- pkg_version "$pkg_name" "" "" "$repo_dir") > /dev/null ||
        // die 'pkg_version' "failed"

        local version_dir="$ver-$rel"

        # Make room for the newcomers
        # The most recent repo backup
        rsync -aqzL "$repo_in_main/." --exclude=keys --exclude=manifest --delete-after "$repo_archive/"
        sync

        [ ! -d "$repo_archive/$version_dir" ] || {
            // identical "$repo_archive/$version_dir" "$repo_in_main" ||
            \mv -f "$repo_archive/$version_dir" "$repo_archive/$version_dir.$(mktemp -u XXXXXX)"
        }

        [ -d "$repo_archive/$version_dir" ] || {
            rsync -aqzL "$repo_in_main/." "$repo_archive/$version_dir/"
            sync
        }
    }

    if is_in_main "$reference"; then
        # Reundances
        // log '$repo_in_main' "$repo_in_main [$index_global]"
        // log '$reference' "$reference"
        [ "$repo_in_main" == "$reference" ] || {
            \rm -rf "$repo_in_main"
        }
        repo_result="$reference"
    else
        rsync -aqzL "$reference/." --exclude=keys --exclude=manifest --delete-after "$repo_in_main/"
        sync
        repo_result="$repo_in_main"
    fi

    printf '\n%s' "$repo_result"
)

# Readonly
is_in_main() (
    _env
    local repo_url="$1"
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local result=1
    # Without this local definition, repo_in_main in caller/parent functions might be modified.
    # So I made the fuction readonly
    local repo_in_main
    # // war '$kiss_path_repo_list_origin' "$kiss_path_repo_list_origin"
    for repo_in_main in $(// delegate -- pkg_find "$pkg_name" "pure" "-d" "$KISS_PATH"); do
        // debug '$repo_in_main' "${repo_in_main:+"${repo_in_main} "}inside pure pkg_find"
        [ "$repo_url" == "$repo_in_main" ] || continue
        result=0
        break
    done
    return $result
)

# $1 repo_url : package path
pkg_install() {
    _env
    local repo_url="$1"
    local action="install"
    // log '$repo_url' "$repo_url"
    // log '$repo_path' "$repo_path [global]"

    # Install a built package tarball.
    #
    # Package installation works similarly to the method used by Slackware in
    # some of their tooling. It's not the obvious solution to the problem,
    # however it is the best solution at this given time.
    #
    # When an installation is an update to an existing package, instead of
    # removing the old version first we do something different.
    #
    # The new version is installed overwriting any files which it has in
    # common with the previously installed version of the package.
    #
    # A "diff" is then generated between the old and new versions and contains
    # any files existing in the old version but not the new version.
    #
    # The package manager then goes and removes these files which leaves us
    # with the new package version in the file system and all traces of the
    # old version gone.
    #
    # For good measure the package manager will then install the new package
    # an additional time. This is to ensure that the above diff didn't contain
    # anything incorrect.
    #
    # This is the better method as it is "seamless". An update to busybox won't
    # create a window in which there is no access to all of its utilities.
    local tar_file
    local pkg_name
    local repo_source=
    local format
    # Install can also take the full path to a tarball. We don't need to check
    # the repository if this is the case.
    case $repo_url in
        *.tar.*)
            // log 'tar $repo_url' "$repo_url"

            [ -f "$repo_url" ] || // die '$repo_url' "File '${repo_url:+"${repo_url} "}'does not exist"

            pkg_name="${repo_url##*/}"
            pkg_name="${pkg_name%@*}"
            IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$pkg_name") \
                > /dev/null || // die 'repo_resolve' "failed"
            format="$(// delegate -- pkg_format "$repo_path")"
            // log '$format' "$format"
            [ -z "${repo_path##*"${sys_db}"*}" ] || repo_source="$repo_path"
            tar_file="$repo_url"
            ;;

        *)
            // log '$repo_url' "$repo_url"

            repo_url=$(standardize $repo_url)
            IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
                > /dev/null || // die 'repo_resolve' "failed"
            format="$(// delegate -- pkg_format "$repo_path")"
            // log '$format' "$format"
            [ -z "${repo_path##*"${sys_db}"*}" ] || repo_source="$repo_path"
            // tar_file="$(delegate -- "pkg_cache" "$pkg_name")"
            { [ "$?" -eq 0 ] && ok "$tar_file"; } || {  # // die "$pkg_name" "not yet built"
                { action=c; ! // checksum  "$pkg_name" 2>&1 > /dev/stderr; } ||
                { action=b; ! // build_all "$pkg_name" 2>&1 > /dev/stderr; } ||
                // tar_file="$(delegate -- "pkg_cache" "$pkg_name")"
                { [ "$?" -eq 0 ] && ok "$tar_file"; } || // die "$pkg_name" "build failed"
            }
            ;;
    esac

    repo_target="$sys_db/$pkg_name"

    [ -n "$repo_source" ] || {
        // repo_source="$(delegate -- "pkg_find" "$pkg_name" "" "-d" "$KISS_PATH")"
        # IFS=$'\3' read -r repo_source repo_ver repo_rel \
        #     < <(// delegate -- pkg_version "${pkg_name##*/}" "" "" "$pkg_dir/$pkg_name/$db") > /dev/null ||
        # // die 'pkg_version' "failed"
        // log '$repo_source' "$repo_source [first encountered]"
    }
    [ -d "$repo_source" ] || // die '$repo_source' "dir $repo_source does not exist"

    // pkg_dirs "$action" "$pkg_name"

    // identical "$repo_target" "$repo_source" || {
        rsync -aqzL "$repo_source/." --exclude=keys --exclude=manifest --delete-after "$repo_target/"
        sync
    }

    // log '$pkg_name' "$pkg_name"
    // log '$repo_source' "$repo_source"
    // log '$repo_target' "$repo_target"
    // log '$tar_dir/$pkg_name' "$tar_dir/$pkg_name"

    { [ -d "$repo_target" ] &&
    // identical "$repo_target" "$repo_source"; } || // die '$repo_target' "${repo_target:+"${repo_target} "}is invalid"

    // mkcd "$tar_dir/$pkg_name"

    # The tarball is extracted to a temporary directory where its contents are
    # then "installed" to the filesystem. Running this step as soon as possible
    # allows us to also check the validity of the tarball and bail out early
    # if needed.

    ok "$tar_file" ||
    // die '$tar_file' "${tar_file:+"${tar_file} "}not found [local]"

    // log '$tar_file' "$tar_file [local]"

    // decompress "$tar_file" | tar xf -

    # Naively assume that the existence of a manifest file is all that
    # determines a valid KISS package from an invalid one. This should be a
    # fine assumption to make in 99.99% of cases.
    local tar_man="$tar_dir/$pkg_name/$db/$pkg_name/manifest"
    [ -f "$tar_man" ] || // die '$tar_man' "Not a valid KISS package. $tar_man does not exist"

    # Intended behavior.
    # shellcheck disable=2030,2031
    equ "$KISS_FORCE" 1 || {
        // manifest_validate "$pkg_name"
        // installable "$pkg_name" "$tar_dir/$pkg_name/$db/$pkg_name/depends"
    }
    // log '$PWD' "$PWD"

    # arg1: pre-install
    # arg2: package name
    # arg3: path to extracted package
    // run_hook pre-install "$pkg_name" "$tar_dir/$pkg_name"

    // pkg_conflicts "$pkg_name"

    // log "$pkg_name" "installing package (${tar_file##*/})"

    # If the package is already installed (and this is an upgrade) make a
    # backup of the manifest and etcsums files.
    local manifest="$(// delegate -- "slot_push" "$pkg_name" "$repo_target/manifest")"
    // log '$manifest' "$manifest"

    local manifest_diff="$(// delegate -- "slot_aquire" "$pkg_name" "manifest-diff")"
    // log '$manifest_diff' "$manifest_diff"

    # Generate a list of files which exist in the currently installed manifest
    # but not in the newer (to be installed) manifest.
    grep -vFxf "$tar_man" "$manifest" > "$manifest_diff" 2>/dev/null ||:

    # Reverse the manifest file so that we start shallow and go deeper as we
    # iterate over each item. This is needed so that directories are created
    # going down the tree.
    local manifest_reverse="$(delegate -- "slot_aquire" "$pkg_name" "manifest-reverse")"
    sort "$tar_man" > "$manifest_reverse"

    # Block being able to abort the script with Ctrl+C during installation.
    # Removes all risk of the user aborting a package installation leaving
    # an incomplete package installed.
    trap_off    # trap '' INT

    local first_run="\"$pkg_name\" -z \"$tar_dir/$pkg_name\" < \"$manifest_reverse\""
    local remove="< \"$manifest_diff\""
    local second_run="\"$pkg_name\" -e \"$tar_dir/$pkg_name\" < \"$manifest_reverse\""
    [ ! -f "$repo_target/etcsums" ] || {
        local etcsums_clone="$(// delegate -- "slot_push" "$pkg_name" "$repo_target/etcsums")"
        // log '$etcsums_clone'  "$etcsums_clone"
        first_run="$first_run 3< \"$etcsums_clone\""
        remove="$remove 3< \"$etcsums_clone\""
        second_run="$second_run 3< \"$etcsums_clone\""
    }
    // log '$first_run' "$first_run"
    // log '$remove' "$remove"
    // log '$second_run' "$second_run"
    # Install the package's files by iterating over its manifest.
    {
        / // pkg_install_files $first_run &&

        # This is the aforementioned step removing any files from the old
        # version of the package if the installation is an update. Each file
        # type has to be specially handled to ensure no system breakage occurs.
        / // pkg_remove_files $remove &&

        # Install the package's files a second time to fix any mess caused by
        # the above removal of the previous version of the package.
        / // pkg_install_files $second_run;

    } || {
        # clean_all
        // war "$pkg_name" "Failed to install package."
        // die "$pkg_name" "Filesystem now dirty, manual repair needed."
    }
    # Reset 'trap' to its original value. Installation is done so we no longer
    # need to block 'Ctrl+C'.
    trap_on "install" "$pkg_name" # trap clean_all EXIT INT

    # arg1: post-install
    # arg2: package name
    # arg3: path to installed package database
    // run_hook_pkg post-install "$pkg_name"
    // run_hook     post-install "$pkg_name" "$repo_target"

    // log '$sys_db' "$sys_db"
    // log '$tar_dir' "$tar_dir"
    # $HOME/.cache/kiss/proc/$pkg_name/extract
    // log '$pkg_dir' "$pkg_dir"
    # $HOME/.cache/kiss/proc/$pkg_name/pkg
    // log '$db' "$db"
    // log '$pkg_name' "$pkg_name"
    // log '$pkg_dir/$pkg_name/$db/$pkg_name' "$pkg_dir/$pkg_name/$db/$pkg_name"
    // log '$tar_dir/$pkg_name/$db/$pkg_name' "$tar_dir/$pkg_name/$db/$pkg_name"

    [ -d "$pkg_dir/$pkg_name/$db/$pkg_name" ] ||
    // die "$pkg_dir/$pkg_name/$db/$pkg_name" "does not exist"

    IFS=$'\3' read -r _ repo_ver repo_rel \
        < <(// delegate -- pkg_version "${repo_source##*/}" "" "" "${repo_source%/*}") > /dev/null ||
    // die 'pkg_version' "failed"
    // log '$repo_ver' "$repo_ver"
    // log '$repo_rel' "$repo_rel"


    [ -n "${REPO_ROOT:+x}" ] || // die '$REPO_ROOT' "$REPO_ROOT"
    [ -n "${REPO_MAIN:+x}" ] || // die '$REPO_MAIN' "$REPO_MAIN"
    [ -d "$REPO_MAIN" ] || // die '$REPO_MAIN' "$REPO_MAIN directory does not exist"

    # package repo might be in sys_db / main repo / others
    # We want to create the relation between sys_db and main repo
    # Serial key occupied : value identical : key in main repo
    #   1      0            check checksum?            0          # Key global conflicts free. Double keys might have the same repo
    #   1      0            check checksum?            0          # Copy $repo_target to main repo
    #   2      1                   1                   1          # Keep it: repo_source="$repo"
    #   3      1                   1                   0          # Copy $repo_target to main repo
    #   4      1                   0                   0          # To invent a wheel? Auto version and link to it? archive. "choices"?

    # Move to pick_up? No, because you don't know if it will be built
    # [ -n "${repo_source##*${sys_db}*}" ] || {

    # repo_source is in sys_db
    local index_global=-1
    local condidates=

    local repo_archive="$REPO_MAIN/archive/$pkg_name"
    [ -d "$repo_archive" ] || \mkdir -p "$repo_archive"

    # Will include submodules
    # Search outside sys_db
    # for repo_in_main in $(find "$REPO_MAIN" \( -type d -o -type l \) \( \
    #             -path "*/modules" \
    #             -o -path "*/underconstruction" \
    #             -o -path "*/.git" \
    #             \) -prune -o -name "${pkg_name}" -print); do
    #             # -o -path "*/archive" \

    # In system evironment main repo list
    # Looks like:
    # $REPO_MAIN/system/crust
    local repo_in_main
    for repo_in_main in $(// delegate -- pkg_find $pkg_name "pure" "-d" "$KISS_PATH"); do
        index_global=$((index_global + 1))
        [ -n "${repo_in_main##*"${repo_archive}"*}" ] || // die '$repo_in_main' "$repo_in_main [$index_global]"
        [ -n "${repo_in_main##*"${sys_db}"*}" ] || { // war '$repo_in_main' "$repo_in_main [$index_global]"; continue; }
        // log '$repo_in_main' "$repo_in_main [$index_global]"
        // log '$repo_source' "$repo_source"
        [ -n "${repo_source##*"${repo_archive}"*}" ] || // die '$repo_source' "$repo_source [$index_global]"

        repo_source="$(// delegate -- archive "$repo_archive" "$repo_in_main" "$repo_source" "$index_global")"
        ! // is_in_main "$repo_source" && [ -d "$repo_in_main" ] || continue

        # Guaranteed performance with step-by-step filtering
        diff -bwurB "$repo_target/version" "$repo_in_main/version" > /dev/null 2>&1 || continue
        diff -bwurB "$repo_target/build" "$repo_in_main/build" > /dev/null 2>&1 || continue
        ! // identical "$repo_target" "$repo_in_main" || {
            # First run
            # If identical, and repo_source is not in main repo list, get it
            IFS=$'\3' read -r _ ver rel \
                < <(// delegate -- pkg_version "${repo_in_main##*/}" "" "" "${repo_in_main%/*}") > /dev/null ||
            // die 'pkg_version' "failed"
            // log "${pkg_name}" "$repo_in_main [$ver-$rel]"
            [ -n "${repo_in_main##*"${repo_archive}"*}" ] || // die '$repo_in_main' "$repo_in_main [$index_global]"
            repo_source="$repo_in_main"
            continue
        }

        # key matched/conflicts repos has different content with repo_source
        # Key conflicts and content does not match / inconsistency
        # First run
        repo_source="$(// delegate -- archive "$repo_archive" "$repo_in_main" "$repo_target" "$index_global")"
        [ -n "${repo_in_main##*"${repo_archive}"*}" ] || // die '$repo_in_main' "$repo_in_main [$index_global]"

        // log "${pkg_name} imported" "$repo_in_main [$ver-$rel]"
    done

    { [ -d "$repo_target" ] &&
    // identical "$repo_target" "$repo_source"; } || // die '$repo_target' "${repo_target:+"${repo_target} "}is invalid"
    # [ -n "${repo_source##*${sys_db}*}" ] || // die '$repo_source' "$repo_source is an unresolved orphan"

    # }

    # package repo is in other paths or just in sys_db
    # [ -z "${repo_source##*${REPO_MAIN}*}" ] || {
    // is_in_main "$repo_source" || {
        // log "$pkg_name imported" "$REPO_MAIN/extra/$pkg_name"
        rsync -aqz "$repo_target" "$REPO_MAIN/extra/"
        sync
        # package repo is in main repo
        repo_source="$REPO_MAIN/extra/$pkg_name"
    }

    is_in_main "$repo_source" || // die '$repo_source' "${repo_source:+"${repo_source} "}is weird imported"

    local repo_source_encoded="$(delegate -- encode "$repo_source" "REPO_MAIN" "$REPO_MAIN")"

    // log '$repo_source' "$repo_source"

    local index_key=0
    local version_list=

    IFS_ORIGIN=$IFS
    IFS=$(printf '%b' "\x03")
    [ ! -s "$repo_target/keys" ] ||
    while IFS=$' ' read -r ver rel repo; do
        null "$ver" || null "$rel" || null "$repo" ||
        { [ "$ver" = "$repo_ver" ] && [ "$rel" = "$repo_rel" ] && [ "$repo" = "$repo_source" ]; } ||
        [ -z "${version_list##*${ver}*${rel}*${repo}*}" ] || {
            length_trim "ver" "$LENGTH_VER"
            length_trim "rel" "$TABSTOP"
            local c2_origin="$c2"
            // log "$(printf "%-${TABSTOP}s %-${LENGTH_VER}s" "$index_key" "$ver")" "$(printf "%-${TABSTOP}s %-2s %s" "$rel" "" "$repo")"
            c2="$c2_origin"
            version_list="$version_list${ver} ${rel} ${repo}${IFS}"
        }
        : $((index_key += 1))
    done < "$repo_target/keys"
    # No \n at the end
    version_list="$version_list${repo_ver} ${repo_rel} ${repo_source_encoded}"
    : > "$repo_target/keys"
    for item in $version_list; do
        printf "%s\n" "$item" >> "$repo_target/keys"
    done
    IFS=$IFS_ORIGIN

    local tail_deep="$(// delegate -- valid_tail "$repo_target/keys")"
    [ -n "${tail_deep:+x}" ] || // die '$repo_target/keys' "keys file \"$repo_target/keys\" is empty"
    IFS=$' ' read -r _ver _rel _repo_source \
        < <(tail -n $tail_deep "$repo_target/keys" | grep "$repo_ver" | grep "$repo_rel") > /dev/null || {
        cat "$repo_target/keys"
        // die 'query current key' "failed"
    }
    [ "$_repo_source" == "$repo_source_encoded" ] || // die '$_repo_source' "$_repo_source"

    // density_output "$pkg_name" "$repo_target" "$repo_source" "0"
    // density_output "$pkg_name" "$repo_source" "$repo_source" "1"

    // log "$pkg_name" "installed successfully"
}

pkg_update() {
    _env
    // log "updating" "repositories"

    # Create a list of all repositories.
    # Intentional, globbing disabled.
    # shellcheck disable=2046,2086
    { IFS_ORIGIN=$IFS; IFS=:; set -- $KISS_PATH; IFS=$IFS_ORIGIN; }

    # Update each repository in '$KISS_PATH'.
    for repo do
        local repo_type
        if git -C "$repo" rev-parse 'HEAD@{upstream}' >/dev/null 2>&1; then
            repo_type=git

            # Get the Git repository root directory.
            local subm=$(git -C "$repo" rev-parse --show-superproject-working-tree)
            repo=$(git -C "${subm:-"$repo"}" rev-parse --show-toplevel)

        elif ! [ -d "$repo" ]; then
            continue
        else
            unset repo_type
        fi

        // pkg_update_repo $repo_type $repo
    done

    // pkg_upgrade
}

# $1 repo_type
# $2 repo
pkg_update_repo() {
    _env
    local repo_type=$1
    local repo=$2
    cd "$repo" || // die '$repo' "Repository '${repo:+"${repo} "}'inaccessible"

    local repos
    contains "$repos" "$PWD" || {
        repos="$repos $PWD"

        // log '$PWD' "$PWD"

        IFS=$'\3' read -r  pwd_user _  \
            < <(// am_owner "$PWD") > /dev/null ||
            // die 'am_owner' "failed"
        equ "pwd_user" "$(whoami)" || {
            // log 'needs "$user" to update to' "$pwd_user"
            local as_pwd_user="$(// delegate -- as_user "$pwd_user")"
            set -- $as_pwd_user
        }

        # arg1: pre-update
        # arg2: need su?
        # arg3: owner
        # env:  PWD is path to repository
        // run_hook pre-update "$#" "$user"

        case $repo_type in git)
            // pkg_update_git "$@"
        esac

        # arg1: post-update
        # env:  PWD is path to repository
        // run_hook post-update
    }
}

pkg_update_git() {
    _env
    # Display whether or not signature verification is enabled.
    case $(git config --get merge.verifySignatures) in true)
        // log 'signature verification" "enabled'
    esac

    "$@" git pull
    "$@" git submodule update --remote --init -f
}

pkg_upgrade() {
    _env

    local action="upgrade"

    // log "versions" "checking for new package"
    set +f

    local repo_orphans

    for pkg_name in "$sys_db/"*; do set -f
        // pkg_dirs "$action" "$pkg_name"
        IFS=$'\3' read -r repo_path ver_pre rel_pre \
            < <(// delegate -- pkg_version "${pkg_name##*/}" "" "" "$sys_db") \
            > /dev/null || // die 'pkg_version' "failed"

        IFS=$'\3' read -r repo_path repo_ver repo_rel \
            < <(// delegate -- pkg_version "${pkg_name##*/}") > /dev/null || // die 'pkg_version' "failed"

        # Detect repository orphans (installed packages with no
        # associated repository).
        case $repo_path in *"$REPO_ROOT/installed/"*)
            repo_orphans="$repo_orphans$newline${pkg_name##*/}"
        esac

        # Compare installed packages to repository packages.
        equ "$ver_pre-$rel_pre" "$repo_ver-$repo_rel" || {
            set -- "$@" "${pkg_name##*/}"

            // log "${pkg_name##*/}" "$ver_pre-$rel_pre => $repo_ver-$repo_rel"
        }
    done

    case $repo_orphans in *?*)
        // war "packages without repository" "$repo_orphans"
    esac

    build_install=0
    prefer_cache=1

    ! contains "$*" kiss || {
        // log "package manager update" "detected"
        // log "the package manager" "will be updated first"

        // prompt
        // build_all kiss

        // log "the package manager" "updated"
        // log "re-run 'kiss update'" "to update your system"
        return 0
    }

    for _ do
        IFS=$'\3' read -r order redro < <(// pkg_order "$@") > /dev/null ||
            // die 'pkg_order' "failed"

        # Intentional, globbing disabled.
        # shellcheck disable=2046,2086
        set -- $order

        // prompt "Packages to update ($#): $*"
        // build_all "$@"
        for repo_url in "$@"; do // pkg_install "$repo_url"; done
        // log "all packages" "updated"
        return 0
    done

    // log "nothing" "to do"
}

# $1 action
# $2 pkg_name_00
# $3 pkg_name_00
# ...
# Claen all? $@ might has multiple packages
clean_all() {
    _env
    # Clean up on exit or error. This removes everything related to the build.
    # If _KISS_LVL is (1) we are the top-level process - the entire cache will
    # be removed. If _KISS_LVL is any other value, remove only the tar directory.

    local action="$1"
    shift 1
    ! { [ "$action" == "pick" ] || [ "$action" == "p" ] ||
    [ "$action_of_session" == "pick" ] || [ "$action_of_session" == "p" ]; } || set -- "$1"
    for pkg_name in "$@"; do
        # https://stackoverflow.com/questions/32107041/how-to-check-if-a-string-only-contains-digits-numerical-characters
        # [ $(expr "x$pkg_name" : "x[0-9]*$") -gt 0 ] || continue
        // log '$action' "$action"
        // log '$pkg_name' "$pkg_name"
        [ -d "$proc_root" ] || // die '$proc_root' "$proc_root"
        // debug '$tar_dir' "$tar_dir"
        // debug '$KISS_DEBUG' "$KISS_DEBUG"
        // debug '$_KISS_LVL' "$_KISS_LVL"

        case $action in
            i|install)
                // log_permanent_all "$action" "$pkg_name"
        esac

        case ${KISS_DEBUG:-0}-${_KISS_LVL:-1} in
            0-1) null "$proc_root" || [ "$(standardize "$proc_root")" = "/proc" ] ||
                // pkg_clear "$action" "$pkg_name" ;;
            0-*) null "$tar_dir" || [ "$(// occurrences "$tar_dir" "/")" -eq "1" ] ||
                // / as "$kiss_root_user" find "$tar_dir/$pkg_name" -mindepth 1 -delete
        esac
    done
}

# $@ :
pkg_help_ext() {
    _env
    // debug '$#' "$#"
    // log "extensions (kiss-* in PATH)" "installed"

    # Intentional, globbing disabled.
    # shellcheck disable=2046,2030,2031
    set -- $(// delegate -- "pkg_find" kiss-\* all -x "$PATH")
    ok "$1" || // die 'kiss-*' "$1"

    local path_list
    # To align descriptions figure out which extension has the longest
    # name by doing a simple 'name > max ? name : max' on the basename
    # of the path with 'kiss-' stripped as well.
    #
    # This also removes any duplicates found in '$PATH', picking the
    # first match.
    for path do
        p=${path#*/kiss-}

        [ -d "$path" ] && continue
        case " $seen " in *" $p "*)
            shift
            continue
            ;;
            *) path_list="$path_list $path"
        esac

        seen=" $seen $p "
        max=$((${#p} > max ? ${#p}+1 : max))
    done
    // log '$#' "$#"
    set -- $path_list
    // log '$#' "$#"
    IFS_ORIGIN=$IFS
    IFS=\#$IFS

    # Print each extension, grab its description from the second line
    # in the file and align the output based on the above max.
    for path do
        # Open the extension as a file descriptor.
        exec 3< "$path"

        # Grab the second line in the extension.
        { read -r _ && IFS=\#$IFS read -r _ cmt; } <&3

        printf "%b->%b %-${max}s %s\\n" \
            "$c1" "$c3" "${path#*/kiss-}" "$cmt"
    done >&2
    IFS=$IFS_ORIGIN
}

trap_on() {
    # Catch errors and ensure that build files and directories are cleaned
    # up before we die. This occurs on 'Ctrl+C' as well as success and error.
    trap on_int INT TERM
    trap 'on_exit "$@"' EXIT
}

on_int() {
    // run_hook SIGINT
    exit 1
}

on_exit() {
    // clean_all "$@"
    // run_hook SIGEXIT
    // pipe_read_kill "$pid_log" &
    // pipe_read_kill "$pid_screen" &
    kill 0
}

trap_off() {
    # Block being able to abort the script with 'Ctrl+C'. Removes all risk of
    # the user aborting a package install/removal leaving an incomplete package
    # installed.
    trap "" INT EXIT
}

share_link() {
    _env
    [ "$#" -ge "6" ] || // die '$#' "input arguments $# less than 6"
    local body_root_name="$1"
    local anchor_root_name="$2"
    local parent_dir="$3"
    local src_user="$4"
    local cache_dir="$5"
    local anchor_folder="$6"

    / ": \"\${$body_root_name:=\"$parent_dir/$anchor_folder\"}\""
    # / "true \"\${$body_root_name:=\"$parent_dir/$anchor_folder\"}\""
    # / "$body_root_name=\"$parent_dir/$anchor_folder\""
    # local body_root_value="$(/ "printf '%s' \"\$$body_root_name\"")"
    / "local body_root_value=\$$body_root_name"
    #                   name            value
    // log "$body_root_name ->" "$body_root_value"
    [ "$body_root_value" == "$parent_dir/$anchor_folder" ] ||
    // die "$body_root_name" "$body_root_value"

    [ -d "$body_root_value" ] ||
        // / as $src_user /usr/bin/mkdir -p "$body_root_value"

    / "$anchor_root_name=\"$cache_dir/$anchor_folder\""
    # local anchor_root_value="$(/ "printf '%s' \"\$$anchor_root_name\"")"
    / "local anchor_root_value=\$$anchor_root_name"
    #                   name            value
    // log "$anchor_root_name <-" "$anchor_root_value"
    [ "$anchor_root_value" == "$cache_dir/$anchor_folder" ] ||
    // die "$anchor_root_name" "$anchor_root_value"

    { [ -L "$anchor_root_value" ] &&
        [ "$body_root_value" = "$(readlink -f "$anchor_root_value")" ]; } || {
            [ ! -d "$anchor_root_value" ] || [ -L "$anchor_root_value" ] || {
                [ "$(stat -c '%U' "$anchor_root_value")" == "$src_user" ] ||
                // / as "root" /usr/bin/chown -R $src_user:users "$anchor_root_value"
                // / as $src_user /usr/bin/rsync -aqz "$anchor_root_value/." "$body_root_value/"
                sync
            }
            // / as "root" /usr/bin/rm -rf "$anchor_root_value"
            ln -sf "$body_root_value" "$anchor_root_value"
        }
    / "$anchor_root_name=\"$body_root_value\""
}

# package is git or not
pkg_format() {
    _env
    local pkg_name
    local repo_path
    local repo_url="$1"
    // debug '$repo_url' "$repo_url"
    IFS=$'\x03' read -r pkg_name _ repo_path < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"
    local format

    [ "$scope" != "source_route" ] || { printf '\n%s' ""; return 0; }

    while read -r src_url dest || ok "${src_url%%\#*}"; do
        ok "${src_url%%\#*}" || continue

        null "${src_url##*"${pkg_name}"*}" || continue

        // debug '$src_url' "$src_url"
        // debug '$dest' "$dest"
        __
        IFS=$'\3' read -r _res _des_dir real_url \
            < <(// source_route "$pkg_name" "$src_url" "$dest") > /dev/null ||
        // die "source_route" "failed"
        ^^
        // debug '$_res' "$_res"
        // debug '$_des_dir' "$_des_dir"

        # '$2' is set when this function is called from 'kiss c' and it is used
        # here to skip calling the Git code.
        local _res_purified="${_res##"${_res%%+*}+"}"
        // debug '$_res_purified' "$_res_purified"
        case $_res in
            "url+"*) format="${_res##*.}";;
            "git+"*) format="git";;
            *) format="${_res##*.}";;
        esac
        break
    done < "$repo_path/sources"

    // debug '$format' "$format"

    printf "\n%s" "$format"
}

repo_resolve() {
    _env
    local pkg_name
    local repo_url="$1"
    // debug '$repo_url' "$repo_url"
    local search_dir="$2"
    // debug '$search_dir' "$search_dir"
    repo_url=$(standardize $repo_url)
    pkg_name="${repo_url##*/}"
    // debug '$pkg_name' "$pkg_name"

    [ "$scope" != "pkg_find" ] || { printf '%s\x03%s\x03%s\n' "$pkg_name" "" ""; return 0; }

    local repo_dir
    local repo_path

    [ -n "${repo_url##*"/"*}" ] || [ ! -d "${repo_url}" ] ||
    [ ! -f "$repo_url/version" ] ||
    [ ! -f "$repo_url/build" ] ||
    [ ! -f "$repo_url/sources" ] ||
    {
        repo_dir="${repo_url%/*}"
        repo_path="$repo_url"
        printf '%s\x03%s\x03%s\n' "$pkg_name" "$repo_dir" "$repo_path"
        return 0
    }

    [ -n "${repo_dir:+x}" ] ||
    null "$search_dir" || {
        [ -z "${search_dir##*:*}" ] ||
        [ ! -d "$search_dir/$pkg_name" ] || {
            repo_dir="$search_dir"
            repo_path="$repo_dir/$pkg_name"
            printf '%s\x03%s\x03%s\n' "$pkg_name" "$repo_dir" "$repo_path"
            return 0
        }

        [ -n "${repo_dir:+x}" ] || {
            # pkg_find will search $sys_db also
            repo_path="$(// delegate -- "pkg_find" "$pkg_name" "" "-d" "$search_dir")"
            repo_dir="${repo_path%/*}"
            printf '%s\x03%s\x03%s\n' "$pkg_name" "$repo_dir" "$repo_path"
            return 0
        }
    }

        # [ -n "${repo_dir:+x}" ] ||
        # [ -z "${REPO_DIR:+x}" ] ||
        # [ ! -d "$REPO_DIR/$pkg_name" ] || {
        #     // debug '$REPO_DIR' "$REPO_DIR"
        #     repo_dir="$REPO_DIR"
        # }

        # [ -n "${repo_dir:+x}" ] ||
        # [ -z "${KISS_PATH##*:*}" ] ||
        # [ ! -d "$KISS_PATH/$pkg_name" ] || {
        #     // debug '$KISS_PATH' "$KISS_PATH"
        #     repo_dir="$KISS_PATH"
        # }

    [ -n "${repo_dir:+x}" ] || {
        # pkg_find will search $sys_db also
        repo_path="$(// delegate -- "pkg_find" "$pkg_name" "" "-d" "$KISS_PATH")"
        repo_dir="${repo_path%/*}"
        printf '%s\x03%s\x03%s\n' "$pkg_name" "$repo_dir" "$repo_path"
        return 0
    }

    [ -z "${repo_dir:+x}" ] ||
    [ -n "${repo_path:+x}" ] || repo_path="$repo_dir/$pkg_name"

    // debug '$repo_dir' "$repo_dir"
    // debug '$repo_path' "$repo_path"

    printf '%s\x03%s\x03%s\n' "$pkg_name" "$repo_dir" "$repo_path"
}

# Pay attention to name override
repo_resolve_no_subshell() {
    _env
    [ "$1" == "_" ] || [ -z "$1" ] || local pkg_name_name="${1#*" "}"
    local repo_url="$2"
    // debug '$repo_url' "$repo_url"

    repo_url=$(standardize $repo_url)
    local pkg_name_value="${repo_url##*/}"
    # // log '$pkg_name_value' "$pkg_name_value"
    [ -z "${pkg_name_name:+x}" ] || {
        / "$pkg_name_name=\"$pkg_name_value\""
        / debug "$pkg_name_name" "\"\$$pkg_name_name\""
    }

    [ "$scope" != "pkg_find" ] || return 0

    [ "$3" == "_" ] || [ -z "$3" ] || local repo_dir_name="$3"
    [ "$4" == "_" ] || [ -z "$4" ] || local repo_path_name="$4"

    [ -n "${repo_dir_name:+x}" ] || [ -n "${repo_path_name:+x}" ] || return 0

    [ -z "${repo_dir_name:+x}" ] ||
    / "local repo_dir_value=\"\$$repo_dir_name\""
    [ -z "${repo_path_name:+x}" ] ||
    / "local repo_path_value=\"\$$repo_path_name\""

    if [ -z "${repo_url##*"/"*}" ] && [ -d "${repo_url}" ]; then
        { [ -z "${repo_dir_name:+x}" ] && [ -z "${repo_path_name:+x}" ]; } || local repo_dir_value="${repo_url%/*}"
        [ -z "${repo_path_name:+x}" ] || local repo_path_value="$repo_url"
    else
        { [ -z "${repo_dir_name:+x}" ] && [ -z "${repo_path_name:+x}" ]; } || {

            # [ -n "${repo_dir_value:+x}" ] ||
            # [ -z "${REPO_DIR:+x}" ] || {
            #     // log '$REPO_DIR' "$REPO_DIR"
            #     local repo_dir_value="$REPO_DIR"
            # }

            # [ -n "${repo_dir_value:+x}" ] ||
            # [ -z "${KISS_PATH##*:*}" ] ||
            # [ ! -d "$KISS_PATH/$pkg_name_value" ] || {
            #     // log '$KISS_PATH' "$KISS_PATH"
            #     local repo_dir_value="$KISS_PATH"
            # }

            [ -n "${repo_dir_value:+x}" ] || {
                // repo_path_value="$(delegate -- "pkg_find" "$pkg_name_value" "" "-d" "$KISS_PATH")"
                local repo_dir_value="${repo_path_value%/*}"
            }
        }
        [ -z "${repo_path_name:+x}" ] || local repo_path_value="$repo_dir_value/$pkg_name_value"
    fi
    [ -z "${repo_dir_name:+x}" ] || {
        // log '$repo_dir_value' "$repo_dir_value"
        / "$repo_dir_name=\"$repo_dir_value\""
    }
    [ -z "${repo_path_name:+x}" ] || {
        // log '$repo_path_value' "$repo_path_value"
        / "$repo_path_name=\"$repo_path_value\""
    }
}

pipe_read() {
    _env
    [ "$#" -ge "3" ] || // die '$#' "$# parameters are not enough"
    # local log_dir_user="$1"
    # shift 1
    local lock="$1"
    local target="$2"
    local pipe="$3"
    # set --
    # [ "$log_dir_user" == "$(whoami)" ] || set -- $(// delegate -- as_user "$log_dir_user")
    # // bog "$log_output" '$@' "$(esceval "$@")"
    local pipe_user="$(stat -c '%U' "$pipe")"
    [ "$pipe_user" == "$(whoami)" ] || // war "$pipe_user owns" "$pipe"
    [ -p "$pipe" ] || // die '$pipe' "$pipe is not ready"
    while :; do
        # [ -p "$pipe" ] || mkfifo -m 644 "$pipe" || // die '$pipe' "$pipe"
        [ ! -e "$pipe" ] ||
        while IFS= read -r content; do
            # [ -z "$content" ] || $@ flock -x "$lock" -c "$($@ printf '%s\n' "$content" >> "$target")"
            [ -z "$content" ] || {
                flock -x "$lock" -c "$(printf '%s\n' "$content" >> "$target")"
                [ -n "${content##*"ERROR"*}" ] || {
                    printf '%s\n' "$content" > /dev/stderr
                    printf '%s\n' "$content" | sed $'s,\x1b\\[[0-9;]*[a-zA-Z],,g' 2>&1 >> "$log_output"
                    kill 0
                }
            }
        done < "$pipe" || // die "$pipe" "reading failed"
    done
}

log_address() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }

    # Neither the log folder nor the file is created at this moment. So don't use log functions
    [ -n "${KISS_TMPDIR:+x}" ] || KISS_TMPDIR="/tmp/${HOME:1}/kiss"
    [ -d "$KISS_TMPDIR" ] || mkdir -p "$KISS_TMPDIR"

    # The log folder is created
    [ -n "${KISS_TMPDIR:+x}" ] || KISS_TMPDIR="/tmp/${HOME:1}/kiss"
    log_dir="$KISS_TMPDIR/logs"
    [ -d "$log_dir" ] || mkdir -p "$log_dir"
    log_output="$log_dir/build.log"
    [ -f "$log_output" ] || touch "$log_output"

    log_dir_user="$(stat -c '%U' "$log_dir")"

    if [ -n "${LOG_DIR:+x}" ]; then
        LOG_DIR_USER="$(stat -c '%U' "$LOG_DIR")"
        [ "$LOG_DIR_USER" == "$(whoami)" ] ||
        [ "$LOG_DIR" == "$log_dir" ] ||
        flock -x "$KISS_TMPDIR/logs/.lock" -c "$(\cp -f "$LOG_DIR/build.log" "$log_dir/")" &
    else
        : > "$log_output" 2>/dev/null
    fi

    # // bog "$log_output" '$log_dir_user' "$log_dir_user"
    // bog "$log_output" '$(whoami)' "$(whoami)"
    // bog "$log_output" '$LOGNAME' "$LOGNAME"

    log_pipe="$log_dir/log.pipe"
    pipe_lock_log="$log_dir/.lock_log"
    screen_pipe="$log_dir/screen.pipe"
    pipe_lock_screen="$log_dir/.lock_screen"
    lock_file="$log_dir/.lock"
    lock_print="$log_dir/.lock_print"
    # set --
    # [ "$log_dir_user" == "$(whoami)" ] || set -- $(// delegate -- as_user "$log_dir_user")
    # // bog "$log_output" '$@' "$(esceval "$@")"
    [ ! -e "$log_pipe" ] || rm -f -- "$log_pipe"
    [ ! -e "$screen_pipe" ] || rm -f -- "$screen_pipe"
    [ -p "$log_pipe" ] || mkfifo -m 644 "$log_pipe" || // die '$log_pipe' "$log_pipe"
    [ -p "$screen_pipe" ] || mkfifo -m 644 "$screen_pipe" || // die '$screen_pipe' "$screen_pipe"

    # [ -n "${PID_SCREEN:+x}" ] || {
        # // pipe_read "$log_dir_user" "$lock_print" "/dev/stderr" "$screen_pipe" &
        // pipe_read "$lock_print" "/dev/stderr" "$screen_pipe" &
        pid_screen=$!
    # }
    // bog "$log_output" '$pid_screen' "$pid_screen"
    # [ -n "${PID_LOG:+x}" ] || {
        # // pipe_read "$log_dir_user" "$lock_file" "$log_output" "$log_pipe" &
        // pipe_read "$lock_file" "$log_output" "$log_pipe" &
        pid_log=$!
    # }
    // bog "$log_output" '$pid_log' "$pid_log"
}


init_dirs() {
    local level=-1
    [ "$level" -eq "-1" ] || { _env; }
    local ppwd="$1"
    shift 1

    : "${KISS_SRC_ROOT:?kiss requires KISS_SRC_ROOT be set (prefer to a normal users share folder)}"
    KISS_SRC_ROOT="$(standardize "$KISS_SRC_ROOT")"
    [ -d "$KISS_SRC_ROOT" ] || {
        local ksr_parent="${KISS_SRC_ROOT%/*}"
        [ "$ksr_parent" != "/" ] || ksr_parent="/"
        as_own "$ksr_parent" mkdir -p "$KISS_SRC_ROOT"
    }
    [ -n "${src_user:+x}" ] ||
    src_user="$(stat -c '%U' "$(readlink -f "$KISS_SRC_ROOT")")"


    proc_volatile="$KISS_TMPDIR/proc"
    [ -d "$proc_volatile" ] || mkdir -p "$proc_volatile"

    // hint 'New session' "started"

    # __ 'New session' "started"
    # // _ 'New session' "started"
    # // $'_ \'New session\' "started"'
    # // _ 'New session' "started
    # Works
    # // _ 'New session' "started"

    # Works
    # // _ 'New session' "started"
    # __ 'New session' "started"
    # Works
    # // _ 'New session' "started"

    # Root directory standardization
    KISS_ROOT=${KISS_ROOT%"${KISS_ROOT##*[!/]}"}
    [ -n "${kiss_root_user:+x}" ] ||
    IFS=$'\3' read -r  kiss_root_user _ \
        < <(// am_owner "$KISS_ROOT/") > /dev/null || // die 'am_owner' "failed"
    # This allows for automatic setup of a KISS chroot and will
    # do nothing on a normal system.
    [ -d "$KISS_ROOT/" ] ||
    // / as $kiss_root_user /usr/bin/mkdir -p "$KISS_ROOT/" 2>/dev/null || :

    # System package database.
    [ -n "${REPO_ROOT:+x}" ] || REPO_ROOT="/var/db/kiss"
    [ -d "$REPO_ROOT" ] || // die '$REPO_ROOT' "does not exist"
    sys_db=$KISS_ROOT/${db:="${REPO_ROOT#*/}/installed"}
    sys_ch=$KISS_ROOT/${cho_db:="${REPO_ROOT#*/}/choices"}
    // log '$db' "$db"
    // log '$cho_db' "$cho_db"

    [ -n "${REPO_MAIN:+x}" ] || [ "$action" != "i" ] || [ "$action" != "install" ] ||
    // die '$REPO_MAIN' "for reverse copying sys_db/repo to the main repo"

    # Top-level cache directory.
    cache_dir=${XDG_CACHE_HOME:-"${HOME%"${HOME##*[!/]}"}/.cache"}
    cache_dir=${cache_dir%"${cache_dir##*[!/]}"}/kiss
    [ -d "$cache_dir" ] || mkdir -p "$cache_dir"

    # : "${share_src:="$KISS_SRC_ROOT/sources"}"
    // share_link "share_src" "src_dir" "$KISS_SRC_ROOT" "$src_user" "$cache_dir" "sources"

    # src_dir_user="$(stat -c '%U' "$(readlink -f "${src_dir}")")"

    # : "${share_proc:="$KISS_SRC_ROOT/proc"}"
    // share_link "share_proc" "proc_root" "$KISS_SRC_ROOT" "$src_user" "$cache_dir" "proc"

    # : "${share_archive:="$KISS_SRC_ROOT/archive"}"
    // share_link "share_archive" "archive_path" "$KISS_SRC_ROOT" "$src_user" "$cache_dir" "archive"


    // log '$(whoami)' "$(whoami)"
    // log '$LOGNAME' "$LOGNAME"
    // log '$KISS_SRC_ROOT' "$KISS_SRC_ROOT"
    // log '$KISS_ROOT/' "$KISS_ROOT/"
    // log '$src_user' "$src_user"
    // log '$kiss_root_user' "$kiss_root_user"
    // log '$time' "$time"
    // log '$sys_db' "$sys_db"
    // log '$proc_volatile' "$proc_volatile"
}

pkg_clear() {
    _env

    local action="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"

    [ ! -d "$make_dir/$pkg_name" ] || [ "$make_dir" = "/make" ] ||
    find "$make_dir/$pkg_name" -mindepth 1 -delete
    [ ! -d "$tmp_dir/$pkg_name" ] || [ "$tmp_dir" = "/tmp" ] ||
    // / as "$kiss_root_user" find "$tmp_dir/$pkg_name" -mindepth 1 -delete

    [ "pick" == "$action" ] || [ "p" == "$action" ] ||
    [ "install" == "$action" ] || [ "i" == "$action" ] || {
        [ ! -d "$pkg_dir/$pkg_name" ] || [ "$pkg_dir" = "/pkg" ] ||
        // / as "$kiss_root_user" find "$pkg_dir/$pkg_name" -mindepth 1 -delete
        [ ! -d "$tar_dir/$pkg_name" ] || [ "$tar_dir" = "/extract" ] ||
        // / as "$kiss_root_user" find "$tar_dir/$pkg_name" -mindepth 1 -delete
    }

    # For pick_up to do a series of operations, we don't delete the results
    # tar_file in $bin_dir/$pkg_name mean building succeeded
    # [ ! -d "$bin_dir/$pkg_name" ] || [ "$bin_dir" = "/bin" ] || find "$bin_dir/$pkg_name" -mindepth 1 -delete

    # [ "$src_dir/$pkg_name" = "/$pkg_name" ]    || find "$src_dir/$pkg_name"  -mindepth 1 -delete

    # [ ! -d "${KISS_TMPDIR}/proc" ] ||
    # for item in $(\ls -x "${KISS_TMPDIR}/proc"); do [ "$item" = "$pkg_name" ] || \rm -rf "${KISS_TMPDIR}/proc/$item"; done
}

transfer() {
    _env
    target_dir="$1"
    root_dir_user="$2"
    target_dir_user="$3"
    root_dir_group="$4"

    // / as "$target_dir_user" chown -R $root_dir_user:$root_dir_group "${target_dir}" > /dev/null 2>&1 ||
    // / as "$root_dir_user" chown -R $root_dir_user:$root_dir_group "${target_dir}" > /dev/null 2>&1 ||
    # Hard code root is not good
    // / as "$kiss_root_user" chown -R $root_dir_user:$root_dir_group "${target_dir}" > /dev/null 2>&1 ||
    // die "chown ${target_dir}" "failed"
}

# maintain ownership
ownership() {
    _env
    local root_dir="$1"
    [ ! -L "$root_dir" ] || root_dir="$(readlink -f "$root_dir")"
    local target_dir="$2"
    [ ! -L "$target_dir" ] || target_dir="$(readlink -f "$target_dir")"
    shift $#
    IFS=$'\3' read -r root_dir_user root_dir_group \
        < <(// am_owner "$root_dir") > /dev/null ||
        // die 'am_owner' "failed"

    // debug '$root_dir' "$root_dir"
    // debug '$target_dir' "$target_dir"
    // debug '$root_dir_user' "$root_dir_user"

    if [ -d "$target_dir" ]; then
        IFS=$'\3' read -r target_dir_user target_dir_group \
            < <(// am_owner "$target_dir") > /dev/null ||
        // die 'am_owner' "failed"

        { equ "$target_dir_user" "$root_dir_user" && equ "$target_dir_group" "$root_dir_group"; } || {
            if equ "$target_dir_user" "$root_dir_user"; then
                // / as "$target_dir_user" chgrp -R $root_dir_group "${target_dir}" > /dev/null 2>&1 ||
                // / as "$root_dir_user" chgrp -R $root_dir_group "${target_dir}" > /dev/null 2>&1 ||
                # Hard code root is not good
                // / as "$kiss_root_user" chgrp -R $root_dir_group "${target_dir}" > /dev/null 2>&1 ||
                // die "chgrp ${target_dir}" "failed"
            else
                // transfer "${target_dir}" "$root_dir_user" "$target_dir_user" "$root_dir_group"
            fi
        }

        # File name might have spaces
        local found_folder_onwership_issue=0
        local item_user
        IFS_ORIGIN=$IFS
        IFS=$'\n'
        local index=0
        for item in $(find "${target_dir}" -name "*"); do
            [ "$index" -le 10 ] || break
            [ -f "$item" ] || continue
            item_user="$(stat -c '%U' "$item")"
            [ "$item_user" != "$root_dir_user" ] || { : $((index += 1)); continue; }

            // log '$item' "$item"
            // log '$item_user' "$item_user"
            found_folder_onwership_issue=1
            break
        done
        IFS=$IFS_ORIGIN
        # Won't work inside for loop with special $IFS
        [ "$found_folder_onwership_issue" -eq "0" ] ||
        // transfer "${target_dir}" "$root_dir_user" "$item_user" "$root_dir_group"
    else
        // / as "$root_dir_user" mkdir -p "$target_dir"
    fi
}

# make or point to pkg_name related dirs
# $1 repo_url : package repo url/uri
pkg_dirs() {
    _env

    local action="$1"
    local repo_url="$2"
    local pkg_name
    IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
        > /dev/null || // die 'repo_resolve' "failed"

    [ -n "${src_user:+x}" ] ||
    IFS=$'\3' read -r  src_user _ \
        < <(// am_owner "$KISS_SRC_ROOT") > /dev/null ||
    // die 'am_owner' "failed"

    // debug '$pkg_name' "$pkg_name"
    {
        ok "$log_dir" || // die '$log_dir' "${log_dir:+"${log_dir} "} is not defined"

        local as_src_user="$(// delegate -- as_user "$src_user")"
        [ ! -L "$proc_root" ] || proc_root="$(readlink -f "$proc_root")"

        # Temporary cache directories.
        make_dir="$proc_volatile/make"
        tmp_dir="$proc_volatile/tmp"
        # log_dir="$proc_volatile/logs"

        pkg_dir="$proc_root/pkg"
        tar_dir="$proc_root/extract"
        bin_dir="$proc_root/bin"


        # set +e will bypass the following line and without exit
        # [ -d "${proc_root}" ] && equ "reset" "$2" && \rm -rf "$proc_root" && exit 1

        # Using 'as $some_dir_to_be_made_user' of 'as_owner "$some_dir_to_be_made"' all will fail because they pick up
        # the new $some_dir_to_be_made to display content. But that location does not exist yet
        mkdir -p \
            "$make_dir" \
            "$tmp_dir"

            # "$log_dir" \

        $as_src_user mkdir -p \
            "$pkg_dir" \
            "$tar_dir" \
            "$bin_dir"

        [ ! -d "${proc_root}" ] || [ -z "${pkg_name:+x}" ] || {
            // ownership "$pkg_dir" "$pkg_dir/$pkg_name"
            // ownership "$tar_dir" "$tar_dir/$pkg_name"
            // ownership "$bin_dir" "$bin_dir/$pkg_name"
            // ownership "$src_dir" "$src_dir/$pkg_name"
            // ownership "$archive_path" "$archive_path/$pkg_name"

            // pkg_clear "$action" "$pkg_name"

            mkdir -p \
                "$tmp_dir/$pkg_name" \
                "$make_dir/$pkg_name"
            # // die '$pkg_dir/$pkg_name' "$pkg_dir/$pkg_name"
            # // die '$as_src_user' "$as_src_user"
            / $as_src_user mkdir -p \
                "$pkg_dir/$pkg_name" \
                "$tar_dir/$pkg_name" \
                "$bin_dir/$pkg_name"

        }

        // log '$log_dir' "$log_dir"
    }

    # Naming convention:
    # directory path
    # directory name
    #           folder (name)


    // log '$make_dir' "$make_dir"
    // log '$tmp_dir' "$tmp_dir"
    // log '$pkg_dir' "$pkg_dir"
    // log '$tar_dir' "$tar_dir"
    // log '$bin_dir' "$bin_dir"
    // log '$src_dir' "$src_dir"
    // log '$archive_path' "$archive_path"

    # printf "%s" "$proc_root"
}

log_permanent_all() {
    _env
    local action="$1"
    // debug '$action' "$action"
    shift 1
    ! { [ "$action" == "pick" ] || [ "$action" == "p" ] ||
    [ "$action_of_session" == "pick" ] || [ "$action_of_session" == "p" ]; } || set -- "$1"
    [ "$#" -ge "1" ] || return 0    # // die "package based log not available"
    // debug '$log_dir' "$log_dir"
    local cache_dir_user="$(stat -c '%U' "$cache_dir")"
    local as_cache_user="$(// delegate -- as_user "$cache_dir_user")"
    equ "$cache_dir_user" "$(whoami)" || {
        // log '$(whoami)' "$(whoami)"
        // log '$LOGNAME' "$LOGNAME"
        // log '$cache_dir_user' "$cache_dir_user"
        // log '$as_cache_user' "$as_cache_user"
    }
    # // log '$log_output' "$log_output"
    # [ ! -f "$log_output" ] ||
    # // log "user of $log_output" "$(stat -c '%U' "$log_output")"
    for pkg_name in "$@"; do
        // log '$pkg_name' "$pkg_name"

        local log_dir_package="$cache_dir/logs/$pkg_name"

        [ -d "$log_dir_package" ] ||
        $as_cache_user mkdir -p "$log_dir_package"

        local log_permanent="$log_dir_package/build.log"
        $as_cache_user touch "$log_permanent"
        [ -f "$log_output" ] || continue
        // debug '$log_dir_package' "$log_dir_package"
        local find_tip="find log at"

        local tail_deep="$(// delegate -- valid_tail "$log_output")"
        [ -z "${tail_deep:+x}" ] ||
            IFS=$' ' read -r _ tip_check _ _ address < <(tail -n $tail_deep "$log_output") \
                > /dev/null || // die "tail -n $tail_deep \"$log_output\"" "failed"

        # // log '$find_tip_check' "$find_tip_check"
        # // log '$address' "$address"

        [ "$tip_check" != "find" ] ||
        [ "$log_permanent" != "$address" ] || continue
        # // log "user of $log_permanent" "$(stat -c '%U' "$log_permanent")"
        // log "$find_tip" "$log_permanent"
        # // log "user of $log_output" "$(stat -c '%U' "$log_output")"
        # https://man7.org/linux/man-pages/man1/flock.1.html
        # https://unix.stackexchange.com/questions/184259/how-to-use-flock-and-file-descriptors-to-lock-a-file-and-write-to-the-locked-fil
        # https://stackoverflow.com/questions/67351646/what-does-flock-u-actually-do

        $as_cache_user 9>$log_dir_package/.lock 2>&1 |
        $as_cache_user 9>&- flock -x "$log_dir_package/.lock" -c "$($as_cache_user cp -f "$log_output" "$log_dir_package/")" & pig_list="${pig_list:+"${pig_list} "}$!"

        # Works, too
        # https://unix.stackexchange.com/questions/388026/flock-doesnt-seem-to-be-working
        # flock -x "$log_dir_package/.lock" -c "$(\cp -f "$log_output" "$log_dir_package/")" &

        # sleep 0.01

        # break the lock during flock -x running
        # flock -u 9
        # flock -u "$log_dir_package/.lock"
    done
    log_permanent_all_done=1
}

pipe_read_kill() {
    local pid_pipe="$1"
    while :; do
        # ! { kill -0 "$pid_pipe" && kill "$pid_pipe"; } \
        ! kill -9 "$pid_pipe" \
            > /dev/null 2>&1 | grep -q "No such process \"$pid_pipe\"" && break || sleep 1
    done
}

subshell_all() {
    _env
    local action="$1"
    shift 1

    // log '$#' "$#"
    // log '$_KISS_LVL' "$_KISS_LVL"

    // pipe_read_kill "$pid_log" &
    pig_list="${pig_list:+"${pig_list} "}$!"
    // pipe_read_kill "$pid_screen" &
    pig_list="${pig_list:+"${pig_list} "}$!"

    trap_off
    local index=0
    # {} | tee -a "$log_output" will disable colors
    # {
    for repo_url do
        repo_url="${repo_url%@*}"
        local pkg_name
        IFS=$'\x03' read -r pkg_name _ _ < <(// repo_resolve "$repo_url") \
            > /dev/null || // die 'repo_resolve' "failed"
        // bog "$log_output" '$index' "$index"
        // bog "$log_output" '$0' "$0"
        // bog "$log_output" '$action' "$action"
        // bog "$log_output" '$pkg_name' "$pkg_name"

            # HOME="$HOME" \
            # LOGNAME="$(whoami)" \
            # XDG_CACHE_HOME="$XDG_CACHE_HOME" \
        $(// delegate -- as_user "$kiss_root_user") \
            env \
            RUSTFLAGS="--remap-path-prefix=${PWD=.} ${RUSTFLAGS}" \
            KISS_XHOST_ARCH="$KISS_XHOST_ARCH" \
            KISS_XBUILD_ARCH="$KISS_XHOST_ARCH" \
            CHOST="${KISS_XHOST_TRIPLE}" \
            CBUILD="${KISS_XBUILD_TRIPLE}" \
            KISS_XHOST_ABI="$KISS_XHOST_ABI" \
            KISS_XBUILD_ABI="$KISS_XBUILD_ABI" \
            KISS_XHOST_TRIPLE="$KISS_XHOST_ARCH-linux-$KISS_XHOST_ABI" \
            KISS_XBUILD_TRIPLE="$KISS_XBUILD_ARCH-linux-$KISS_XBUILD_ABI" \
            KISS_SRC_ROOT="$KISS_SRC_ROOT" \
            KISS_COMPRESS="$KISS_COMPRESS" \
            KISS_PATH="$KISS_PATH" \
            KISS_FORCE="$KISS_FORCE" \
            KISS_ROOT="$KISS_ROOT" \
            KISS_CHOICE="$KISS_CHOICE" \
            KISS_COLOR="$KISS_COLOR" \
            KISS_TMPDIR="$KISS_TMPDIR" \
            REPO_MAIN="$REPO_MAIN" \
            KISS_PID="$KISS_PID" \
            _KISS_LVL="$_KISS_LVL" \
            SRC_DIR="$src_dir" \
            LOG_DIR="$log_dir" \
            MAKE_DIR="$make_dir" \
            DESTDIR="$pkg_dir/$pkg_name" \
            "$0" "$action" "$pkg_name" 2>&1 || {
            // log '$index' "$index"
            // log '$0' "$0"
            // log '$action' "$action"
            // log '$pkg_name' "$pkg_name"
            // log "$pkg_name" "install failed"
            // log_permanent_all "$action" "$pkg_name"

            kill 0
        }
        : $((index += 1))
    done
    # } | tee -a "$log_output"
    trap_on "$action" "$@"
}

args() {
    _env
    # Parse script arguments manually. This is rather easy to do in our case
    # since the first argument is always an "action" and the arguments that
    # follow are all package names.
    action="$1"
    // log '$action' "$action"

    shift "$(($# != 0))"

    # Ensure that arguments do not contain invalid characters. Wildcards can
    # not be used here as they would conflict with kiss extensions.
    case $action in
        a|alternatives)
            case $1 in *\**|*\!*|*\[*|*\ *|*\]*|*/*|*"$newline"*)
                // die 'Invalid argument' "'!*[ ]/\\n' ($1)"
            esac
        ;;

        b|build|c|checksum|d|download|i|install|l|list|r|remove)
            for _arg do case ${action%%"${action#?}"}-$_arg in
                i-*\!*|i-*\**|i-*\[*|i-*\ *|i-*\]*|i-*"$newline"*)
                    // die 'Invalid argument' "'!*[ ]\\n' ('$_arg')"
                    ;;

                [!i]-*\!*|[!i]-*\**|[!i]-*\[*|[!i]-*\ *|\
                [!i]-*\]*|[!i]-*/*|[!i]-*"$newline"*)
                    // die "Might be wrong usage of argument '!*[ ]/\\n' ('$_arg')." "Use a package name, please."
                    ;;
            esac done

            # When no arguments are given on the command-line, use the basename
            # of the current directory as the package name and add the parent
            # directory to the running process' KISS_PATH.
            case ${action%%"${action#?}"}-$# in [!l]-0)
                export KISS_PATH=${PWD%/*}:$KISS_PATH
                set -- "${PWD##*/}"
            esac

            # Search the installed database first when removing packages. Dependency
            # files may differ when repositories change. Removal is not dependent on
            # the state of the repository.
            case $action in r|remove)
                export KISS_PATH=$sys_db:$KISS_PATH
            esac

            # Order the argument list based on dependence.
            IFS=$'\3' read -r order redro < <(// pkg_order "$@") \
                > /dev/null || // die 'pkg_order' "failed"
            for pkg_name in $order; do
                // pkg_dirs "$action" "$pkg_name"
            done
            # Intentional, globbing disabled.
            # shellcheck disable=2046,2086
            set -- $order
    esac

    # Need to increment _KISS_LVL here to ensure we don't wipe the cache
    # early by non-asroot invocations.
    export _KISS_LVL=$((_KISS_LVL + 1))

    # Rerun the script as root with a fixed environment if needed. We sadly
    # can't run singular functions as root so this is needed.
    #
    # Intended behavior.
    # shellcheck disable=2030,2031

    // log '$KISS_FORCE' "$KISS_FORCE"
    case $action in a|alternatives|i|install|r|remove)
        [ -n "${kiss_root_user:+x}" ] ||
        IFS=$'\3' read -r  kiss_root_user _ \
            < <(// am_owner "$KISS_ROOT/") > /dev/null || // die 'am_owner' "failed"

        null "$action" || equ "$(whoami)" "$kiss_root_user" || {
            // subshell_all "$action" "$@"
            return
        }
    esac

    # Clear temporary files

    # This will cancell the process on busybox 1.35.0-2, when test if variables have definition
    # and set -e
    # [ -z "$KISS_DEBUG" ] || // log '$KISS_DEBUG' "$KISS_DEBUG"
    # null "$KISS_DEBUG" || // log '$KISS_DEBUG' "$KISS_DEBUG"
    # This will recover the process
    # [ -z "$KISS_DEBUG" ] || {
    # :
    # // log '$KISS_DEBUG' "$KISS_DEBUG"
    # }
    [ -z ${KISS_DEBUG+x} ] || // log "$KISS_DEBUG" "$LINENO"

    # Actions can be abbreviated to their first letter. This saves keystrokes
    # once you memorize the commands.
    case $action in
        a|alternatives) // pkg_alternatives "$@" ;;
        b|build)        // build_all "$@" ;;
        c|checksum)     for pkg_name do // checksum "$pkg_name"; done ;;
        d|download)     for pkg_name do // pkg_download "$pkg_name"; done ;;
        H|help-ext)     // pkg_help_ext "$@" ;;
        i|install)      for repo_url do // pkg_install "$repo_url"; done ;;
        l|list)         // list_version "$@" ;;
        p|pick)         // pick_up "$1" "$2" ;;
        r|remove)       for pkg_name in $redro; do // pkg_remove "$pkg_name"; done ;;
        s|search)
            for pkg_name; do
                for item in $(// delegate -- "pkg_find" "$pkg_name" all -d); do
                    // log "$pkg_name" "$item"
                done; done ;;
        u|update)       // pkg_update ;;
        U|upgrade)      // pkg_upgrade ;;
        v|version)      // version_installed $1 ;;
        '')
            // log 'kiss [a|b|c|d|i|l|r|s|u|U|v]' '[pkg]...'
            // log 'alternatives' 'List and swap alternatives'
            // log 'build' 'Build packages'
            // log 'checksum' 'Generate checksums'
            // log 'download' 'Download sources'
            // log 'install' 'Install packages'
            // log 'list' 'List installed packages'
            // log 'pick' 'Query and pick up a package'
            // log 'remove' 'Remove packages'
            // log 'search' 'Search for packages'
            // log 'update' 'Update the system and repositories'
            // log 'upgrade' 'Update the system'
            // log 'version' 'Package version'

            // log '\nRun "kiss [H|help-ext]" to see all actions\n'
            ;;

        *)
            # _KISS_LVL must be reset here so the that any extensions
            # which call the package manager do not increment the value
            # further than the parent instance.
            // debug '$#' "$#"
            // debug '$2-$#' "$2-$#"

            local kiss_command="$(// delegate -- "pkg_find" "kiss-$action*" "" -x "$PATH")"
            // hint '$kiss_command' "$kiss_command"
            ok "$kiss_command" || // die '$kiss_command' "$kiss_command"

            // debug '$sys_db' "$sys_db"
            // debug '$kiss_command' "$kiss_command"

            // pipe_read_kill "$pid_log" &
            pig_list="${pig_list:+"${pig_list} "}$!"
            // pipe_read_kill "$pid_screen" &
            pig_list="${pig_list:+"${pig_list} "}$!"

            # Like this
            # /usr/bin/kiss-manifest $@
            _KISS_LVL=1 "$kiss_command" "$@"
    esac
}

# Need a nicer way of detecting architecture
determine_arch() {
    _env
    local _arch="$($cmd_elf -a -W $1 | grep 'Machine:')"
    local _endian="$($cmd_elf -a -W $1 | grep 'Data:')"

    case "$_arch $_endian" in
        *AArch64*little*)   arch="aarch64-linux-musl";;
        *AArch64*big*)      arch="aarch64_be-linux-musl";;
        *ARM*)              arch="armv7-linux-musleabihf";;
        *Intel*80386*)      arch="i686-linux-musl";;
        *PowerPC64*little*) arch="powerpc64le-linux-musl";;
        *PowerPC64*big*)    arch="powerpc64-linux-musl";;
        *PowerPC*little*)   arch="powerpcle-linux-musl";;
        *PowerPC*big*)      arch="powerpc-linux-musl";;
        *X86-64*)           arch="x86_64-linux-musl";;
        *RISC-V*)           arch="riscv64-linux-musl";;
        *)
            // die 'Unknown architecture' "$_arch / $_endian"
            ;;
    esac

    echo $arch
}

cross_flags() {
    _env
    export KISS_XBUILD_TRIPLE="$(clang -print-target-triple | sed 's/-unknown//')"
    export KISS_XHOST_TRIPLE="${KISS_XHOST_TRIPLE:-$(// determine_arch $KISS_ROOT/usr/bin/bzip2)}"

    set -f
    IFS_ORIGIN=$IFS
    IFS=-

    set -- $KISS_XBUILD_TRIPLE
    export KISS_XBUILD_ARCH=$1
    export KISS_XBUILD_SYS=$2
    export KISS_XBUILD_ABI=$3

    set -- $KISS_XHOST_TRIPLE
    export KISS_XHOST_ARCH=$1
    export KISS_XHOST_SYS=$2
    export KISS_XHOST_ABI=$3

    IFS=$IFS_ORIGIN
    set +f

    # Flags used for pkg-config
    export PKG_CONFIG_PATH=
    export PKG_CONFIG_LIBDIR=${KISS_ROOT}/usr/lib/pkgconfig:${KISS_ROOT}/usr/share/pkgconfig
    export PKG_CONFIG_SYSROOT_DIR=${KISS_ROOT}

    # Don't carry over flags if this is a cross build
    [ -z ${KISS_ROOT:+x} ] || {
        unset CFLAGS
        unset CXXFLAGS
        unset LDFLAGS
    }

    # Allow setting of chroot-specific cflags
    flagfile="$KISS_ROOT/etc/os-buildflags"
    [ ! -f "$flagfile" ] || source $flagfile

    # Set the compiler target architecture
    if [ -z "${KISS_ROOT:+x}" ]; then
        # Local build. Allow user-set CFLAGS as per normal KISS, or override them in /etc/os-buildflags
        export CC="${CC:-clang}"
        export CXX="${CXX:-clang++}"
    else
        # Cross build. CFLAGS will always come from $KISS_ROOT/etc/os-buildflags
        flags="--target=$KISS_XHOST_TRIPLE --sysroot=${KISS_ROOT} -fPIC"
        export   CFLAGS="$flags $CFLAGS"
        export CXXFLAGS="$flags $CXXFLAGS"
        export  LDFLAGS="--sysroot=$KISS_ROOT $LDFLAGS"
        export       CC="clang $CFLAGS"
        export      CXX="clang++ $CXXFLAGS"
    fi
}

repo_setup() {
    _env
    # Set variables which help with cross building
    if [ -z "$KISS_BINREPO" ]; then
        // cross_flags

        # Bin repo will be "local" for normal builds, for chroot builds
        # it will be the last part of $KISS_ROOT appended with md5sum of
        # the full $KISS_ROOT path. This keeps packages built for different
        # root directories in separate directories.
        local lastbit="${KISS_ROOT##*/}"
        if null "$lastbit"; then
            binrepo="local"
        else
            binrepo="${lastbit}_$(echo "$KISS_ROOT" | md5sum | cut -c1-32)"
        fi
    else
        binrepo="$KISS_BINREPO"
    fi
}

func_name="kiss"

main() {

    # Color can be disabled via the environment variable KISS_COLOR. Colors are
    # also automatically disabled if output is being used in a pipe/redirection.
    equ "$KISS_COLOR" 0 || { :; ! [ -t 2 ]; } || { :
        if [ -z "${KISS_ROOT:+x}" ]; then
            [ -n "${KISS_C1:+x}" ] && c1="$KISS_C1" || { c1='\033[1;100m'; KISS_C1="$c1"; }
            [ -n "${KISS_C2:+x}" ] && c2="$KISS_C2" || { c2='\033[1;32m'; KISS_C2="$c2"; }
            [ -n "${KISS_C3:+x}" ] && c3="$KISS_C3" || { c3='\033[m'; KISS_C3="$c3"; }
        else
            [ -n "${KISS_C1:+x}" ] && c1="$KISS_C1" || { c1='\033[1;41m'; KISS_C1="$c1"; }
            [ -n "${KISS_C2:+x}" ] && c2="$KISS_C2" || { c2='\033[1;32m'; KISS_C2="$c2"; }
            [ -n "${KISS_C3:+x}" ] && c3="$KISS_C3" || { c3='\033[m'; KISS_C3="$c3"; }
        fi
        [ -n "${KISS_LINEC:+x}" ] && c4="$KISS_LINEC" || { c4='\033[1:90m'; KISS_LINEC="$c4"; }
    }

    # http://mywiki.wooledge.org/BashFAQ/105
    # Globally disable globbing and enable exit-on-error.

    # https://unix.stackexchange.com/questions/151771/getting-wrong-lineno-for-a-trapped-function
    set -efE # -eE # -ef # -exf

    # Store the original working directory to ensure that relative paths
    # passed by the user on the command-line properly resolve to locations
    # in the filesystem.
    ppwd=$PWD

    # : "${kiss_path_repo_list_origin:="${KISS_PATH}"}"
    # // war '$kiss_path_repo_list_origin' "$kiss_path_repo_list_origin"

    # Store the date and time of script invocation to be used as the name of
    # the log files the package manager creates during builds.
    time=$(date +%Y-%m-%d-%H:%M)

    # Never know when you're gonna need one of these.
    newline="
"
    cr="\n"

    # Defaults for environment variables.
    : "${KISS_COMPRESS:=gz}"
    : "${KISS_PID:=$$}"
    : "${LOGNAME:?POSIX requires LOGNAME be set}"


    # Figure out which 'sudo' command to use based on the user's choice or what
    # is available on the system.
    cmd_su=${KISS_SU:-"$(
        command -v /usr/bin/ssu  ||
        command -v /usr/bin/doas ||
        command -v /usr/bin/sudo ||
        command -v /usr/bin/su
    )"} || cmd_su=/usr/bin/su

    # Figure out which utility is available to dump elf information.
    cmd_elf=${KISS_ELF:-"$(
        command -v /usr/bin/readelf      ||
        command -v /usr/bin/eu-readelf   ||
        command -v /usr/bin/llvm-readelf
    )"} || cmd_elf=/usr/bin/ldd

    # Only after thie line, logs might work
    log_address

    // debug '$KISS_C1' "$KISS_C1"
    // debug '$KISS_C2' "$KISS_C2"
    // debug '$KISS_C3' "$KISS_C3"

    _env

    # Figure out which sha256 utility is available.
    cmd_sha=${KISS_CHK:-"$(
        command -v /usr/bin/openssl   ||
        command -v /usr/bin/sha256sum ||
        command -v /usr/bin/sha256    ||
        command -v /usr/bin/shasum    ||
        command -v /usr/bin/digest
    )"} || // die 'sha256' "utility not found"

    # Figure out which download utility is available.
    cmd_get=${KISS_GET:-"$(
        command -v /usr/bin/aria2c ||
        command -v /usr/bin/axel   ||
        command -v /usr/bin/curl   ||
        command -v /usr/bin/wget   ||
        command -v /usr/bin/wget2
    )"} || // die 'download utility' "not found (aria2c, axel, curl, wget, wget2)"


    init_dirs "$ppwd"
    // log '$log_dir' "$log_dir"
    // log '$KISS_ROOT' "$KISS_ROOT"
    // log '$KISS_PID' "$KISS_PID"
    // log '$PPID' "$PPID"

    // repo_setup

    # Catch errors and ensure that build files and directories are cleaned
    # up before we die. This occurs on 'Ctrl+C' as well as success and error.
    # trap clean_all EXIT INT
    # trap_off
    trap_on "$@"

    // args "$@"

    trap_off

    [ -n "${log_permanent_all_done:+x}" ] || // log_permanent_all "$@"

    // pipe_read_kill "$pid_log" &
    pig_list="${pig_list:+"${pig_list} "}$!"
    // pipe_read_kill "$pid_screen" &
    pig_list="${pig_list:+"${pig_list} "}$!"
    local item
    # for item in $pig_list; do printf "%s %s\n" '$item' "$item"; done;
    as_own "$log_dir" rm -f -- "$log_output"
    as_own "$log_dir" rm -f -- "$log_pipe"
    as_own "$log_dir" rm -f -- "$screen_pipe"
    [ ! -p "$log_pipe" ] || // die '$log_pipe' "$log_pipe"
    [ ! -p "$screen_pipe" ] || // die '$screen_pipe' "$screen_pipe"

    trap "exit" INT TERM

    # [ "$(whoami)" == "$LOGNAME" ] &&
    [ "$_KISS_LVL" -ne "1" ] ||
    trap "kill 0" EXIT
    # trap 'for item in $pig_list; do printf "%s %s\n" "In trap \$item" "$item"; kill -0 $item && kill $item; done; kill -0 $KISS_PID && kill $KISS_PID; ' EXIT
    return 0
}

// main "$@"

# vi:   set filetype=sh syntax=sh :
# vim:  set filetype=sh syntax=sh :
# nvim: set filetype=sh syntax=sh :
